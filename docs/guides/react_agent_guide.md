# ReAct Self-Reflection Agent Guide

## ê°œìš”

ReAct (Reasoning + Acting) Self-Reflection íŒ¨í„´ì„ êµ¬í˜„í•œ AI ì—ì´ì „íŠ¸ë¡œ, ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¨ê³„ì  ì‚¬ê³ ì™€ ìì²´ í‰ê°€ë¥¼ í†µí•´ ê³ í’ˆì§ˆ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

## ë™ì‘ ì›ë¦¬

### ReAct Loop

```
1. Thought (ì‚¬ê³ )
   â†“
2. Action (í–‰ë™)
   â†“
3. Observation (ê´€ì°°)
   â†“
4. Reflection (ë°˜ì„±)
   â†“
   ë°˜ë³µ (ìµœëŒ€ 3íšŒ)
```

### Self-Reflection

ì‘ë‹µ ìƒì„± í›„ ìì²´ í’ˆì§ˆ í‰ê°€:
- ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µë³€í–ˆëŠ”ê°€?
- ëˆ„ë½ëœ ì¤‘ìš” ì •ë³´ê°€ ìˆëŠ”ê°€?
- ë°ì´í„°/ê·¼ê±°ê°€ ì¶©ë¶„í•œê°€?

## ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### ìë™ í™œì„±í™” (UnifiedBrain)

`UnifiedBrain.process_query()`ì—ì„œ ë³µì¡í•œ ì§ˆë¬¸ ìë™ ê°ì§€:

```python
from src.core.brain import get_initialized_brain

brain = await get_initialized_brain()
response = await brain.process_query("LANEIGEê°€ ê²½ìŸì‚¬ ëŒ€ë¹„ ì–´ë–¤ ìœ„ì¹˜ì— ìˆëŠ”ì§€ ë¶„ì„í•´ì¤˜")

# ë³µì¡ë„ íŒë‹¨ â†’ ReAct ëª¨ë“œ ìë™ í™œì„±í™”
print(f"Mode: {response.metadata.get('mode')}")  # "react"
print(f"Iterations: {response.metadata.get('iterations')}")
```

### ìˆ˜ë™ ì‚¬ìš© (Standalone)

```python
from src.core.react_agent import get_react_agent

agent = get_react_agent()
agent.set_tool_executor(tool_executor)

result = await agent.run(
    query="LANEIGE ìˆœìœ„ ì¶”ì´ëŠ”?",
    context="ìµœê·¼ 30ì¼ ë°ì´í„° ìˆìŒ"
)

print(f"ë‹µë³€: {result.final_answer}")
print(f"ì‹ ë¢°ë„: {result.confidence}")
print(f"ë°˜ë³µ íšŸìˆ˜: {result.iterations}")
```

## ë³µì¡ë„ íŒë‹¨ ê¸°ì¤€

UnifiedBrainì€ ë‹¤ìŒ ì¡°ê±´ìœ¼ë¡œ ë³µì¡í•œ ì§ˆë¬¸ íŒë‹¨:

| ì¡°ê±´ | ì˜ˆì‹œ |
|------|------|
| ë¶„ì„ì  í‚¤ì›Œë“œ | "ì™œ", "ì–´ë–»ê²Œ", "ë¹„êµ", "ë¶„ì„", "ì¶”ì²œ" |
| ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡± | RAG ë¬¸ì„œ < 2ê°œ, KG íŠ¸ë¦¬í”Œ ì—†ìŒ |
| ë‹¤ë‹¨ê³„ ì§ˆë¬¸ | "?"ê°€ 2ê°œ ì´ìƒ, ì ‘ì†ì‚¬ ("ê·¸ë¦¬ê³ ", "í•˜ì§€ë§Œ") |

**ë³µì¡í•œ ì§ˆë¬¸ ì˜ˆì‹œ:**
- "LANEIGEê°€ CeraVe ëŒ€ë¹„ ì™œ ìˆœìœ„ê°€ ë‚®ì€ì§€ ë¶„ì„í•´ì¤˜"
- "ê²½ìŸì‚¬ì™€ ë¹„êµí–ˆì„ ë•Œ LANEIGEì˜ ì „ëµì€ ì–´ë–»ê²Œ ê°œì„ í•  ìˆ˜ ìˆì„ê¹Œ?"
- "SoSê°€ í•˜ë½í•œ ì›ì¸ê³¼ í•´ê²° ë°©ì•ˆì€?"

**ë‹¨ìˆœí•œ ì§ˆë¬¸ ì˜ˆì‹œ:**
- "LANEIGE ìˆœìœ„ ì•Œë ¤ì¤˜"
- "ì˜¤ëŠ˜ ë°ì´í„° ìˆì–´?"
- "LANEIGE ASINì€?"

## ReAct Step êµ¬ì¡°

```python
@dataclass
class ReActStep:
    thought: str                       # í˜„ì¬ ìƒí™© ë¶„ì„
    action: str | None = None          # ì„ íƒí•œ ë„êµ¬ (query_data, query_knowledge_graph ë“±)
    action_input: dict | None = None   # ë„êµ¬ íŒŒë¼ë¯¸í„°
    observation: str | None = None     # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
    reflection: str | None = None      # ê²°ê³¼ í‰ê°€
```

## ì„¤ì • íŒŒë¼ë¯¸í„°

```python
agent = ReActAgent(
    model="gpt-4o-mini",          # LLM ëª¨ë¸
    max_iterations=3,             # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    min_confidence=0.7            # ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’
)
```

## ë„êµ¬ í†µí•©

ReActAgentëŠ” `ToolExecutor`ì™€ ì—°ê²°í•˜ì—¬ ë‹¤ìŒ ë„êµ¬ ì‚¬ìš©:

| ë„êµ¬ | ì„¤ëª… |
|------|------|
| `query_data` | ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ |
| `query_knowledge_graph` | ì§€ì‹ ê·¸ë˜í”„ ì¡°íšŒ |
| `calculate_metrics` | ì§€í‘œ ê³„ì‚° |
| `final_answer` | ìµœì¢… ë‹µë³€ (ë£¨í”„ ì¢…ë£Œ) |

```python
# UnifiedBrainì˜ ToolExecutor ì—°ê²°
agent.set_tool_executor(brain.tool_executor)
```

## ì‘ë‹µ êµ¬ì¡°

```python
@dataclass
class ReActResult:
    final_answer: str                  # ìµœì¢… ë‹µë³€
    steps: list[ReActStep]             # ì‹¤í–‰ ë‹¨ê³„
    iterations: int                    # ë°˜ë³µ íšŸìˆ˜
    confidence: float                  # ì‹ ë¢°ë„ (0.0~1.0)
    needs_improvement: bool            # ê°œì„  í•„ìš” ì—¬ë¶€
```

## ë¡œê¹… ë° ë””ë²„ê¹…

```python
import logging

# ReAct ì‹¤í–‰ ë¡œê·¸ í™•ì¸
logging.getLogger("src.core.react_agent").setLevel(logging.DEBUG)

# ë³µì¡ë„ íŒë‹¨ ë¡œê·¸
logging.getLogger("src.core.brain").setLevel(logging.INFO)
```

**ë¡œê·¸ ì˜ˆì‹œ:**
```
[INFO] Complex query detected, using ReAct mode: LANEIGEê°€ ê²½ìŸì‚¬ ëŒ€ë¹„...
[INFO] ğŸ”§ Tool: query_data | Params: {"query_type": "brand_metrics"}
[INFO] ğŸ‘ï¸ Observation: {"brand": "LANEIGE", "rank": 5, "sos": 12.5}
[WARNING] ReAct result needs improvement (confidence: 0.65)
```

## ì„±ëŠ¥ ìµœì í™”

### 1. ìºì‹±

ë³µì¡í•œ ì§ˆë¬¸ë„ ìºì‹± ê°€ëŠ¥:

```python
response = await brain.process_query(
    query="LANEIGE ê²½ìŸ ë¶„ì„",
    skip_cache=False  # ìºì‹œ í™œì„±í™”
)
```

### 2. ë°˜ë³µ íšŸìˆ˜ ì¡°ì •

ê°„ë‹¨í•œ ë³µì¡í•œ ì§ˆë¬¸:
```python
agent = ReActAgent(max_iterations=2)  # ë¹ ë¥¸ ì‘ë‹µ
```

ë§¤ìš° ë³µì¡í•œ ì§ˆë¬¸:
```python
agent = ReActAgent(max_iterations=5)  # ê¹Šì€ ë¶„ì„
```

### 3. ëª¨ë¸ ì„ íƒ

ë¹ ë¥¸ ì‘ë‹µ:
```python
agent = ReActAgent(model="gpt-4o-mini")  # ê¸°ë³¸ê°’
```

ê³ í’ˆì§ˆ ì‘ë‹µ:
```python
agent = ReActAgent(model="gpt-4o")  # ë” ì •í™•
```

## ì—ëŸ¬ ì²˜ë¦¬

```python
try:
    result = await agent.run(query, context)

    if result.needs_improvement:
        logger.warning("ë‚®ì€ í’ˆì§ˆ ì‘ë‹µ ê°ì§€")

    if result.confidence < 0.5:
        logger.warning("ë‚®ì€ ì‹ ë¢°ë„ - ì¶”ê°€ ì •ë³´ í•„ìš”")

except Exception as e:
    logger.error(f"ReAct ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    # Fallback ë¡œì§
```

## ì‹¤ì „ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ìˆœìœ„ ë¶„ì„

```python
query = "LANEIGE ìˆœìœ„ê°€ ì™œ í•˜ë½í–ˆëŠ”ì§€ ë¶„ì„í•´ì¤˜"

# UnifiedBrainì´ ìë™ìœ¼ë¡œ ReAct ëª¨ë“œ í™œì„±í™”
response = await brain.process_query(query)

# Step 1: Thought - "ìˆœìœ„ í•˜ë½ ì›ì¸ ë¶„ì„ í•„ìš”"
# Step 2: Action - query_data(query_type="brand_metrics")
# Step 3: Observation - {"rank": 8, "rank_delta": "+3"}
# Step 4: Thought - "ê²½ìŸì‚¬ ë™í–¥ í™•ì¸ í•„ìš”"
# Step 5: Action - query_data(query_type="competitor_analysis")
# Step 6: Observation - {"CeraVe": {"rank": 2, "deals": "Lightning Deal"}}
# Step 7: Action - final_answer
# Self-Reflection: confidence=0.85, needs_improvement=False
```

### ì˜ˆì‹œ 2: ì „ëµ ì¶”ì²œ

```python
query = "LANEIGEì˜ SoSë¥¼ ë†’ì´ê¸° ìœ„í•œ ì „ëµì„ ì¶”ì²œí•´ì¤˜"

response = await brain.process_query(query)

# Step 1: Thought - "í˜„ì¬ SoS í™•ì¸"
# Step 2: Action - query_data(query_type="brand_metrics")
# Step 3: Observation - {"sos": 12.5}
# Step 4: Thought - "ê²½ìŸì‚¬ SoSì™€ ë¹„êµ í•„ìš”"
# Step 5: Action - query_knowledge_graph(entity="LANEIGE", relation_type="competitors")
# Step 6: Observation - {"competitors": ["CeraVe", "Neutrogena"]}
# Step 7: Action - final_answer
# Self-Reflection: confidence=0.72, needs_improvement=True
```

## ì œì•½ì‚¬í•­

1. **ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ì œí•œ**: ë¬´í•œ ë£¨í”„ ë°©ì§€ (ê¸°ë³¸ 3íšŒ)
2. **ë„êµ¬ ì˜ì¡´ì„±**: ToolExecutorì— ë“±ë¡ëœ ë„êµ¬ë§Œ ì‚¬ìš© ê°€ëŠ¥
3. **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´**: ê³¼ë„í•œ step ëˆ„ì  ì‹œ í† í° ì œí•œ ì£¼ì˜
4. **LLM íŒŒì‹± ì˜¤ë¥˜**: JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback

## í–¥í›„ ê°œì„  ë°©í–¥

- [ ] Multi-Agent ReAct (ë³‘ë ¬ ì‚¬ê³ )
- [ ] í•™ìŠµ ê¸°ë°˜ ë°˜ë³µ íšŸìˆ˜ ì¡°ì •
- [ ] ë„êµ¬ ì„ íƒ ìš°ì„ ìˆœìœ„ í•™ìŠµ
- [ ] Reflection ê¸°ë°˜ ìë™ ì¬ì‹œë„

## ì°¸ê³  ìë£Œ

- [ReAct Paper (Yao et al., 2022)](https://arxiv.org/abs/2210.03629)
- [Self-Reflection in LLMs](https://arxiv.org/abs/2303.11366)
- `src/core/react_agent.py`: êµ¬í˜„ ì½”ë“œ
- `tests/unit/core/test_react_agent.py`: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- `examples/react_agent_demo.py`: ì‹¤í–‰ ê°€ëŠ¥í•œ ë°ëª¨
