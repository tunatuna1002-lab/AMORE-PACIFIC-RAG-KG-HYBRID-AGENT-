"""
ëŒ€ì‹œë³´ë“œ ì˜¨í†¨ë¡œì§€ ì¸ì‚¬ì´íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸
ê¸°ì¡´ dashboard_data.jsonì„ ë¡œë“œí•˜ì—¬ ì˜¨í†¨ë¡œì§€ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.ontology.knowledge_graph import KnowledgeGraph
from src.ontology.reasoner import OntologyReasoner
from src.ontology.business_rules import register_all_rules
from src.ontology.relations import Relation, RelationType


def load_dashboard_data() -> dict:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ"""
    data_path = PROJECT_ROOT / "data" / "dashboard_data.json"
    with open(data_path, "r", encoding="utf-8") as f:
        return json.load(f)


def generate_ontology_insights(dashboard_data: dict) -> dict:
    """ì˜¨í†¨ë¡œì§€ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    # 1. Knowledge Graph êµ¬ì¶•
    kg = KnowledgeGraph()
    reasoner = OntologyReasoner(kg)
    register_all_rules(reasoner)

    stats = {"brand_product": 0, "product_category": 0, "competition": 0}

    # ì œí’ˆ ë°ì´í„°ì—ì„œ ê´€ê³„ ì¶”ì¶œ
    products = dashboard_data.get("products", {})
    for asin, product in products.items():
        # Brand â†’ Product
        rel1 = Relation(
            subject="LANEIGE",
            predicate=RelationType.HAS_PRODUCT,
            object=asin,
            properties={
                "product_name": product.get("name", "")[:50],
                "rank": product.get("rank"),
                "category": product.get("category")
            }
        )
        kg.add_relation(rel1)
        stats["brand_product"] += 1

        # Product â†’ Category
        category = product.get("category")
        if category:
            rel2 = Relation(
                subject=asin,
                predicate=RelationType.BELONGS_TO_CATEGORY,
                object=category,
                properties={"rank": product.get("rank")}
            )
            kg.add_relation(rel2)
            stats["product_category"] += 1

    # ê²½ìŸì‚¬ ê´€ê³„ ì¶”ì¶œ
    competitors = dashboard_data.get("brand", {}).get("competitors", [])
    for comp in competitors:
        brand_name = comp.get("brand", "")
        is_laneige = brand_name.upper() == "LANEIGE"

        # ë©”íƒ€ë°ì´í„° ì„¤ì •
        kg.set_entity_metadata(brand_name, {
            "type": "brand",
            "sos": comp.get("sos", 0) / 100,
            "avg_rank": comp.get("avg_rank"),
            "product_count": comp.get("product_count"),
            "is_target": is_laneige
        })

        if not is_laneige:
            rel = Relation(
                subject="LANEIGE",
                predicate=RelationType.COMPETES_WITH,
                object=brand_name,
                properties={"competitor_sos": comp.get("sos", 0) / 100}
            )
            kg.add_relation(rel)
            stats["competition"] += 1

    # 2. ì¶”ë¡  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    brand_kpis = dashboard_data.get("brand", {}).get("kpis", {})
    categories = dashboard_data.get("categories", {})

    # ìµœê³  ìˆœìœ„ ì œí’ˆ ì°¾ê¸°
    best_rank = 999
    for asin, product in products.items():
        rank = product.get("rank", 999)
        if rank < best_rank:
            best_rank = rank

    first_cat = next(iter(categories.values()), {}) if categories else {}

    inference_context = {
        "brand": "LANEIGE",
        "is_target": True,
        "sos": brand_kpis.get("sos", 0) / 100,
        "avg_rank": brand_kpis.get("avg_rank", 0),
        "product_count": len(products),
        "hhi": brand_kpis.get("hhi", 0),
        "top1_sos": competitors[0].get("sos", 0) / 100 if competitors else 0,
        "category": next(iter(categories.keys()), "unknown"),
        "cpi": first_cat.get("cpi", 100),
        "best_rank": first_cat.get("best_rank", best_rank),
        "competitor_count": len([c for c in competitors if c.get("brand", "").upper() != "LANEIGE"]),
        "current_rank": best_rank,
        "rank_change_7d": 0,
        "streak_days": 7,
        "rating_gap": 0.1
    }

    # 3. ì¶”ë¡  ì‹¤í–‰
    inferences = reasoner.infer(inference_context)

    # 4. ê²°ê³¼ í¬ë§·íŒ…
    def get_priority(insight_type):
        high = {"risk_alert", "competitive_threat", "rank_shock"}
        medium = {"price_quality_gap", "competitive_advantage", "growth_opportunity"}
        if insight_type in high:
            return "high"
        elif insight_type in medium:
            return "medium"
        return "low"

    def get_icon(insight_type):
        icons = {
            "market_dominance": "crown",
            "market_position": "chart-bar",
            "competitive_advantage": "star",
            "competitive_threat": "exclamation-triangle",
            "growth_momentum": "arrow-up",
            "stability": "shield-check",
            "risk_alert": "bell",
            "entry_opportunity": "door-open",
            "price_position": "tag",
            "price_quality_gap": "balance-scale"
        }
        return icons.get(insight_type, "lightbulb")

    def get_color(insight_type):
        colors = {
            "market_dominance": "#10b981",
            "market_position": "#3b82f6",
            "competitive_advantage": "#8b5cf6",
            "competitive_threat": "#ef4444",
            "growth_momentum": "#22c55e",
            "stability": "#06b6d4",
            "risk_alert": "#f59e0b",
            "entry_opportunity": "#14b8a6",
            "price_position": "#6366f1",
            "price_quality_gap": "#f97316"
        }
        return colors.get(insight_type, "#6b7280")

    formatted_inferences = []
    for inf in inferences:
        insight_type = inf.insight_type.value
        formatted_inferences.append({
            "rule_name": inf.rule_name,
            "insight_type": insight_type,
            "insight": inf.insight,
            "recommendation": inf.recommendation,
            "confidence": inf.confidence,
            "priority": get_priority(insight_type),
            "icon": get_icon(insight_type),
            "color": get_color(insight_type)
        })

    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
    formatted_inferences.sort(
        key=lambda x: (0 if x["priority"] == "high" else 1 if x["priority"] == "medium" else 2)
    )

    # ìš”ì•½ ìƒì„±
    positive_types = {"market_dominance", "competitive_advantage", "growth_momentum", "stability"}
    warning_types = {"risk_alert", "competitive_threat", "price_quality_gap"}
    opportunity_types = {"entry_opportunity", "growth_opportunity"}

    positive = sum(1 for inf in inferences if inf.insight_type.value in positive_types)
    warnings = sum(1 for inf in inferences if inf.insight_type.value in warning_types)
    opportunities = sum(1 for inf in inferences if inf.insight_type.value in opportunity_types)

    top_inference = max(inferences, key=lambda x: x.confidence) if inferences else None

    kg_stats = kg.get_stats()

    return {
        "enabled": True,
        "total_rules": len(reasoner.rules),
        "triggered_rules": len(inferences),
        "kg_stats": {
            "total_triples": kg_stats.get("total_triples", 0),
            "brand_product": stats["brand_product"],
            "product_category": stats["product_category"],
            "competition": stats["competition"]
        },
        "inferences": formatted_inferences,
        "summary": {
            "total_insights": len(inferences),
            "positive_count": positive,
            "warning_count": warnings,
            "opportunity_count": opportunities,
            "headline": top_inference.insight if top_inference else "ì¶”ë¡ ëœ ì¸ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.",
            "top_rule": top_inference.rule_name if top_inference else None
        },
        "context": inference_context
    }


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ¯ ëŒ€ì‹œë³´ë“œ ì˜¨í†¨ë¡œì§€ ì¸ì‚¬ì´íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸")
    print(f"   ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # 1. ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ
    print("\nğŸ“Š ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    dashboard_data = load_dashboard_data()
    print(f"   - ìƒì„±ì¼: {dashboard_data.get('metadata', {}).get('generated_at')}")
    print(f"   - ì œí’ˆ ìˆ˜: {len(dashboard_data.get('products', {}))}")

    # 2. ì˜¨í†¨ë¡œì§€ ì¸ì‚¬ì´íŠ¸ ìƒì„±
    print("\nğŸ§  ì˜¨í†¨ë¡œì§€ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
    ontology_insights = generate_ontology_insights(dashboard_data)

    print(f"\nğŸ“ˆ Knowledge Graph í†µê³„:")
    kg_stats = ontology_insights.get("kg_stats", {})
    print(f"   - ì´ íŠ¸ë¦¬í”Œ: {kg_stats.get('total_triples', 0)}")
    print(f"   - ë¸Œëœë“œ-ì œí’ˆ: {kg_stats.get('brand_product', 0)}")
    print(f"   - ì œí’ˆ-ì¹´í…Œê³ ë¦¬: {kg_stats.get('product_category', 0)}")
    print(f"   - ê²½ìŸ ê´€ê³„: {kg_stats.get('competition', 0)}")

    print(f"\nğŸ” ì¶”ë¡  ê²°ê³¼:")
    print(f"   - ì´ ê·œì¹™: {ontology_insights.get('total_rules', 0)}ê°œ")
    print(f"   - íŠ¸ë¦¬ê±°ëœ ê·œì¹™: {ontology_insights.get('triggered_rules', 0)}ê°œ")

    summary = ontology_insights.get("summary", {})
    print(f"\nğŸ“‹ ìš”ì•½:")
    print(f"   - ê¸ì •ì  ì¸ì‚¬ì´íŠ¸: {summary.get('positive_count', 0)}ê°œ")
    print(f"   - ê²½ê³ : {summary.get('warning_count', 0)}ê°œ")
    print(f"   - ê¸°íšŒ: {summary.get('opportunity_count', 0)}ê°œ")
    print(f"   - ëŒ€í‘œ ì¸ì‚¬ì´íŠ¸: {summary.get('headline', '')[:50]}...")

    # 3. ì¸ì‚¬ì´íŠ¸ ìƒì„¸ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“ ìƒì„¸ ì¸ì‚¬ì´íŠ¸")
    print("=" * 60)

    for i, inf in enumerate(ontology_insights.get("inferences", []), 1):
        priority_emoji = "ğŸ”´" if inf["priority"] == "high" else "ğŸŸ¡" if inf["priority"] == "medium" else "ğŸŸ¢"
        print(f"\n{i}. {priority_emoji} [{inf['insight_type']}] (ì‹ ë¢°ë„: {inf['confidence']:.0%})")
        print(f"   ğŸ’¡ {inf['insight']}")
        if inf.get("recommendation"):
            print(f"   ğŸ“Œ ê¶Œì¥: {inf['recommendation']}")
        print(f"   ğŸ¨ ìƒ‰ìƒ: {inf['color']} | ì•„ì´ì½˜: {inf['icon']}")

    # 4. ëŒ€ì‹œë³´ë“œ ë°ì´í„°ì— ì¶”ê°€í•˜ì—¬ ì €ì¥
    dashboard_data["ontology_insights"] = ontology_insights
    dashboard_data["metadata"]["ontology_enabled"] = True

    output_path = PROJECT_ROOT / "data" / "dashboard_data_with_ontology.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(dashboard_data, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")

    print("\n" + "=" * 60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 60)

    # JSON êµ¬ì¡° ë¯¸ë¦¬ë³´ê¸°
    print("\nğŸ“„ ontology_insights êµ¬ì¡° ë¯¸ë¦¬ë³´ê¸°:")
    print(json.dumps({
        "enabled": ontology_insights["enabled"],
        "total_rules": ontology_insights["total_rules"],
        "triggered_rules": ontology_insights["triggered_rules"],
        "kg_stats": ontology_insights["kg_stats"],
        "summary": ontology_insights["summary"],
        "inferences_count": len(ontology_insights["inferences"])
    }, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
