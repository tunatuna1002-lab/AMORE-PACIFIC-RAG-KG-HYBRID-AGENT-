"""
LLM API ì—°ë™ í…ŒìŠ¤íŠ¸
HybridInsightAgentë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
"""

import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv(PROJECT_ROOT / ".env")

from src.ontology.knowledge_graph import KnowledgeGraph
from src.ontology.reasoner import OntologyReasoner
from src.ontology.business_rules import register_all_rules
from src.domain.entities.relations import Relation, RelationType

from src.rag.hybrid_retriever import HybridRetriever, HybridContext
from src.rag.context_builder import ContextBuilder

from src.agents.hybrid_insight_agent import HybridInsightAgent


def load_dashboard_data() -> dict:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ"""
    data_path = PROJECT_ROOT / "data" / "dashboard_data.json"
    with open(data_path, "r", encoding="utf-8") as f:
        return json.load(f)


def build_metrics_data_from_dashboard(data: dict) -> dict:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„°ì—ì„œ ë©”íŠ¸ë¦­ ë°ì´í„° êµ¬ì„±"""
    brand_kpis = data.get("brand", {}).get("kpis", {})
    categories = data.get("categories", {})
    products = data.get("products", {})
    competitors = data.get("brand", {}).get("competitors", [])

    # ë¸Œëœë“œ ë©”íŠ¸ë¦­
    brand_metrics = []
    for comp in competitors:
        brand_metrics.append({
            "brand_name": comp.get("brand"),
            "share_of_shelf": comp.get("sos", 0) / 100,
            "avg_rank": comp.get("avg_rank"),
            "product_count": comp.get("product_count"),
            "is_laneige": comp.get("brand", "").upper() == "LANEIGE"
        })

    # ì œí’ˆ ë©”íŠ¸ë¦­
    product_metrics = []
    for asin, product in products.items():
        product_metrics.append({
            "asin": asin,
            "product_title": product.get("name", ""),
            "category_id": product.get("category"),
            "current_rank": product.get("rank"),
            "rank_change_1d": 0,  # ë°ì´í„°ì— ì—†ìŒ
            "rank_change_7d": 0,
            "rating": product.get("rating"),
            "rank_volatility": product.get("volatility", 0)
        })

    # ë§ˆì¼“ ë©”íŠ¸ë¦­
    market_metrics = []
    for cat_id, cat_data in categories.items():
        market_metrics.append({
            "category_id": cat_id,
            "hhi": brand_kpis.get("hhi", 0.02),
            "cpi": cat_data.get("cpi", 100),
            "avg_rating_gap": 0.1
        })

    # ì„œë¨¸ë¦¬
    summary = {
        "laneige_products_tracked": len(product_metrics),
        "laneige_sos_by_category": {
            cat_id: cat_data.get("sos", 0) / 100
            for cat_id, cat_data in categories.items()
        },
        "alert_count": 0
    }

    return {
        "summary": summary,
        "brand_metrics": brand_metrics,
        "product_metrics": product_metrics,
        "market_metrics": market_metrics,
        "alerts": []
    }


def build_knowledge_graph_from_dashboard(data: dict) -> KnowledgeGraph:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„°ì—ì„œ KG êµ¬ì¶•"""
    kg = KnowledgeGraph()

    # ì œí’ˆ ì •ë³´
    products = data.get("products", {})
    for asin, product in products.items():
        brand = "LANEIGE"
        category = product.get("category", "unknown")

        # Brand â†’ Product
        kg.add_relation(Relation(
            subject=brand,
            predicate=RelationType.HAS_PRODUCT,
            object=asin,
            properties={
                "product_name": product.get("name", "")[:50],
                "rank": product.get("rank"),
                "category": category
            }
        ))

        # Product â†’ Category
        kg.add_relation(Relation(
            subject=asin,
            predicate=RelationType.BELONGS_TO_CATEGORY,
            object=category,
            properties={"rank": product.get("rank")}
        ))

    # ê²½ìŸì‚¬ ì •ë³´
    competitors = data.get("brand", {}).get("competitors", [])
    for comp in competitors:
        brand_name = comp.get("brand", "")
        is_laneige = brand_name.upper() == "LANEIGE"

        kg.set_entity_metadata(brand_name, {
            "type": "brand",
            "sos": comp.get("sos", 0) / 100,
            "avg_rank": comp.get("avg_rank"),
            "product_count": comp.get("product_count"),
            "is_target": is_laneige
        })

        if not is_laneige:
            kg.add_relation(Relation(
                subject="LANEIGE",
                predicate=RelationType.COMPETES_WITH,
                object=brand_name,
                properties={"competitor_sos": comp.get("sos", 0) / 100}
            ))

    return kg


async def test_hybrid_insight_agent_with_llm():
    """HybridInsightAgent LLM ì—°ë™ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("ğŸ¤– LLM API ì—°ë™ í…ŒìŠ¤íŠ¸")
    print(f"   ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key.startswith("sk-your"):
        print("\nâš ï¸  OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— ìœ íš¨í•œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        print("\n   í…ŒìŠ¤íŠ¸ë¥¼ í´ë°± ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
        use_fallback = True
    else:
        print(f"\nâœ… OPENAI_API_KEY í™•ì¸ë¨ (ë§ˆì§€ë§‰ 4ìë¦¬: ...{api_key[-4:]})")
        use_fallback = False

    # 1. ë°ì´í„° ë¡œë“œ
    print("\nğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    data = load_dashboard_data()
    metrics_data = build_metrics_data_from_dashboard(data)
    print(f"   - ì œí’ˆ ë©”íŠ¸ë¦­: {len(metrics_data['product_metrics'])}ê°œ")
    print(f"   - ë¸Œëœë“œ ë©”íŠ¸ë¦­: {len(metrics_data['brand_metrics'])}ê°œ")

    # 2. KG êµ¬ì¶•
    print("\nğŸ“ˆ Knowledge Graph êµ¬ì¶• ì¤‘...")
    kg = build_knowledge_graph_from_dashboard(data)
    stats = kg.get_stats()
    print(f"   - íŠ¸ë¦¬í”Œ: {stats['total_triples']}ê°œ")

    # 3. Reasoner ì´ˆê¸°í™”
    print("\nğŸ§  Reasoner ì´ˆê¸°í™” ì¤‘...")
    reasoner = OntologyReasoner(kg)
    register_all_rules(reasoner)
    print(f"   - ê·œì¹™: {len(reasoner.rules)}ê°œ")

    # 4. HybridInsightAgent ìƒì„±
    print("\nğŸ”§ HybridInsightAgent ì´ˆê¸°í™” ì¤‘...")
    model = "gpt-4o-mini" if not use_fallback else "gpt-4o-mini"

    agent = HybridInsightAgent(
        model=model,
        knowledge_graph=kg,
        reasoner=reasoner,
        docs_dir=str(PROJECT_ROOT)
    )
    print(f"   - ëª¨ë¸: {model}")

    # 5. ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤í–‰
    print("\n" + "=" * 60)
    print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤í–‰")
    print("=" * 60)

    try:
        result = await agent.execute(
            metrics_data=metrics_data,
            crawl_data=None,
            crawl_summary=None
        )

        print("\nâœ… ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"   - ìƒíƒœ: {result.get('status')}")
        print(f"   - ì¶”ë¡  ê²°ê³¼: {len(result.get('inferences', []))}ê°œ")
        print(f"   - ì•¡ì…˜ ì•„ì´í…œ: {len(result.get('action_items', []))}ê°œ")
        print(f"   - í•˜ì´ë¼ì´íŠ¸: {len(result.get('highlights', []))}ê°œ")

        # ì¼ì¼ ì¸ì‚¬ì´íŠ¸ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ“ ì¼ì¼ ì¸ì‚¬ì´íŠ¸")
        print("=" * 60)
        daily_insight = result.get("daily_insight", "")
        print(daily_insight)

        # ì¶”ë¡  ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ” ì˜¨í†¨ë¡œì§€ ì¶”ë¡  ê²°ê³¼")
        print("=" * 60)
        for i, inf in enumerate(result.get("inferences", []), 1):
            print(f"\n{i}. [{inf.get('insight_type')}]")
            print(f"   ê²°ë¡ : {inf.get('insight')}")
            if inf.get('recommendation'):
                print(f"   ê¶Œì¥: {inf.get('recommendation')}")
            print(f"   ì‹ ë¢°ë„: {inf.get('confidence', 0):.0%}")

        # ì•¡ì…˜ ì•„ì´í…œ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ“‹ ì•¡ì…˜ ì•„ì´í…œ")
        print("=" * 60)
        for i, action in enumerate(result.get("action_items", []), 1):
            priority = action.get("priority", "low").upper()
            print(f"{i}. [{priority}] {action.get('action')}")
            print(f"   ì†ŒìŠ¤: {action.get('source')} / ìœ í˜•: {action.get('type')}")

        # í•˜ì´ë¸Œë¦¬ë“œ í†µê³„
        print("\n" + "=" * 60)
        print("ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í†µê³„")
        print("=" * 60)
        hybrid_stats = result.get("hybrid_stats", {})
        print(f"   - KG ì—…ë°ì´íŠ¸: {hybrid_stats.get('kg_update', {})}")
        print(f"   - ì¶”ë¡  ê²°ê³¼: {hybrid_stats.get('inferences_count', 0)}ê°œ")
        print(f"   - RAG ì²­í¬: {hybrid_stats.get('rag_chunks_count', 0)}ê°œ")
        print(f"   - ì˜¨í†¨ë¡œì§€ ì‚¬ì‹¤: {hybrid_stats.get('ontology_facts_count', 0)}ê°œ")

        # ê²°ê³¼ ì €ì¥
        output_path = PROJECT_ROOT / "data" / "llm_insight_result.json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

        return True

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_context_builder_only():
    """ì»¨í…ìŠ¤íŠ¸ ë¹Œë”ë§Œ í…ŒìŠ¤íŠ¸ (LLM ì—†ì´)"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ì»¨í…ìŠ¤íŠ¸ ë¹Œë” í…ŒìŠ¤íŠ¸ (LLM ì—†ì´)")
    print("=" * 60)

    # ë°ì´í„° ì¤€ë¹„
    data = load_dashboard_data()
    kg = build_knowledge_graph_from_dashboard(data)
    reasoner = OntologyReasoner(kg)
    register_all_rules(reasoner)

    # ì¶”ë¡  ì‹¤í–‰
    inference_context = {
        "brand": "LANEIGE",
        "is_target": True,
        "sos": 0.023,
        "hhi": 0.02,
        "category": "lip_care",
        "cpi": 212.0,
        "current_rank": 3
    }

    inferences = reasoner.infer(inference_context)
    print(f"\nì¶”ë¡  ê²°ê³¼: {len(inferences)}ê°œ")

    # HybridContext êµ¬ì„±
    hybrid_context = HybridContext(
        query="LANEIGE ì‹œì¥ ë¶„ì„",
        inferences=inferences,
        rag_chunks=[],
        ontology_facts=[]
    )

    # ì»¨í…ìŠ¤íŠ¸ ë¹Œë“œ
    builder = ContextBuilder()
    system_prompt = builder.build_system_prompt(hybrid_context)
    user_prompt = builder.build_user_prompt("ì‹œì¥ ë¶„ì„í•´ì¤˜", hybrid_context)

    print("\n" + "-" * 40)
    print("ğŸ“ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì²˜ìŒ 500ì)")
    print("-" * 40)
    print(system_prompt[:500] + "...")

    print("\n" + "-" * 40)
    print("ğŸ“ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (ì²˜ìŒ 500ì)")
    print("-" * 40)
    print(user_prompt[:500] + "...")

    return True


async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    # 1. ì»¨í…ìŠ¤íŠ¸ ë¹Œë” í…ŒìŠ¤íŠ¸ (LLM ì—†ì´)
    await test_context_builder_only()

    # 2. LLM ì—°ë™ í…ŒìŠ¤íŠ¸
    print("\n\n")
    success = await test_hybrid_insight_agent_with_llm()

    print("\n" + "=" * 60)
    if success:
        print("âœ… LLM ì—°ë™ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    else:
        print("âš ï¸  LLM ì—°ë™ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (API í‚¤ í™•ì¸ í•„ìš”)")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
