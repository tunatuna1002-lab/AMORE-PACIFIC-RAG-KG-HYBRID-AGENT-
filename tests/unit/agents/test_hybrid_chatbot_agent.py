"""
TDD Phase 2: HybridChatbotAgent í…ŒìŠ¤íŠ¸ (RED â†’ GREEN)

í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: src/agents/hybrid_chatbot_agent.py
"""

from typing import Any
from unittest.mock import AsyncMock, MagicMock, patch

import pytest


class TestHybridChatbotAgentInit:
    """HybridChatbotAgent ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""

    def test_init_with_defaults(self):
        """ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™” ê°€ëŠ¥í•´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        assert agent.model == "gpt-4.1-mini"
        assert agent.kg is not None
        assert agent.reasoner is not None
        assert agent.hybrid_retriever is not None

    def test_init_with_custom_model(self):
        """ì»¤ìŠ¤í…€ ëª¨ë¸ëª…ìœ¼ë¡œ ì´ˆê¸°í™” ê°€ëŠ¥í•´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(model="gpt-4")
        assert agent.model == "gpt-4"

    def test_init_with_injected_knowledge_graph(self):
        """ì£¼ì…ëœ KnowledgeGraph ì‚¬ìš©í•´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent
        from src.ontology.knowledge_graph import KnowledgeGraph

        mock_kg = KnowledgeGraph()
        agent = HybridChatbotAgent(knowledge_graph=mock_kg)

        assert agent.kg is mock_kg


class TestHybridChatbotAgentChat:
    """HybridChatbotAgent.chat() í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_kg(self):
        """Mock KnowledgeGraph"""
        kg = MagicMock()
        kg.query.return_value = []
        kg.get_entities_by_type.return_value = []
        return kg

    @pytest.fixture
    def mock_reasoner(self):
        """Mock OntologyReasoner"""
        reasoner = MagicMock()
        reasoner.infer.return_value = []
        reasoner.rules = ["rule1"]
        return reasoner

    @pytest.fixture
    def sample_data(self) -> dict[str, Any]:
        """ìƒ˜í”Œ ë°ì´í„°"""
        return {
            "date": "2026-01-23",
            "categories": {
                "lip_care": {
                    "total_products": 100,
                    "laneige_count": 3,
                    "sos": 0.15,
                    "brands": {"LANEIGE": {"count": 3, "sos": 0.15}},
                }
            },
        }

    @pytest.mark.asyncio
    async def test_chat_returns_dict_with_required_keys(self, mock_kg, mock_reasoner):
        """chat()ëŠ” í•„ìˆ˜ í‚¤ë¥¼ í¬í•¨í•œ dict ë°˜í™˜í•´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion", new_callable=AsyncMock
        ) as mock_llm:
            mock_llm.return_value = MagicMock(
                choices=[MagicMock(message=MagicMock(content="Test response"))]
            )

            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            # router.route ëª¨í‚¹
            with patch.object(agent.router, "route") as mock_route:
                mock_route.return_value = {
                    "query_type": "METRIC",
                    "entities": {"brands": ["LANEIGE"]},
                }

                # hybrid_retriever.retrieve ëª¨í‚¹
                with patch.object(
                    agent.hybrid_retriever, "retrieve", new_callable=AsyncMock
                ) as mock_retrieve:
                    mock_context = MagicMock()
                    mock_context.entities = {}
                    mock_context.ontology_facts = []
                    mock_context.inferences = []
                    mock_context.rag_chunks = []
                    mock_retrieve.return_value = mock_context

                    result = await agent.chat("LANEIGE ê²½ìŸë ¥ì€?")

        assert isinstance(result, dict)
        assert "response" in result

    @pytest.mark.asyncio
    async def test_chat_response_is_string(self, mock_kg, mock_reasoner):
        """ì‘ë‹µì€ ë¬¸ìì—´ì´ì–´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion", new_callable=AsyncMock
        ) as mock_llm:
            mock_llm.return_value = MagicMock(
                choices=[MagicMock(message=MagicMock(content="ë¼ë„¤ì¦ˆì˜ ê²½ìŸë ¥ ë¶„ì„ì…ë‹ˆë‹¤."))]
            )

            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            with patch.object(agent.router, "route") as mock_route:
                mock_route.return_value = {"query_type": "METRIC"}

                with patch.object(
                    agent.hybrid_retriever, "retrieve", new_callable=AsyncMock
                ) as mock_retrieve:
                    mock_context = MagicMock()
                    mock_context.entities = {}
                    mock_context.ontology_facts = []
                    mock_context.inferences = []
                    mock_context.rag_chunks = []
                    mock_retrieve.return_value = mock_context

                    result = await agent.chat("LANEIGE ë¶„ì„")

        assert isinstance(result["response"], str)
        assert len(result["response"]) > 0

    @pytest.mark.asyncio
    async def test_chat_uses_hybrid_retrieval(self, mock_kg, mock_reasoner):
        """ì¿¼ë¦¬ ì‹œ HybridRetrieverë¥¼ ì‚¬ìš©í•´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion", new_callable=AsyncMock
        ) as mock_llm:
            mock_llm.return_value = MagicMock(
                choices=[MagicMock(message=MagicMock(content="Response"))]
            )

            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            with patch.object(agent.router, "route") as mock_route:
                mock_route.return_value = {"query_type": "METRIC"}

                with patch.object(
                    agent.hybrid_retriever, "retrieve", new_callable=AsyncMock
                ) as mock_retrieve:
                    mock_context = MagicMock()
                    mock_context.entities = {}
                    mock_context.ontology_facts = []
                    mock_context.inferences = []
                    mock_context.rag_chunks = []
                    mock_retrieve.return_value = mock_context

                    await agent.chat("SoS ë¶„ì„")

                    mock_retrieve.assert_called_once()

    @pytest.mark.asyncio
    async def test_chat_includes_sources_when_available(self, mock_kg, mock_reasoner):
        """RAG ì²­í¬ê°€ ìˆìœ¼ë©´ sourcesì— í¬í•¨í•´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion", new_callable=AsyncMock
        ) as mock_llm:
            mock_llm.return_value = MagicMock(
                choices=[MagicMock(message=MagicMock(content="Response"))]
            )

            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            with patch.object(agent.router, "route") as mock_route:
                mock_route.return_value = {"query_type": "DEFINITION"}

                with patch.object(
                    agent.hybrid_retriever, "retrieve", new_callable=AsyncMock
                ) as mock_retrieve:
                    mock_context = MagicMock()
                    mock_context.entities = {}
                    mock_context.ontology_facts = []
                    mock_context.inferences = []
                    mock_context.rag_chunks = [{"source": "guide1.md", "content": "Content 1"}]
                    mock_retrieve.return_value = mock_context

                    result = await agent.chat("ê°€ì´ë“œ ê²€ìƒ‰")

        assert "sources" in result


class TestHybridChatbotAgentErrorHandling:
    """HybridChatbotAgent ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_kg(self):
        return MagicMock()

    @pytest.fixture
    def mock_reasoner(self):
        reasoner = MagicMock()
        reasoner.rules = ["rule1"]
        return reasoner

    @pytest.mark.asyncio
    async def test_chat_handles_unknown_query_type(self, mock_kg, mock_reasoner):
        """ì•Œ ìˆ˜ ì—†ëŠ” ì¿¼ë¦¬ íƒ€ì…ì€ fallback ì‘ë‹µ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent
        from src.rag.router import QueryType

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        with patch.object(agent.router, "route") as mock_route:
            mock_route.return_value = {
                "query_type": QueryType.UNKNOWN,
                "fallback_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            }

            result = await agent.chat("")

            assert "response" in result
            assert result.get("is_fallback", False) is True

    @pytest.mark.asyncio
    async def test_chat_handles_llm_failure_gracefully(self, mock_kg, mock_reasoner):
        """LLM ì‹¤íŒ¨ ì‹œ graceful degradation (ì—ëŸ¬ ì‘ë‹µ ë°˜í™˜)"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion",
            new_callable=AsyncMock,
            side_effect=Exception("LLM API failed"),
        ):
            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            with patch.object(agent.router, "route") as mock_route:
                mock_route.return_value = {"query_type": "METRIC"}

                with patch.object(
                    agent.hybrid_retriever, "retrieve", new_callable=AsyncMock
                ) as mock_retrieve:
                    mock_context = MagicMock()
                    mock_context.entities = {}
                    mock_context.ontology_facts = []
                    mock_context.inferences = []
                    mock_context.rag_chunks = []
                    mock_retrieve.return_value = mock_context

                    # ì—ëŸ¬ ì‹œì—ë„ ì‘ë‹µ ë°˜í™˜ (graceful degradation)
                    result = await agent.chat("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬")
                    assert "response" in result


class TestHybridChatbotAgentQueryRouting:
    """HybridChatbotAgent ì¿¼ë¦¬ ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸"""

    def test_router_exists(self):
        """ì—ì´ì „íŠ¸ì— ë¼ìš°í„°ê°€ ìˆì–´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        assert hasattr(agent, "router")
        assert agent.router is not None


class TestHybridChatbotAgentSuggestions:
    """HybridChatbotAgent í›„ì† ì§ˆë¬¸ ì œì•ˆ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_kg(self):
        return MagicMock()

    @pytest.fixture
    def mock_reasoner(self):
        reasoner = MagicMock()
        reasoner.rules = ["rule1"]
        return reasoner

    @pytest.mark.asyncio
    async def test_chat_returns_suggestions(self, mock_kg, mock_reasoner):
        """ì‘ë‹µì— í›„ì† ì§ˆë¬¸ ì œì•ˆì´ í¬í•¨ë˜ì–´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion", new_callable=AsyncMock
        ) as mock_llm:
            mock_llm.return_value = MagicMock(
                choices=[MagicMock(message=MagicMock(content="Response"))]
            )

            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            with patch.object(agent.router, "route") as mock_route:
                mock_route.return_value = {"query_type": "METRIC"}

                with patch.object(
                    agent.hybrid_retriever, "retrieve", new_callable=AsyncMock
                ) as mock_retrieve:
                    mock_context = MagicMock()
                    mock_context.entities = {}
                    mock_context.ontology_facts = []
                    mock_context.inferences = []
                    mock_context.rag_chunks = []
                    mock_retrieve.return_value = mock_context

                    result = await agent.chat("LANEIGE ë¶„ì„")

        # suggestionsê°€ ìˆì„ ìˆ˜ ìˆìŒ
        if "suggestions" in result:
            assert isinstance(result["suggestions"], list)


class TestHybridChatbotAgentDataContext:
    """HybridChatbotAgent ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸"""

    def test_set_data_context(self):
        """ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ê°€ëŠ¥í•´ì•¼ í•¨"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        data = {"date": "2026-01-23", "categories": {}}
        agent.set_data_context(data)

        assert agent._current_data == data


class TestHybridChatbotAgentGenerateResponse:
    """_generate_response ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_kg(self):
        kg = MagicMock()
        kg.get_category_hierarchy.return_value = {"error": "not_found"}
        return kg

    @pytest.fixture
    def mock_reasoner(self):
        reasoner = MagicMock()
        reasoner.rules = ["rule1"]
        return reasoner

    @pytest.mark.asyncio
    async def test_generate_response_with_valid_llm_response(self, mock_kg, mock_reasoner):
        """LLM ì‘ë‹µì´ ì •ìƒì¸ ê²½ìš°"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent
        from src.rag.router import QueryType

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion", new_callable=AsyncMock
        ) as mock_llm:
            mock_response = MagicMock()
            mock_response.choices = [
                MagicMock(message=MagicMock(content="LANEIGEëŠ” ê°•ë ¥í•œ ê²½ìŸë ¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤."))
            ]
            mock_response.usage = MagicMock(prompt_tokens=100, completion_tokens=50)
            mock_llm.return_value = mock_response

            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            result = await agent._generate_response(
                user_message="LANEIGE ê²½ìŸë ¥ì€?",
                query_type=QueryType.ANALYSIS,
                context="í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸",
                inferences=[],
            )

            assert isinstance(result, str)
            assert len(result) > 0
            mock_llm.assert_called_once()

    @pytest.mark.asyncio
    async def test_generate_response_with_llm_failure(self, mock_kg, mock_reasoner):
        """LLM ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent
        from src.rag.router import QueryType

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion",
            new_callable=AsyncMock,
            side_effect=Exception("API Error"),
        ):
            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            result = await agent._generate_response(
                user_message="Test",
                query_type=QueryType.ANALYSIS,
                context="Test context",
                inferences=[],
            )

            assert isinstance(result, str)
            assert "ì£„ì†¡í•©ë‹ˆë‹¤" in result or "ì‘ë‹µ" in result

    @pytest.mark.asyncio
    async def test_generate_response_with_inferences(self, mock_kg, mock_reasoner):
        """ì¶”ë¡  ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent
        from src.domain.entities.relations import InferenceResult, InsightType
        from src.rag.router import QueryType

        with patch(
            "src.agents.hybrid_chatbot_agent.acompletion", new_callable=AsyncMock
        ) as mock_llm:
            mock_response = MagicMock()
            mock_response.choices = [
                MagicMock(message=MagicMock(content="Analysis with inference"))
            ]
            mock_response.usage = MagicMock(prompt_tokens=100, completion_tokens=50)
            mock_llm.return_value = mock_response

            agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

            inference = InferenceResult(
                rule_name="test_rule",
                insight_type=InsightType.COMPETITIVE_THREAT,
                insight="ê²½ìŸì´ ì¹˜ì—´í•©ë‹ˆë‹¤",
                confidence=0.9,
                evidence=[],
                recommendation="ëª¨ë‹ˆí„°ë§ í•„ìš”",
            )

            result = await agent._generate_response(
                user_message="Test",
                query_type=QueryType.ANALYSIS,
                context="Test context",
                inferences=[inference],
            )

            assert isinstance(result, str)


class TestHybridChatbotAgentBrandNormalization:
    """ë¸Œëœë“œëª… ì •ê·œí™” í…ŒìŠ¤íŠ¸"""

    def test_normalize_brand_with_truncated_name(self):
        """ì˜ë¦° ë¸Œëœë“œëª…ì„ ì •ê·œí™”"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        assert agent._normalize_brand("burt's") == "Burt's Bees"
        assert agent._normalize_brand("wet") == "wet n wild"
        assert agent._normalize_brand("the") == "The Ordinary"

    def test_normalize_brand_with_unknown_brand(self):
        """ì•Œ ìˆ˜ ì—†ëŠ” ë¸Œëœë“œëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        assert agent._normalize_brand("RandomBrand") == "RandomBrand"

    def test_normalize_response_brands(self):
        """ì‘ë‹µ ë‚´ ë¸Œëœë“œëª… ì •ê·œí™”"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        response = "Burt's ì œí’ˆì´ ì¸ê¸°ì…ë‹ˆë‹¤."
        normalized = agent._normalize_response_brands(response)

        assert "Burt's Bees" in normalized


class TestHybridChatbotAgentSuggestionGeneration:
    """í›„ì† ì§ˆë¬¸ ì œì•ˆ ìƒì„± í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_kg(self):
        kg = MagicMock()
        kg.get_related_brands.return_value = ["CeraVe", "La Roche-Posay"]
        return kg

    @pytest.fixture
    def mock_reasoner(self):
        reasoner = MagicMock()
        reasoner.rules = ["rule1"]
        return reasoner

    def test_generate_suggestions_with_entities(self, mock_kg, mock_reasoner):
        """ì—”í‹°í‹° ê¸°ë°˜ ì œì•ˆ ìƒì„±"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent
        from src.rag.router import QueryType

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        entities = {"brands": ["LANEIGE"], "categories": ["Lip Care"], "indicators": ["SoS"]}

        suggestions = agent._generate_suggestions(
            query_type=QueryType.ANALYSIS,
            entities=entities,
            inferences=[],
            response="LANEIGEì˜ ì‹œì¥ ì ìœ ìœ¨ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        )

        assert isinstance(suggestions, list)
        assert len(suggestions) <= 3
        assert all(isinstance(s, str) for s in suggestions)

    def test_extract_response_keywords(self, mock_kg, mock_reasoner):
        """ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        response = "ìˆœìœ„ê°€ í•˜ë½í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²½ìŸì‚¬ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤."
        keywords = agent._extract_response_keywords(response)

        assert isinstance(keywords, list)
        assert len(keywords) <= 2

    def test_generate_entity_suggestions(self, mock_kg, mock_reasoner):
        """ì—”í‹°í‹° ê¸°ë°˜ ì œì•ˆ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        entities = {"brands": ["LANEIGE"], "categories": ["Lip Care"]}
        suggestions = agent._generate_entity_suggestions(entities)

        assert isinstance(suggestions, list)

    def test_get_fallback_suggestions(self, mock_kg, mock_reasoner):
        """í´ë°± ì œì•ˆ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        suggestions = agent._get_fallback_suggestions()

        assert isinstance(suggestions, list)
        assert len(suggestions) == 3


class TestHybridChatbotAgentSourceExtraction:
    """ì¶œì²˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_kg(self):
        kg = MagicMock()
        kg.get_category_hierarchy.return_value = {
            "name": "Lip Care",
            "level": 2,
            "ancestors": [{"name": "Skin Care"}, {"name": "Beauty"}],
            "descendants": [],
        }
        return kg

    @pytest.fixture
    def mock_reasoner(self):
        reasoner = MagicMock()
        reasoner.rules = ["rule1"]
        return reasoner

    @pytest.fixture
    def sample_hybrid_context(self):
        """ìƒ˜í”Œ í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…ìŠ¤íŠ¸"""
        from src.domain.entities.relations import InferenceResult, InsightType

        context = MagicMock()
        context.entities = {"brands": ["LANEIGE"], "categories": ["Lip Care"]}
        context.ontology_facts = [
            {"subject": "LANEIGE", "predicate": "competes_with", "object": "CeraVe"}
        ]
        context.inferences = [
            InferenceResult(
                rule_name="competitive_analysis",
                insight_type=InsightType.COMPETITIVE_THREAT,
                insight="ê²½ìŸ ì‹¬í™”",
                confidence=0.85,
                evidence=["fact1"],
                recommendation="ëª¨ë‹ˆí„°ë§",
            )
        ]
        context.rag_chunks = [
            {
                "content": "Test content",
                "metadata": {
                    "doc_id": "doc1",
                    "title": "ê°€ì´ë“œë¼ì¸",
                    "file_path": "/path/to/guide.md",
                    "section": "Section 1",
                },
                "score": 0.92,
            }
        ]
        return context

    def test_extract_sources_with_crawled_data(self, mock_kg, mock_reasoner, sample_hybrid_context):
        """í¬ë¡¤ë§ ë°ì´í„° ì¶œì²˜ ì¶”ì¶œ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)
        agent._current_data = {
            "metadata": {"data_date": "2026-01-23"},
            "categories": {
                "lip_care": {
                    "rank_records": [
                        {
                            "asin": "B001TEST",
                            "brand": "LANEIGE",
                            "product_name": "Lip Sleeping Mask",
                            "rank": 4,
                        }
                    ]
                }
            },
        }

        sources = agent._extract_sources(sample_hybrid_context, external_signals=[])

        assert isinstance(sources, list)
        assert len(sources) > 0
        assert any(s["type"] == "crawled_data" for s in sources)
        assert any(s["type"] == "ai_model" for s in sources)

    def test_extract_sources_with_kg_facts(self, mock_kg, mock_reasoner, sample_hybrid_context):
        """KG íŒ©íŠ¸ ì¶œì²˜ ì¶”ì¶œ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        sources = agent._extract_sources(sample_hybrid_context, external_signals=[])

        kg_sources = [s for s in sources if s["type"] == "knowledge_graph"]
        assert len(kg_sources) > 0
        assert kg_sources[0]["fact_count"] > 0

    def test_extract_sources_with_inferences(self, mock_kg, mock_reasoner, sample_hybrid_context):
        """ì¶”ë¡  ê²°ê³¼ ì¶œì²˜ ì¶”ì¶œ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        sources = agent._extract_sources(sample_hybrid_context, external_signals=[])

        inference_sources = [s for s in sources if s["type"] == "ontology_inference"]
        assert len(inference_sources) > 0
        assert inference_sources[0]["confidence"] == 0.85

    def test_extract_sources_with_rag_chunks(self, mock_kg, mock_reasoner, sample_hybrid_context):
        """RAG ì²­í¬ ì¶œì²˜ ì¶”ì¶œ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        sources = agent._extract_sources(sample_hybrid_context, external_signals=[])

        rag_sources = [s for s in sources if s["type"] == "rag_document"]
        assert len(rag_sources) > 0
        assert rag_sources[0]["relevance_score"] == 0.92

    def test_format_sources_for_response(self, mock_kg, mock_reasoner):
        """ì¶œì²˜ í¬ë§·íŒ…"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        sources = [
            {
                "type": "crawled_data",
                "icon": "ğŸ“Š",
                "description": "Amazon ë°ì´í„°",
                "collected_at": "2026-01-23",
                "url": "https://amazon.com",
                "details": {"total_products": 100},
            },
            {
                "type": "ai_model",
                "icon": "ğŸ¤–",
                "description": "AI ë¶„ì„",
                "model": "gpt-4.1-mini",
                "disclaimer": "AI ìƒì„±",
            },
        ]

        formatted = agent._format_sources_for_response(sources)

        assert isinstance(formatted, str)
        assert "ğŸ“Š" in formatted
        assert "ğŸ¤–" in formatted
        assert "ì¶œì²˜" in formatted

    def test_extract_entity_names(self, mock_kg, mock_reasoner):
        """ì—”í‹°í‹° ì´ë¦„ ì¶”ì¶œ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        facts = [
            {"subject": "LANEIGE", "predicate": "competes_with", "object": "CeraVe"},
            {"subject": "CeraVe", "predicate": "has_product", "object": "Moisturizer"},
        ]

        entities = agent._extract_entity_names(facts)

        assert isinstance(entities, list)
        assert "LANEIGE" in entities
        assert "CeraVe" in entities
        assert len(entities) <= 5

    def test_extract_relation_types(self, mock_kg, mock_reasoner):
        """ê´€ê³„ íƒ€ì… ì¶”ì¶œ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        facts = [
            {"subject": "LANEIGE", "predicate": "competes_with", "object": "CeraVe"},
            {"subject": "CeraVe", "predicate": "has_product", "object": "Moisturizer"},
        ]

        relations = agent._extract_relation_types(facts)

        assert isinstance(relations, list)
        assert "competes_with" in relations
        assert "has_product" in relations


class TestHybridChatbotAgentExternalSignals:
    """ì™¸ë¶€ ì‹ í˜¸ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_kg(self):
        return MagicMock()

    @pytest.fixture
    def mock_reasoner(self):
        reasoner = MagicMock()
        reasoner.rules = ["rule1"]
        return reasoner

    @pytest.mark.asyncio
    async def test_collect_external_signals_with_entities(self, mock_kg, mock_reasoner):
        """ì—”í‹°í‹°ê°€ ìˆëŠ” ê²½ìš° ì™¸ë¶€ ì‹ í˜¸ ìˆ˜ì§‘"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)

        # Mock external signal collector
        mock_collector = MagicMock()
        mock_collector.fetch_tavily_news = AsyncMock(return_value=[])
        mock_collector.fetch_all_rss_feeds = AsyncMock(return_value=[])
        agent._external_signal_collector = mock_collector

        entities = {"brands": ["LANEIGE"], "categories": ["Lip Care"]}

        signals = await agent._collect_external_signals("LANEIGE ë‰´ìŠ¤", entities)

        assert isinstance(signals, list)

    @pytest.mark.asyncio
    async def test_collect_external_signals_without_collector(self, mock_kg, mock_reasoner):
        """ìˆ˜ì§‘ê¸°ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent(knowledge_graph=mock_kg, reasoner=mock_reasoner)
        agent._external_signal_collector = None

        with patch(
            "src.tools.collectors.external_signal_collector.ExternalSignalCollector",
            side_effect=ImportError("mocked"),
        ):
            signals = await agent._collect_external_signals("test", None)

            assert isinstance(signals, list)
            assert len(signals) == 0


class TestHybridChatbotAgentConversation:
    """ëŒ€í™” ê´€ë¦¬ í…ŒìŠ¤íŠ¸"""

    def test_get_conversation_history(self):
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        history = agent.get_conversation_history(limit=5)

        assert isinstance(history, list)

    def test_clear_conversation(self):
        """ëŒ€í™” ì´ˆê¸°í™”"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        agent.clear_conversation()

        history = agent.get_conversation_history()
        assert len(history) == 0

    @pytest.mark.asyncio
    async def test_maybe_rewrite_query_without_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì—†ìœ¼ë©´ ì¬êµ¬ì„± ìŠ¤í‚µ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        result = await agent._maybe_rewrite_query("LANEIGE ë¶„ì„")

        assert result.was_rewritten is False
        assert result.rewritten_query == "LANEIGE ë¶„ì„"


class TestHybridChatbotAgentUtilities:
    """ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""

    def test_estimate_cost(self):
        """ë¹„ìš© ì¶”ì •"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        cost = agent._estimate_cost(prompt_tokens=1000, completion_tokens=500)

        assert isinstance(cost, float)
        assert cost > 0

    def test_get_knowledge_graph(self):
        """KG ë°˜í™˜"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        kg = agent.get_knowledge_graph()

        assert kg is not None

    def test_get_reasoner(self):
        """ì¶”ë¡ ê¸° ë°˜í™˜"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        reasoner = agent.get_reasoner()

        assert reasoner is not None

    def test_get_last_hybrid_context(self):
        """ë§ˆì§€ë§‰ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        context = agent.get_last_hybrid_context()

        assert context is None  # ì´ˆê¸° ìƒíƒœ

    @pytest.mark.asyncio
    async def test_explain_last_response_without_context(self):
        """ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì„¤ëª… ì—†ìŒ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotAgent

        agent = HybridChatbotAgent()

        explanation = await agent.explain_last_response()

        assert "ì—†ìŠµë‹ˆë‹¤" in explanation


class TestHybridChatbotSession:
    """HybridChatbotSession í…ŒìŠ¤íŠ¸"""

    def test_session_get_or_create(self):
        """ì„¸ì…˜ ìƒì„± ë˜ëŠ” ì¡°íšŒ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotSession

        session_manager = HybridChatbotSession()

        agent1 = session_manager.get_or_create("session1")
        agent2 = session_manager.get_or_create("session1")

        assert agent1 is agent2

    def test_session_close(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotSession

        session_manager = HybridChatbotSession()

        session_manager.get_or_create("session1")
        session_manager.close_session("session1")

        sessions = session_manager.list_sessions()
        assert "session1" not in sessions

    def test_session_list(self):
        """ì„¸ì…˜ ëª©ë¡"""
        from src.agents.hybrid_chatbot_agent import HybridChatbotSession

        session_manager = HybridChatbotSession()

        session_manager.get_or_create("session1")
        session_manager.get_or_create("session2")

        sessions = session_manager.list_sessions()

        assert len(sessions) == 2
        assert "session1" in sessions
        assert "session2" in sessions
