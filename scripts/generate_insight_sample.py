#!/usr/bin/env python3
"""
ì¸ì‚¬ì´íŠ¸ ìƒ˜í”Œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
HybridInsightAgentë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì¸ì‚¬ì´íŠ¸ ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv

load_dotenv(PROJECT_ROOT / ".env")

from src.agents.hybrid_insight_agent import HybridInsightAgent
from src.domain.entities.relations import Relation, RelationType
from src.ontology.business_rules import register_all_rules
from src.ontology.knowledge_graph import KnowledgeGraph
from src.ontology.reasoner import OntologyReasoner


def load_dashboard_data() -> dict:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ"""
    data_path = PROJECT_ROOT / "data" / "dashboard_data.json"
    if not data_path.exists():
        print(f"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        print("ê¸°ë³¸ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        return create_sample_data()

    with open(data_path, encoding="utf-8") as f:
        return json.load(f)


def create_sample_data() -> dict:
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    return {
        "brand": {
            "kpis": {"hhi": 0.12},
            "competitors": [
                {"brand": "LANEIGE", "sos": 6.2, "avg_rank": 12, "product_count": 6},
                {"brand": "COSRX", "sos": 8.5, "avg_rank": 9, "product_count": 7},
                {"brand": "TIRTIR", "sos": 5.1, "avg_rank": 18, "product_count": 4},
                {"brand": "Beauty of Joseon", "sos": 7.3, "avg_rank": 11, "product_count": 5},
            ],
        },
        "categories": {"lip_care": {"sos": 6.2, "cpi": 135}, "skin_care": {"sos": 4.4, "cpi": 120}},
        "products": {
            "B000TEST01": {
                "name": "LANEIGE Lip Sleeping Mask",
                "category": "lip_care",
                "rank": 7,
                "rating": 4.6,
                "volatility": 2.1,
            },
            "B000TEST02": {
                "name": "LANEIGE Water Bank Cream",
                "category": "skin_care",
                "rank": 18,
                "rating": 4.5,
                "volatility": 3.0,
            },
            "B000TEST03": {
                "name": "LANEIGE Lip Glowy Balm",
                "category": "lip_care",
                "rank": 15,
                "rating": 4.4,
                "volatility": 1.8,
            },
        },
    }


def build_metrics_data_from_dashboard(data: dict) -> dict:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„°ì—ì„œ ë©”íŠ¸ë¦­ ë°ì´í„° êµ¬ì„±"""
    brand_kpis = data.get("brand", {}).get("kpis", {})
    categories = data.get("categories", {})
    products = data.get("products", {})
    competitors = data.get("brand", {}).get("competitors", [])

    # ë¸Œëœë“œ ë©”íŠ¸ë¦­
    brand_metrics = []
    for comp in competitors:
        brand_metrics.append(
            {
                "brand_name": comp.get("brand"),
                "share_of_shelf": comp.get("sos", 0) / 100,
                "avg_rank": comp.get("avg_rank"),
                "product_count": comp.get("product_count"),
                "is_laneige": comp.get("brand", "").upper() == "LANEIGE",
            }
        )

    # ì œí’ˆ ë©”íŠ¸ë¦­
    product_metrics = []
    for asin, product in products.items():
        product_metrics.append(
            {
                "asin": asin,
                "product_title": product.get("name", ""),
                "category_id": product.get("category"),
                "current_rank": product.get("rank"),
                "rank_change_1d": 0,
                "rank_change_7d": -2,  # ìƒ˜í”Œ: 7ì¼ ì „ ëŒ€ë¹„ 2ìœ„ ìƒìŠ¹
                "rating": product.get("rating"),
                "rank_volatility": product.get("volatility", 0),
            }
        )

    # ë§ˆì¼“ ë©”íŠ¸ë¦­
    market_metrics = []
    for cat_id, cat_data in categories.items():
        market_metrics.append(
            {
                "category_id": cat_id,
                "hhi": brand_kpis.get("hhi", 0.02),
                "cpi": cat_data.get("cpi", 100),
                "avg_rating_gap": 0.1,
            }
        )

    # ì„œë¨¸ë¦¬
    summary = {
        "laneige_products_tracked": len(product_metrics),
        "laneige_sos_by_category": {
            cat_id: cat_data.get("sos", 0) / 100 for cat_id, cat_data in categories.items()
        },
        "alert_count": 0,
    }

    return {
        "summary": summary,
        "brand_metrics": brand_metrics,
        "product_metrics": product_metrics,
        "market_metrics": market_metrics,
        "alerts": [],
    }


def build_knowledge_graph_from_dashboard(data: dict) -> KnowledgeGraph:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„°ì—ì„œ KG êµ¬ì¶•"""
    kg = KnowledgeGraph()

    # ì œí’ˆ ì •ë³´
    products = data.get("products", {})
    for asin, product in products.items():
        brand = "LANEIGE"
        category = product.get("category", "unknown")

        # Brand â†’ Product
        kg.add_relation(
            Relation(
                subject=brand,
                predicate=RelationType.HAS_PRODUCT,
                object=asin,
                properties={
                    "product_name": product.get("name", "")[:50],
                    "rank": product.get("rank"),
                    "category": category,
                },
            )
        )

        # Product â†’ Category
        kg.add_relation(
            Relation(
                subject=asin,
                predicate=RelationType.BELONGS_TO_CATEGORY,
                object=category,
                properties={"rank": product.get("rank")},
            )
        )

    # ê²½ìŸì‚¬ ì •ë³´
    competitors = data.get("brand", {}).get("competitors", [])
    for comp in competitors:
        brand_name = comp.get("brand", "")
        is_laneige = brand_name.upper() == "LANEIGE"

        kg.set_entity_metadata(
            brand_name,
            {
                "type": "brand",
                "sos": comp.get("sos", 0) / 100,
                "avg_rank": comp.get("avg_rank"),
                "product_count": comp.get("product_count"),
                "is_target": is_laneige,
            },
        )

        if not is_laneige:
            kg.add_relation(
                Relation(
                    subject="LANEIGE",
                    predicate=RelationType.COMPETES_WITH,
                    object=brand_name,
                    properties={"competitor_sos": comp.get("sos", 0) / 100},
                )
            )

    return kg


async def generate_insight_sample():
    """ì¸ì‚¬ì´íŠ¸ ìƒ˜í”Œ ìƒì„±"""
    print("=" * 80)
    print("ğŸ“Š ì¸ì‚¬ì´íŠ¸ ìƒ˜í”Œ ìƒì„±")
    print(f"   ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key.startswith("sk-your"):
        print("\nâš ï¸  OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±ì€ ìŠ¤í‚µë˜ê³ , ì¶”ë¡  ê²°ê³¼ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
        use_llm = False
    else:
        print(f"\nâœ… OPENAI_API_KEY í™•ì¸ë¨ (ë§ˆì§€ë§‰ 4ìë¦¬: ...{api_key[-4:]})")
        use_llm = True

    # 1. ë°ì´í„° ë¡œë“œ
    print("\nğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    data = load_dashboard_data()
    metrics_data = build_metrics_data_from_dashboard(data)
    print(f"   - ì œí’ˆ ë©”íŠ¸ë¦­: {len(metrics_data['product_metrics'])}ê°œ")
    print(f"   - ë¸Œëœë“œ ë©”íŠ¸ë¦­: {len(metrics_data['brand_metrics'])}ê°œ")
    print(f"   - ì¹´í…Œê³ ë¦¬ ë©”íŠ¸ë¦­: {len(metrics_data['market_metrics'])}ê°œ")

    # 2. KG êµ¬ì¶•
    print("\nğŸ“ˆ Knowledge Graph êµ¬ì¶• ì¤‘...")
    kg = build_knowledge_graph_from_dashboard(data)
    stats = kg.get_stats()
    print(f"   - íŠ¸ë¦¬í”Œ: {stats.get('total_triples', len(kg.triples))}ê°œ")
    unique_subjects = stats.get("unique_subjects", 0)
    unique_objects = stats.get("unique_objects", 0)
    print(f"   - ì£¼ì²´ ì—”í‹°í‹°: {unique_subjects}ê°œ, ê°ì²´ ì—”í‹°í‹°: {unique_objects}ê°œ")

    # 3. Reasoner ì´ˆê¸°í™”
    print("\nğŸ§  Reasoner ì´ˆê¸°í™” ì¤‘...")
    reasoner = OntologyReasoner(kg)
    register_all_rules(reasoner)
    print(f"   - ê·œì¹™: {len(reasoner.rules)}ê°œ")

    # 4. HybridInsightAgent ìƒì„±
    print("\nğŸ”§ HybridInsightAgent ì´ˆê¸°í™” ì¤‘...")
    model = "gpt-4o-mini" if use_llm else None

    agent = HybridInsightAgent(
        model=model, knowledge_graph=kg, reasoner=reasoner, docs_dir=str(PROJECT_ROOT)
    )
    print(f"   - ëª¨ë¸: {model or 'N/A (ì¶”ë¡ ë§Œ)'}")

    # 5. ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤í–‰
    print("\n" + "=" * 80)
    print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤í–‰")
    print("=" * 80)

    try:
        result = await agent.execute(metrics_data=metrics_data, crawl_data=None, crawl_summary=None)

        print("\nâœ… ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"   - ìƒíƒœ: {result.get('status')}")
        print(f"   - ì¶”ë¡  ê²°ê³¼: {len(result.get('inferences', []))}ê°œ")
        print(f"   - ì•¡ì…˜ ì•„ì´í…œ: {len(result.get('action_items', []))}ê°œ")
        print(f"   - í•˜ì´ë¼ì´íŠ¸: {len(result.get('highlights', []))}ê°œ")

        # ì¼ì¼ ì¸ì‚¬ì´íŠ¸ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ“ ì¼ì¼ ì¸ì‚¬ì´íŠ¸")
        print("=" * 80)
        daily_insight = result.get("daily_insight", "")
        if daily_insight:
            print(daily_insight)
        else:
            print("(LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.)")

        # ì¶”ë¡  ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ” ì˜¨í†¨ë¡œì§€ ì¶”ë¡  ê²°ê³¼")
        print("=" * 80)
        inferences = result.get("inferences", [])
        if inferences:
            for i, inf in enumerate(inferences, 1):
                print(f"\n{i}. [{inf.get('insight_type', 'UNKNOWN')}]")
                print(f"   ê²°ë¡ : {inf.get('insight', 'N/A')}")
                if inf.get("recommendation"):
                    print(f"   ê¶Œì¥: {inf.get('recommendation')}")
                print(f"   ì‹ ë¢°ë„: {inf.get('confidence', 0):.0%}")
        else:
            print("(ì¶”ë¡  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.)")

        # ì•¡ì…˜ ì•„ì´í…œ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ“‹ ì•¡ì…˜ ì•„ì´í…œ")
        print("=" * 80)
        action_items = result.get("action_items", [])
        if action_items:
            for i, action in enumerate(action_items, 1):
                priority = action.get("priority", "low").upper()
                print(f"{i}. [{priority}] {action.get('action', 'N/A')}")
                if action.get("source"):
                    print(f"   ì†ŒìŠ¤: {action.get('source')}")
                if action.get("type"):
                    print(f"   ìœ í˜•: {action.get('type')}")
        else:
            print("(ì•¡ì…˜ ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤.)")

        # í•˜ì´ë¸Œë¦¬ë“œ í†µê³„
        print("\n" + "=" * 80)
        print("ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í†µê³„")
        print("=" * 80)
        hybrid_stats = result.get("hybrid_stats", {})
        print(f"   - KG ì—…ë°ì´íŠ¸: {hybrid_stats.get('kg_update', {})}")
        print(f"   - ì¶”ë¡  ê²°ê³¼: {hybrid_stats.get('inferences_count', 0)}ê°œ")
        print(f"   - RAG ì²­í¬: {hybrid_stats.get('rag_chunks_count', 0)}ê°œ")
        print(f"   - ì˜¨í†¨ë¡œì§€ ì‚¬ì‹¤: {hybrid_stats.get('ontology_facts_count', 0)}ê°œ")

        # ê²°ê³¼ ì €ì¥
        output_path = PROJECT_ROOT / "data" / "insight_sample.json"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

        # ë§ˆí¬ë‹¤ìš´ ìƒ˜í”Œ ìƒì„±
        markdown_path = PROJECT_ROOT / "data" / "insight_sample.md"
        with open(markdown_path, "w", encoding="utf-8") as f:
            f.write("# ì¸ì‚¬ì´íŠ¸ ìƒ˜í”Œ\n\n")
            f.write(f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("## ì¼ì¼ ì¸ì‚¬ì´íŠ¸\n\n")
            f.write(daily_insight or "(ì¸ì‚¬ì´íŠ¸ ì—†ìŒ)\n\n")
            f.write("\n## ì¶”ë¡  ê²°ê³¼\n\n")
            for i, inf in enumerate(inferences, 1):
                f.write(f"### {i}. {inf.get('insight_type', 'UNKNOWN')}\n\n")
                f.write(f"**ê²°ë¡ :** {inf.get('insight', 'N/A')}\n\n")
                if inf.get("recommendation"):
                    f.write(f"**ê¶Œì¥:** {inf.get('recommendation')}\n\n")
                f.write(f"**ì‹ ë¢°ë„:** {inf.get('confidence', 0):.0%}\n\n")
            f.write("\n## ì•¡ì…˜ ì•„ì´í…œ\n\n")
            for i, action in enumerate(action_items, 1):
                priority = action.get("priority", "low").upper()
                f.write(f"{i}. **[{priority}]** {action.get('action', 'N/A')}\n")
                if action.get("source"):
                    f.write(f"   - ì†ŒìŠ¤: {action.get('source')}\n")
        print(f"ğŸ“„ ë§ˆí¬ë‹¤ìš´ ìƒ˜í”Œ ì €ì¥: {markdown_path}")

        return True

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(generate_insight_sample())
    print("\n" + "=" * 80)
    if success:
        print("âœ… ì¸ì‚¬ì´íŠ¸ ìƒ˜í”Œ ìƒì„± ì™„ë£Œ")
    else:
        print("âš ï¸  ì¸ì‚¬ì´íŠ¸ ìƒ˜í”Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
    print("=" * 80)
