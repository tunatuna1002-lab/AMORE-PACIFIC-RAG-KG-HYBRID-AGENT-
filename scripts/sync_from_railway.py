#!/usr/bin/env python3
"""
Railway â†’ ë¡œì»¬ SQLite ë™ê¸°í™” ìŠ¤í¬ë¦½íŠ¸

Railway ì„œë²„ì˜ SQLite ë°ì´í„°ë¥¼ ë¡œì»¬ë¡œ ë™ê¸°í™”í•©ë‹ˆë‹¤.
ëˆ„ë½ëœ ë‚ ì§œë§Œ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

Usage:
    python scripts/sync_from_railway.py
    python scripts/sync_from_railway.py --force      # ì „ì²´ ì¬ë™ê¸°í™”
    python scripts/sync_from_railway.py --dry-run    # ì‹¤ì œ ë™ê¸°í™” ì—†ì´ í™•ì¸ë§Œ
    python scripts/sync_from_railway.py --url URL    # ì»¤ìŠ¤í…€ Railway URL

í™˜ê²½ë³€ìˆ˜:
    RAILWAY_API_URL: Railway API URL (ê¸°ë³¸ê°’: production URL)
"""

import argparse
import asyncio
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

import httpx

from src.tools.storage.sqlite_storage import SQLiteStorage

# Railway Production URL
DEFAULT_RAILWAY_URL = "https://amore-pacific-rag-kg-hybrid-agent-production.up.railway.app"


async def get_remote_dates(base_url: str) -> list[str]:
    """Railway ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ëª©ë¡ ì¡°íšŒ"""
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.get(f"{base_url}/api/sync/dates")
        response.raise_for_status()
        data = response.json()
        return data.get("dates", [])


async def get_remote_status(base_url: str) -> dict:
    """Railway ì„œë²„ì˜ ë°ì´í„° í˜„í™© ì¡°íšŒ"""
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.get(f"{base_url}/api/sync/status")
        response.raise_for_status()
        return response.json()


async def download_date_data(base_url: str, date: str) -> list[dict]:
    """íŠ¹ì • ë‚ ì§œì˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.get(f"{base_url}/api/sync/download/{date}")
        response.raise_for_status()
        data = response.json()
        return data.get("records", [])


async def get_local_dates(sqlite: SQLiteStorage) -> list[str]:
    """ë¡œì»¬ SQLiteì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ëª©ë¡ ì¡°íšŒ"""
    with sqlite.get_connection() as conn:
        cursor = conn.execute("""
            SELECT DISTINCT snapshot_date
            FROM raw_data
            ORDER BY snapshot_date
        """)
        return [row[0] for row in cursor.fetchall()]


async def sync_from_railway(
    base_url: str = DEFAULT_RAILWAY_URL, force: bool = False, dry_run: bool = False
) -> bool:
    """Railway â†’ ë¡œì»¬ SQLite ë™ê¸°í™” ì‹¤í–‰"""

    print("=" * 60)
    print("Railway â†’ Local SQLite ë™ê¸°í™”")
    print("=" * 60)
    print(f"\nRailway URL: {base_url}")

    # 1. Railway ìƒíƒœ í™•ì¸
    print("\n[1/4] Railway ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘...")
    try:
        remote_status = await get_remote_status(base_url)
        if not remote_status.get("success"):
            print("âŒ Railway ì„œë²„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

        print(f"âœ… Railway: {remote_status.get('total_days', 0)}ì¼ì¹˜ ë°ì´í„°")
        print(f"   ë‚ ì§œ ë²”ìœ„: {remote_status.get('oldest')} ~ {remote_status.get('latest')}")
        print(f"   ì´ ë ˆì½”ë“œ: {remote_status.get('total_records', 0):,}")
    except httpx.HTTPError as e:
        print(f"âŒ Railway ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

    # 2. ë¡œì»¬ SQLite ìƒíƒœ í™•ì¸
    print("\n[2/4] ë¡œì»¬ SQLite ìƒíƒœ í™•ì¸ ì¤‘...")
    sqlite = SQLiteStorage()
    if not await sqlite.initialize():
        print("âŒ SQLite ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False

    local_dates = await get_local_dates(sqlite)
    if local_dates:
        print(f"âœ… ë¡œì»¬: {len(local_dates)}ì¼ì¹˜ ë°ì´í„°")
        print(f"   ë‚ ì§œ ë²”ìœ„: {local_dates[0]} ~ {local_dates[-1]}")
    else:
        print("âš ï¸ ë¡œì»¬: ë°ì´í„° ì—†ìŒ")

    # 3. ëˆ„ë½ëœ ë‚ ì§œ í™•ì¸
    print("\n[3/4] ëˆ„ë½ëœ ë‚ ì§œ í™•ì¸ ì¤‘...")
    remote_dates = await get_remote_dates(base_url)
    local_dates_set = set(local_dates)
    remote_dates_set = set(remote_dates)

    if force:
        # ê°•ì œ ëª¨ë“œ: ëª¨ë“  ë‚ ì§œ ì¬ë™ê¸°í™”
        missing_dates = sorted(remote_dates)
        print(f"âš ï¸ ê°•ì œ ëª¨ë“œ: ëª¨ë“  {len(missing_dates)}ì¼ì¹˜ ë°ì´í„° ì¬ë™ê¸°í™”")
    else:
        # ì¼ë°˜ ëª¨ë“œ: ëˆ„ë½ëœ ë‚ ì§œë§Œ
        missing_dates = sorted(remote_dates_set - local_dates_set)

    if not missing_dates:
        print("âœ… ë™ê¸°í™” í•„ìš” ì—†ìŒ - ë¡œì»¬ ë°ì´í„°ê°€ ìµœì‹ ì…ë‹ˆë‹¤")
        return True

    print(f"ğŸ“¥ ëˆ„ë½ëœ ë‚ ì§œ: {len(missing_dates)}ì¼")
    for date in missing_dates:
        print(f"   - {date}")

    if dry_run:
        print("\n[DRY RUN] ì‹¤ì œ ë™ê¸°í™”ëŠ” ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        return True

    # 4. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì‚½ì…
    print("\n[4/4] ë°ì´í„° ë™ê¸°í™” ì¤‘...")
    total_synced = 0
    total_records = 0

    for i, date in enumerate(missing_dates, 1):
        try:
            print(f"   [{i}/{len(missing_dates)}] {date} ë‹¤ìš´ë¡œë“œ ì¤‘...", end=" ", flush=True)

            # ë‹¤ìš´ë¡œë“œ
            records = await download_date_data(base_url, date)
            if not records:
                print("âš ï¸ ë°ì´í„° ì—†ìŒ")
                continue

            # SQLite ì‚½ì…
            result = await sqlite.append_rank_records(records)
            if result.get("success"):
                rows_added = result.get("rows_added", 0)
                total_records += rows_added
                total_synced += 1
                print(f"âœ… {rows_added} records")
            else:
                print(f"âš ï¸ ì‚½ì… ì‹¤íŒ¨: {result.get('error')}")

        except httpx.HTTPError as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        except Exception as e:
            print(f"âŒ ì—ëŸ¬: {e}")

    # 5. ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ë™ê¸°í™” ì™„ë£Œ!")
    print("=" * 60)
    print("\nê²°ê³¼:")
    print(f"  - ë™ê¸°í™”ëœ ë‚ ì§œ: {total_synced}/{len(missing_dates)}")
    print(f"  - ì¶”ê°€ëœ ë ˆì½”ë“œ: {total_records:,}")

    # ìµœì¢… ìƒíƒœ í™•ì¸
    final_dates = await get_local_dates(sqlite)
    print("\në¡œì»¬ SQLite ìµœì¢… ìƒíƒœ:")
    print(f"  - ì´ ì¼ìˆ˜: {len(final_dates)}")
    if final_dates:
        print(f"  - ë‚ ì§œ ë²”ìœ„: {final_dates[0]} ~ {final_dates[-1]}")

    return total_synced == len(missing_dates)


def main():
    parser = argparse.ArgumentParser(description="Railway â†’ ë¡œì»¬ SQLite ë™ê¸°í™” ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--url", default=DEFAULT_RAILWAY_URL, help="Railway API URL")
    parser.add_argument(
        "--force", action="store_true", help="ëª¨ë“  ë‚ ì§œ ì¬ë™ê¸°í™” (ê¸°ì¡´ ë°ì´í„° ë®ì–´ì“°ê¸°)"
    )
    parser.add_argument("--dry-run", action="store_true", help="ì‹¤ì œ ë™ê¸°í™” ì—†ì´ í™•ì¸ë§Œ")

    args = parser.parse_args()

    success = asyncio.run(
        sync_from_railway(base_url=args.url, force=args.force, dry_run=args.dry_run)
    )

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
