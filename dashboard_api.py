"""
Dashboard API Server
ëŒ€ì‹œë³´ë“œìš© FastAPI ë°±ì—”ë“œ ì„œë²„

- ì±—ë´‡ API (ChatGPT + RAG + Ontology ì—°ë™)
- DOCX ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
- ëŒ€í™” ë©”ëª¨ë¦¬ ì§€ì›
- Audit Trail ë¡œê¹…
"""

import json
import os
import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
from io import BytesIO
from collections import defaultdict
from pathlib import Path

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from dotenv import load_dotenv
from litellm import acompletion

from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_TABLE_ALIGNMENT

# RAG ì‹œìŠ¤í…œ ì—°ë™
from rag.router import RAGRouter, QueryType
from rag.retriever import DocumentRetriever

# Ontology ìŠ¤í‚¤ë§ˆ
from ontology.schema import ProductMetrics, BrandMetrics, MarketMetrics

# í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (ì‹ ê·œ)
from core.unified_orchestrator import UnifiedOrchestrator, get_unified_orchestrator
from core.crawl_manager import get_crawl_manager, CrawlStatus

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI(
    title="AMORE Dashboard API",
    description="LANEIGE Amazon ëŒ€ì‹œë³´ë“œ ë°±ì—”ë“œ API (RAG + Ontology í†µí•©)",
    version="2.0.0"
)

# CORS ì„¤ì • (ë¡œì»¬ ê°œë°œìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë°ì´í„° ê²½ë¡œ
DATA_PATH = "./data/dashboard_data.json"
DOCS_PATH = "./"  # MD íŒŒì¼ë“¤ì´ ë£¨íŠ¸ì— ìˆìŒ
AUDIT_LOG_DIR = "./logs"

# ============= Audit Trail Logger ì„¤ì • =============

def setup_audit_logger():
    """Audit Trail ë¡œê±° ì„¤ì •"""
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    Path(AUDIT_LOG_DIR).mkdir(parents=True, exist_ok=True)

    # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ë°˜ ë¡œê·¸ íŒŒì¼
    today = datetime.now().strftime("%Y-%m-%d")
    log_file = Path(AUDIT_LOG_DIR) / f"chatbot_audit_{today}.log"

    # ë¡œê±° ìƒì„±
    audit_logger = logging.getLogger("audit_trail")
    audit_logger.setLevel(logging.INFO)

    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    audit_logger.handlers.clear()

    # íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
    file_handler = logging.FileHandler(log_file, encoding="utf-8")
    file_handler.setLevel(logging.INFO)

    # í¬ë§· ì„¤ì •
    formatter = logging.Formatter(
        '%(asctime)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(formatter)
    audit_logger.addHandler(file_handler)

    return audit_logger

audit_logger = setup_audit_logger()

def log_chat_interaction(
    session_id: str,
    user_query: str,
    ai_response: str,
    query_type: str,
    confidence: float,
    entities: Dict,
    sources: List[str],
    response_time_ms: float
):
    """ì±—ë´‡ ëŒ€í™” Audit Trail ê¸°ë¡"""
    audit_entry = {
        "session_id": session_id,
        "timestamp": datetime.now().isoformat(),
        "user_query": user_query,
        "ai_response": ai_response[:500] + "..." if len(ai_response) > 500 else ai_response,
        "query_type": query_type,
        "confidence": round(confidence, 4),
        "entities": entities,
        "sources": sources,
        "response_time_ms": round(response_time_ms, 2)
    }

    # JSON í˜•ì‹ìœ¼ë¡œ ë¡œê·¸ ê¸°ë¡
    audit_logger.info(json.dumps(audit_entry, ensure_ascii=False))

# ============= Global Instances =============

# RAG ì‹œìŠ¤í…œ
rag_router = RAGRouter()
doc_retriever = DocumentRetriever(DOCS_PATH)

# ì„¸ì…˜ë³„ ëŒ€í™” ë©”ëª¨ë¦¬ (ê°„ë‹¨í•œ ì¸ë©”ëª¨ë¦¬ êµ¬í˜„)
conversation_memory: Dict[str, List[Dict[str, str]]] = defaultdict(list)
MAX_MEMORY_TURNS = 10

# í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì¸ìŠ¤í„´ìŠ¤ëŠ” get_unified_orchestrator()ë¡œ ê´€ë¦¬ë¨


# ============= Pydantic Models =============

class ChatRequest(BaseModel):
    """ì±—ë´‡ ìš”ì²­"""
    message: str
    session_id: Optional[str] = "default"
    context: Optional[Dict] = None


class ChatResponse(BaseModel):
    """ì±—ë´‡ ì‘ë‹µ"""
    response: str
    query_type: str
    confidence: float
    sources: List[str]
    suggestions: List[str]
    entities: Dict[str, Any]


class ExportRequest(BaseModel):
    """ë‚´ë³´ë‚´ê¸° ìš”ì²­"""
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    include_strategy: bool = True


# ============= Helper Functions =============

def load_dashboard_data() -> Dict[str, Any]:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ"""
    try:
        with open(DATA_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}


def get_conversation_history(session_id: str, limit: int = 5) -> str:
    """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ (ë¬¸ìì—´ í˜•íƒœ)"""
    history = conversation_memory.get(session_id, [])[-limit:]
    if not history:
        return ""

    lines = []
    for turn in history:
        role = "ì‚¬ìš©ì" if turn["role"] == "user" else "AI"
        content = turn["content"][:150] + "..." if len(turn["content"]) > 150 else turn["content"]
        lines.append(f"[{role}]: {content}")

    return "\n".join(lines)


def add_to_memory(session_id: str, role: str, content: str) -> None:
    """ëŒ€í™” ë©”ëª¨ë¦¬ì— ì¶”ê°€"""
    conversation_memory[session_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    })
    # ìµœëŒ€ ê°œìˆ˜ ìœ ì§€
    if len(conversation_memory[session_id]) > MAX_MEMORY_TURNS * 2:
        conversation_memory[session_id] = conversation_memory[session_id][-MAX_MEMORY_TURNS * 2:]


def build_data_context(data: Dict, query_type: QueryType, entities: Dict) -> str:
    """
    ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (Ontology ê¸°ë°˜)

    ì§ˆë¬¸ ìœ í˜•ê³¼ ì¶”ì¶œëœ ì—”í‹°í‹°ì— ë”°ë¼ í•„ìš”í•œ ë°ì´í„°ë§Œ ì„ íƒ
    """
    if not data:
        return "í˜„ì¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    context_parts = []

    # ë©”íƒ€ë°ì´í„° (í•­ìƒ í¬í•¨)
    metadata = data.get("metadata", {})
    context_parts.append(f"""[ë°ì´í„° í˜„í™©]
- ê¸°ì¤€ì¼: {metadata.get('data_date', 'N/A')}
- ì´ ì œí’ˆ ìˆ˜: {metadata.get('total_products', 0)}ê°œ
- LANEIGE ì œí’ˆ ìˆ˜: {metadata.get('laneige_products', 0)}ê°œ""")

    # ì§ˆë¬¸ ìœ í˜•ë³„ ë°ì´í„° ì„ íƒ
    brand_kpis = data.get("brand", {}).get("kpis", {})

    # ì‹œì¥/ë¸Œëœë“œ ì§€í‘œ (DEFINITION, INTERPRETATION, ANALYSIS)
    if query_type in [QueryType.DEFINITION, QueryType.INTERPRETATION, QueryType.ANALYSIS, QueryType.COMBINATION]:
        if brand_kpis:
            context_parts.append(f"""
[LANEIGE ë¸Œëœë“œ KPI] (Ontology: BrandMetrics)
- SoS (Share of Shelf): {brand_kpis.get('sos', 0)}% {brand_kpis.get('sos_delta', '')}
- Top 10 ì œí’ˆ ìˆ˜: {brand_kpis.get('top10_count', 0)}ê°œ
- í‰ê·  ìˆœìœ„: {brand_kpis.get('avg_rank', 0)}ìœ„
- HHI (ì‹œì¥ ì§‘ì¤‘ë„): {brand_kpis.get('hhi', 0)}""")

    # ê²½ìŸì‚¬ ì •ë³´ (ANALYSIS, DATA_QUERYì—ì„œ ê²½ìŸì‚¬ ì–¸ê¸‰ ì‹œ)
    competitors = data.get("brand", {}).get("competitors", [])
    brands_mentioned = entities.get("brands", [])

    if query_type == QueryType.ANALYSIS or any(b for b in brands_mentioned if b.lower() != "laneige"):
        if competitors:
            top_comps = competitors[:5]
            comp_lines = [f"  - {c['brand']}: SoS {c['sos']}%, í‰ê·  ìˆœìœ„ {c['avg_rank']}ìœ„, ì œí’ˆ {c['product_count']}ê°œ" for c in top_comps]
            context_parts.append("[ê²½ìŸì‚¬ í˜„í™©]\n" + "\n".join(comp_lines))

    # ì œí’ˆ ì •ë³´ (DATA_QUERY, íŠ¹ì • ì œí’ˆ ì–¸ê¸‰ ì‹œ)
    products = data.get("products", {})
    products_mentioned = entities.get("products", [])

    if query_type == QueryType.DATA_QUERY or products_mentioned:
        if products:
            prod_lines = []
            for asin, p in list(products.items())[:5]:
                prod_lines.append(f"""  - {p['name'][:40]}
    ìˆœìœ„: #{p['rank']} ({p['rank_delta']}), í‰ì : {p['rating']}, ë³€ë™ì„±: {p.get('volatility_status', 'N/A')}""")
            context_parts.append("[LANEIGE ì œí’ˆ í˜„í™©] (Ontology: ProductMetrics)\n" + "\n".join(prod_lines))

    # ì¹´í…Œê³ ë¦¬ ì •ë³´
    categories = data.get("categories", {})
    categories_mentioned = entities.get("categories", [])

    if categories_mentioned or query_type in [QueryType.ANALYSIS, QueryType.INTERPRETATION]:
        if categories:
            cat_lines = []
            for cat_id, cat in categories.items():
                cat_lines.append(f"  - {cat['name']}: SoS {cat['sos']}%, ìµœê³  ìˆœìœ„ #{cat['best_rank']}, CPI {cat.get('cpi', 100)}")
            context_parts.append("[ì¹´í…Œê³ ë¦¬ í˜„í™©] (Ontology: MarketMetrics)\n" + "\n".join(cat_lines))

    # ì•¡ì…˜ ì•„ì´í…œ (ì „ëµ ì§ˆë¬¸)
    if query_type == QueryType.ANALYSIS:
        action_items = data.get("home", {}).get("action_items", [])
        if action_items:
            action_lines = [f"  - [{a['priority']}] {a['product_name']}: {a['signal']} â†’ {a['action_tag']}" for a in action_items[:4]]
            context_parts.append("[í˜„ì¬ ì•¡ì…˜ ì•„ì´í…œ]\n" + "\n".join(action_lines))

    return "\n\n".join(context_parts)


async def get_rag_context(query: str, query_type: QueryType) -> tuple[str, List[str]]:
    """
    RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰

    Returns:
        (ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´, ì¶œì²˜ ëª©ë¡)
    """
    # DocumentRetriever ì´ˆê¸°í™” (ì²˜ìŒ í˜¸ì¶œ ì‹œ)
    if not doc_retriever._initialized:
        await doc_retriever.initialize()

    # ì§ˆë¬¸ ìœ í˜•ì— ë§ëŠ” ë¬¸ì„œ ê²€ìƒ‰
    target_doc = rag_router.get_target_document(query_type)

    # ê²€ìƒ‰ ì‹¤í–‰
    results = await doc_retriever.search(query, top_k=3, doc_filter=target_doc)

    if not results:
        return "", []

    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_parts = []
    sources = []

    for result in results:
        metadata = result.get("metadata", {})
        content = result.get("content", "")
        title = metadata.get("title", "Unknown")
        doc_id = metadata.get("doc_id", "")

        context_parts.append(f"[{title}]\n{content}")

        # ì¶œì²˜ ì¶”ê°€
        doc_name_map = {
            "strategic_indicators": "Strategic Indicators Definition",
            "metric_interpretation": "Metric Interpretation Guide",
            "indicator_combination": "Indicator Combination Playbook",
            "home_insight_rules": "Home Page Insight Rules"
        }
        if doc_id in doc_name_map and doc_name_map[doc_id] not in sources:
            sources.append(doc_name_map[doc_id])

    return "\n\n---\n\n".join(context_parts), sources


def get_dynamic_suggestions(query_type: QueryType, entities: Dict, response: str) -> List[str]:
    """
    ë™ì  í›„ì† ì§ˆë¬¸ ì œì•ˆ

    ì‘ë‹µ ë‚´ìš©ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ì¶¤í˜• ì œì•ˆ ìƒì„±
    """
    suggestions = []

    # ì—”í‹°í‹° ê¸°ë°˜ ì œì•ˆ
    brands = entities.get("brands", [])
    indicators = entities.get("indicators", [])
    categories = entities.get("categories", [])

    if query_type == QueryType.DEFINITION:
        # ì •ì˜ ì§ˆë¬¸ â†’ í•´ì„/í™œìš© ì§ˆë¬¸ ì œì•ˆ
        if indicators:
            ind = indicators[0].upper()
            suggestions.append(f"{ind}ê°€ ë†’ìœ¼ë©´ ì–´ë–¤ ì˜ë¯¸ì¸ê°€ìš”?")
            suggestions.append(f"{ind} ê°œì„ ì„ ìœ„í•œ ì „ëµì€?")
        suggestions.append("ë‹¤ë¥¸ ì§€í‘œì™€ í•¨ê»˜ í•´ì„í•˜ë©´ ì–´ë–¤ê°€ìš”?")

    elif query_type == QueryType.INTERPRETATION:
        # í•´ì„ ì§ˆë¬¸ â†’ ì•¡ì…˜/ì¡°í•© ì œì•ˆ
        suggestions.append("í˜„ì¬ LANEIGE ìˆ˜ì¹˜ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”")
        suggestions.append("ê²½ìŸì‚¬ì™€ ë¹„êµí•˜ë©´ ì–´ë–¤ê°€ìš”?")
        suggestions.append("ê°œì„ ì„ ìœ„í•œ ì•¡ì…˜ ì•„ì´í…œì€?")

    elif query_type == QueryType.DATA_QUERY:
        # ë°ì´í„° ì¡°íšŒ â†’ ì‹¬í™” ë¶„ì„ ì œì•ˆ
        suggestions.append("ì´ ìˆ˜ì¹˜ê°€ ì¢‹ì€ ê±´ê°€ìš”?")
        suggestions.append("ìµœê·¼ 7ì¼ ì¶”ì´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”")
        suggestions.append("ê²½ìŸì‚¬ ëŒ€ë¹„ ì–´ë–¤ê°€ìš”?")

    elif query_type == QueryType.ANALYSIS:
        # ë¶„ì„ â†’ ì „ëµ/ì•¡ì…˜ ì œì•ˆ
        suggestions.append("ê°€ì¥ ì‹œê¸‰í•œ ì•¡ì…˜ì€ ë¬´ì—‡ì¸ê°€ìš”?")
        suggestions.append("Top 10 ì§„ì…ì„ ìœ„í•œ ì „ëµì€?")
        suggestions.append("ë¦¬ìŠ¤í¬ ìš”ì¸ì´ ìˆë‚˜ìš”?")

    elif query_type == QueryType.COMBINATION:
        # ì¡°í•© ì§ˆë¬¸ â†’ ë‹¤ë¥¸ ì¡°í•© ì œì•ˆ
        suggestions.append("ë‹¤ë¥¸ ì‹œë‚˜ë¦¬ì˜¤ë„ ë¶„ì„í•´ì£¼ì„¸ìš”")
        suggestions.append("í˜„ì¬ ë°ì´í„°ì—ì„œ í•´ë‹¹ ìƒí™©ì´ ìˆë‚˜ìš”?")

    else:
        # ê¸°ë³¸ ì œì•ˆ
        suggestions = [
            "SoS(ì ìœ ìœ¨)ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            "í˜„ì¬ LANEIGE ìˆœìœ„ëŠ”?",
            "ì „ëµì  ê¶Œê³ ì‚¬í•­ì´ ìˆë‚˜ìš”?"
        ]

    return suggestions[:3]


# ============= API Endpoints =============

@app.get("/")
async def root():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "ok",
        "message": "AMORE Dashboard API v2.0 (RAG + Ontology)",
        "features": ["chatbot", "rag", "ontology", "memory", "docx_export"]
    }


@app.get("/api/data")
async def get_data():
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ"""
    data = load_dashboard_data()
    if not data:
        raise HTTPException(status_code=404, detail="Dashboard data not found")
    return data


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ChatGPT + RAG + Ontology í†µí•© ì±—ë´‡ API

    1. ì§ˆë¬¸ ë¶„ì„ (RAGRouter)
    2. ì—”í‹°í‹° ì¶”ì¶œ (Ontology ê¸°ë°˜)
    3. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (RAG)
    4. ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    5. ëŒ€í™” ê¸°ë¡ ì°¸ì¡°
    6. LLM ì‘ë‹µ ìƒì„±
    7. Audit Trail ë¡œê¹…
    """
    import time
    start_time = time.time()

    message = request.message.strip()
    session_id = request.session_id or "default"

    if not message:
        raise HTTPException(status_code=400, detail="Message is required")

    # 1. ì§ˆë¬¸ ë¶„ë¥˜ (RAGRouter ì‚¬ìš©)
    route_result = rag_router.route(message)
    query_type = route_result["query_type"]
    confidence = route_result["confidence"]

    # 2. ì—”í‹°í‹° ì¶”ì¶œ (Ontology ê¸°ë°˜)
    entities = rag_router.extract_entities(message)

    # 3. ëª…í™•í™” í•„ìš” ì—¬ë¶€ í™•ì¸
    clarification = rag_router.needs_clarification(route_result, entities)
    if clarification and confidence < 0.5:
        # ëª…í™•í™” ìš”ì²­
        add_to_memory(session_id, "user", message)
        add_to_memory(session_id, "assistant", clarification)

        return ChatResponse(
            response=clarification,
            query_type=query_type.value if hasattr(query_type, 'value') else str(query_type),
            confidence=confidence,
            sources=[],
            suggestions=["ì˜ˆ, ì „ì²´ ë¸Œëœë“œ ë¶„ì„í•´ì£¼ì„¸ìš”", "LANEIGEë§Œ ë¶„ì„í•´ì£¼ì„¸ìš”", "Lip Care ì¹´í…Œê³ ë¦¬ë§Œ"],
            entities=entities
        )

    # 4. RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
    rag_context, sources = await get_rag_context(message, query_type)

    # 5. ë°ì´í„° ë¡œë“œ ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    data = load_dashboard_data()
    data_context = build_data_context(data, query_type, entities)

    # 6. ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
    conversation_history = get_conversation_history(session_id)

    # 7. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = """ë‹¹ì‹ ì€ AMORE Pacificì˜ LANEIGE ë¸Œëœë“œ Amazon ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì—­í• :
- Amazon US ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ì œê³µ
- LANEIGE ë¸Œëœë“œì˜ ì‹œì¥ í¬ì§€ì…˜ ë¶„ì„
- ê²½ìŸì‚¬ ëŒ€ë¹„ ì „ëµì  ê¶Œê³  ì œê³µ
- ì§€í‘œ ì •ì˜ ë° í•´ì„ ê°€ì´ë“œ ì œê³µ

Ontology ì—”í‹°í‹° ì´í•´:
- Brand: ë¸Œëœë“œ ì •ë³´ (LANEIGE, ê²½ìŸì‚¬ ë“±)
- Product: ì œí’ˆ ì •ë³´ (ASIN, ìˆœìœ„, í‰ì , ê°€ê²© ë“±)
- Category: ì¹´í…Œê³ ë¦¬ (Lip Care, Skin Care ë“±)
- BrandMetrics: SoS, í‰ê· ìˆœìœ„, ì œí’ˆìˆ˜ ë“±
- ProductMetrics: ìˆœìœ„ë³€ë™ì„±, ì—°ì†ì²´ë¥˜ì¼, í‰ì ì¶”ì„¸ ë“±
- MarketMetrics: HHI(ì‹œì¥ì§‘ì¤‘ë„), êµì²´ìœ¨ ë“±

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
1. ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì¸ìš©
2. RAG ë¬¸ì„œì˜ ì •ì˜/í•´ì„ ê¸°ì¤€ í™œìš©
3. ì´ì „ ëŒ€í™” ë§¥ë½ ê³ ë ¤
4. ê°„ê²°í•˜ê³  ì•¡ì…˜ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ
5. ë¶ˆí™•ì‹¤í•œ ê²½ìš° ëª…í™•íˆ ë°í ê²ƒ
6. ë‹¨ì •ì  í‘œí˜„ í”¼í•˜ê¸°
7. í•œêµ­ì–´ë¡œ ì‘ë‹µ

ì§ˆë¬¸ ìœ í˜•ë³„ ì‘ë‹µ ìŠ¤íƒ€ì¼:
- ì •ì˜(DEFINITION): ì§€í‘œì˜ ì •ì˜, ì‚°ì¶œì‹, ì˜ë¯¸ë¥¼ ì„¤ëª…
- í•´ì„(INTERPRETATION): ìˆ˜ì¹˜ì˜ ì˜ë¯¸, ì¢‹ê³  ë‚˜ì¨ì˜ ê¸°ì¤€ ì„¤ëª…
- ì¡°í•©(COMBINATION): ì—¬ëŸ¬ ì§€í‘œë¥¼ í•¨ê»˜ í•´ì„, ì‹œë‚˜ë¦¬ì˜¤ë³„ ì•¡ì…˜ ì œì•ˆ
- ë°ì´í„°ì¡°íšŒ(DATA_QUERY): í˜„ì¬ ìˆ˜ì¹˜ì™€ ë³€ë™ í˜„í™© ì•ˆë‚´
- ë¶„ì„(ANALYSIS): ì¢…í•© ë¶„ì„ê³¼ ì „ëµì  ê¶Œê³  ì œê³µ
"""

    # 8. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    user_prompt = f"""## ì‚¬ìš©ì ì§ˆë¬¸
{message}

## ì§ˆë¬¸ ìœ í˜•
{query_type.value if hasattr(query_type, 'value') else str(query_type)} (ì‹ ë¢°ë„: {confidence:.1%})

## ì¶”ì¶œëœ ì—”í‹°í‹°
- ë¸Œëœë“œ: {', '.join(entities.get('brands', [])) or 'ì—†ìŒ'}
- ì¹´í…Œê³ ë¦¬: {', '.join(entities.get('categories', [])) or 'ì—†ìŒ'}
- ì§€í‘œ: {', '.join(entities.get('indicators', [])) or 'ì—†ìŒ'}
- ê¸°ê°„: {entities.get('time_range') or 'ì—†ìŒ'}

## RAG ì°¸ì¡° ë¬¸ì„œ
{rag_context if rag_context else 'ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ'}

## í˜„ì¬ ë°ì´í„°
{data_context}

## ì´ì „ ëŒ€í™”
{conversation_history if conversation_history else 'ì´ì „ ëŒ€í™” ì—†ìŒ'}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
- ì§ˆë¬¸ ìœ í˜•ì— ë§ëŠ” ì‘ë‹µ ìŠ¤íƒ€ì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- RAG ë¬¸ì„œì— ê´€ë ¨ ì •ì˜/í•´ì„ì´ ìˆìœ¼ë©´ ì¸ìš©í•˜ì„¸ìš”.
- ì´ì „ ëŒ€í™” ë§¥ë½ì´ ìˆìœ¼ë©´ ê³ ë ¤í•˜ì„¸ìš”.
"""

    try:
        response = await acompletion(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=1000
        )

        answer = response.choices[0].message.content

        # 9. ëŒ€í™” ë©”ëª¨ë¦¬ì— ì €ì¥
        add_to_memory(session_id, "user", message)
        add_to_memory(session_id, "assistant", answer)

        # 10. ë™ì  í›„ì† ì§ˆë¬¸ ì œì•ˆ
        suggestions = get_dynamic_suggestions(query_type, entities, answer)

        # 11. Audit Trail ë¡œê¹…
        response_time_ms = (time.time() - start_time) * 1000
        log_chat_interaction(
            session_id=session_id,
            user_query=message,
            ai_response=answer,
            query_type=query_type.value if hasattr(query_type, 'value') else str(query_type),
            confidence=confidence,
            entities=entities,
            sources=sources,
            response_time_ms=response_time_ms
        )

        return ChatResponse(
            response=answer,
            query_type=query_type.value if hasattr(query_type, 'value') else str(query_type),
            confidence=confidence,
            sources=sources,
            suggestions=suggestions,
            entities=entities
        )

    except Exception as e:
        print(f"LLM Error: {e}")

        # Fallback ì‘ë‹µ
        fallback = route_result.get("fallback_message") or rag_router.get_fallback_response("unknown")

        # ë°ì´í„° ê¸°ë°˜ ê¸°ë³¸ ì‘ë‹µ ì¶”ê°€
        if data and query_type == QueryType.DATA_QUERY:
            brand_kpis = data.get("brand", {}).get("kpis", {})
            fallback = f"""í˜„ì¬ LANEIGE í˜„í™©:
- SoS: {brand_kpis.get('sos', 0)}%
- Top 10 ì œí’ˆ: {brand_kpis.get('top10_count', 0)}ê°œ
- í‰ê·  ìˆœìœ„: {brand_kpis.get('avg_rank', 0)}ìœ„

(ìƒì„¸ ë¶„ì„ì„ ìœ„í•´ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”)"""

        # Fallback ì‘ë‹µë„ Audit Trail ê¸°ë¡
        response_time_ms = (time.time() - start_time) * 1000
        log_chat_interaction(
            session_id=session_id,
            user_query=message,
            ai_response=f"[ERROR] {str(e)[:100]} | Fallback: {fallback[:200]}",
            query_type=query_type.value if hasattr(query_type, 'value') else str(query_type),
            confidence=0.0,
            entities=entities,
            sources=["fallback"],
            response_time_ms=response_time_ms
        )

        return ChatResponse(
            response=fallback,
            query_type=query_type.value if hasattr(query_type, 'value') else str(query_type),
            confidence=0.0,
            sources=[],
            suggestions=["ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”", "SoSê°€ ë­”ê°€ìš”?", "í˜„ì¬ ìˆœìœ„ ì•Œë ¤ì£¼ì„¸ìš”"],
            entities=entities
        )


@app.delete("/api/chat/memory/{session_id}")
async def clear_memory(session_id: str):
    """ì„¸ì…˜ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
    if session_id in conversation_memory:
        del conversation_memory[session_id]
    return {"status": "ok", "message": f"Session {session_id} memory cleared"}


# ============= Simple Chat API (v3 - ë‹¨ìˆœí™”) =============

from core.simple_chat import get_chat_service


class SimpleChatRequest(BaseModel):
    """Simple Chat ìš”ì²­"""
    message: str
    session_id: Optional[str] = "default"


class SimpleChatResponse(BaseModel):
    """Simple Chat ì‘ë‹µ"""
    text: str
    suggestions: List[str]
    tools_used: List[str]
    data_date: str
    processing_time_ms: float


@app.post("/api/v3/chat", response_model=SimpleChatResponse)
async def chat_v3(request: SimpleChatRequest):
    """
    Simple LLM Chat API (v3)

    ë‹¨ìˆœí™”ëœ êµ¬ì¡°:
    - LLMì´ ëª¨ë“  íŒë‹¨ ë‹´ë‹¹
    - Function Callingìœ¼ë¡œ ë„êµ¬ ì‚¬ìš©
    - ë¶ˆí•„ìš”í•œ ë ˆì´ì–´ ì œê±°
    """
    message = request.message.strip()
    session_id = request.session_id or "default"

    if not message:
        raise HTTPException(status_code=400, detail="Message is required")

    # í¬ë¡¤ë§ ìƒíƒœ ì²´í¬
    crawl_manager = get_crawl_manager()
    crawl_notification = None
    crawl_started = False

    if crawl_manager.needs_crawl():
        crawl_started = await crawl_manager.start_crawl()

    if crawl_manager.should_notify(session_id):
        crawl_notification = crawl_manager.get_notification_message()
        crawl_manager.mark_notified(session_id)

    # Simple Chat Serviceë¡œ ì²˜ë¦¬
    chat_service = get_chat_service()
    result = await chat_service.chat(message, session_id)

    # í¬ë¡¤ë§ ì•Œë¦¼ ì¶”ê°€
    response_text = result["text"]
    if crawl_notification:
        response_text = f"{crawl_notification}\n\n---\n\n{response_text}"
    elif crawl_started:
        data_date = crawl_manager.get_data_date() or "ì—†ìŒ"
        response_text = (
            f"ğŸ“¡ **ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì˜¤ëŠ˜ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.**\n"
            f"í˜„ì¬ ë°ì´í„°: {data_date}\n"
            f"ìˆ˜ì§‘ì´ ì™„ë£Œë˜ë©´ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n---\n\n{response_text}"
        )

    return SimpleChatResponse(
        text=response_text,
        suggestions=result.get("suggestions", []),
        tools_used=result.get("tools_used", []),
        data_date=result.get("data_date", "N/A"),
        processing_time_ms=result.get("processing_time_ms", 0)
    )


# ============= LLM Orchestrator API (v2 - ê¸°ì¡´, deprecated) =============

class OrchestratorChatRequest(BaseModel):
    """LLM Orchestrator ì±—ë´‡ ìš”ì²­"""
    message: str
    session_id: Optional[str] = "default"
    skip_cache: bool = False


class OrchestratorChatResponse(BaseModel):
    """LLM Orchestrator ì±—ë´‡ ì‘ë‹µ"""
    text: str
    query_type: str
    confidence_level: str
    confidence_score: float
    sources: List[str]
    entities: Dict[str, Any]
    tools_called: List[str]
    suggestions: List[str]
    is_fallback: bool
    is_clarification: bool
    processing_time_ms: float


@app.post("/api/v2/chat", response_model=OrchestratorChatResponse)
async def chat_v2(request: OrchestratorChatRequest):
    """
    í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ê¸°ë°˜ ì±—ë´‡ API (v2)

    ë™ì‘ íë¦„:
    1. ì§ˆë¬¸ ìˆ˜ì‹ 
    2. ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€ (ë°ì´í„° ì‹ ì„ ë„, ì‚¬ìš© ê°€ëŠ¥ ì—ì´ì „íŠ¸)
    3. LLMì´ ìƒí™© íŒë‹¨ â†’ ì—ì´ì „íŠ¸ ì„ íƒ
    4. ì—ì´ì „íŠ¸ ì‹¤í–‰ (ì—ëŸ¬ ì‹œ ì „ëµì— ë”°ë¼ ì²˜ë¦¬)
    5. ì‘ë‹µ ìƒì„±

    ì—ëŸ¬ ì „ëµ:
    - RETRY: ì¬ì‹œë„ (ìµœëŒ€ 2íšŒ)
    - FALLBACK: ìºì‹œ ë°ì´í„° ì‚¬ìš©
    - SKIP: ê±´ë„ˆë›°ê³  ê³„ì†
    - ABORT: ì¤‘ë‹¨ + ì‚¬ìš©ì ì•Œë¦¼
    """
    import time
    start_time = time.time()

    message = request.message.strip()
    session_id = request.session_id or "default"

    if not message:
        raise HTTPException(status_code=400, detail="Message is required")

    # === í¬ë¡¤ë§ ìƒíƒœ ì²´í¬ ===
    crawl_manager = get_crawl_manager()
    crawl_notification = None
    crawl_started = False

    # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ì—†ê³ , í¬ë¡¤ë§ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘
    if crawl_manager.needs_crawl():
        crawl_started = await crawl_manager.start_crawl()
        if crawl_started:
            logging.info("Background crawl started for today's data")

    # í¬ë¡¤ë§ ì™„ë£Œ ì•Œë¦¼ ì²´í¬ (ì´ ì„¸ì…˜ì—ì„œ ì•„ì§ ì•ˆ ì•Œë ¸ìœ¼ë©´)
    if crawl_manager.should_notify(session_id):
        crawl_notification = crawl_manager.get_notification_message()
        crawl_manager.mark_notified(session_id)

    try:
        # í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¡œ ì²˜ë¦¬
        orchestrator = get_unified_orchestrator()

        # í˜„ì¬ ë©”íŠ¸ë¦­ ë°ì´í„° ë¡œë“œ
        data = load_dashboard_data()
        current_metrics = data if data else None

        # ì²˜ë¦¬
        response = await orchestrator.process(
            query=message,
            session_id=session_id,
            current_metrics=current_metrics,
            skip_cache=request.skip_cache
        )

        # ì‘ë‹µ í…ìŠ¤íŠ¸ êµ¬ì„±
        response_text = response.text

        # í¬ë¡¤ë§ ì•Œë¦¼ ì¶”ê°€
        if crawl_notification:
            response_text = f"{crawl_notification}\n\n---\n\n{response_text}"
        elif crawl_started:
            # í¬ë¡¤ë§ ì‹œì‘ ì•Œë¦¼
            data_date = crawl_manager.get_data_date() or "ì—†ìŒ"
            response_text = (
                f"ğŸ“¡ **ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì˜¤ëŠ˜ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.**\n"
                f"í˜„ì¬ ë°ì´í„°: {data_date}\n"
                f"ìˆ˜ì§‘ì´ ì™„ë£Œë˜ë©´ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n---\n\n{response_text}"
            )

        # ì‘ë‹µ ë³€í™˜
        return OrchestratorChatResponse(
            text=response_text,
            query_type=response.query_type,
            confidence_level=response.confidence_level.value,
            confidence_score=response.confidence_score,
            sources=response.sources,
            entities=response.entities,
            tools_called=response.tools_called,
            suggestions=response.suggestions,
            is_fallback=response.is_fallback,
            is_clarification=response.is_clarification,
            processing_time_ms=response.processing_time_ms
        )

    except Exception as e:
        logging.error(f"Orchestrator error: {e}")
        return OrchestratorChatResponse(
            text=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            query_type="error",
            confidence_level="unknown",
            confidence_score=0.0,
            sources=[],
            entities={},
            tools_called=[],
            suggestions=["ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”"],
            is_fallback=True,
            is_clarification=False,
            processing_time_ms=(time.time() - start_time) * 1000
        )


@app.get("/api/v2/stats")
async def get_orchestrator_stats():
    """í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í†µê³„ ì¡°íšŒ"""
    orchestrator = get_unified_orchestrator()
    return orchestrator.get_stats()


@app.get("/api/v2/state")
async def get_orchestrator_state():
    """í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒíƒœ ì¡°íšŒ"""
    orchestrator = get_unified_orchestrator()
    return {
        "summary": orchestrator.get_state_summary(),
        "state": orchestrator.state.to_dict()
    }


@app.get("/api/v2/errors")
async def get_orchestrator_errors():
    """í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìµœê·¼ ì—ëŸ¬ ì¡°íšŒ"""
    orchestrator = get_unified_orchestrator()
    return {
        "recent_errors": orchestrator.get_recent_errors(limit=20),
        "stats": orchestrator.get_stats()
    }


@app.post("/api/v2/reset-errors")
async def reset_orchestrator_errors():
    """ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ ëª©ë¡ ì´ˆê¸°í™”"""
    orchestrator = get_unified_orchestrator()
    orchestrator.reset_failed_agents()
    return {"status": "ok", "message": "Failed agents list cleared"}


@app.get("/api/crawl/status")
async def get_crawl_status():
    """
    í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ

    Returns:
        - status: idle/running/completed/failed
        - date: í¬ë¡¤ë§ ëŒ€ìƒ ë‚ ì§œ
        - progress: ì§„í–‰ë¥  (0-100)
        - data_date: í˜„ì¬ ë°ì´í„° ë‚ ì§œ
        - needs_crawl: í¬ë¡¤ë§ í•„ìš” ì—¬ë¶€
    """
    crawl_manager = get_crawl_manager()
    return {
        **crawl_manager.state.to_dict(),
        "data_date": crawl_manager.get_data_date(),
        "needs_crawl": crawl_manager.needs_crawl(),
        "is_today_available": crawl_manager.is_today_data_available(),
        "status_message": crawl_manager.get_status_message()
    }


@app.post("/api/crawl/start")
async def start_crawl():
    """
    ìˆ˜ë™ìœ¼ë¡œ í¬ë¡¤ë§ ì‹œì‘

    Returns:
        - started: í¬ë¡¤ë§ ì‹œì‘ ì—¬ë¶€
        - message: ìƒíƒœ ë©”ì‹œì§€
    """
    crawl_manager = get_crawl_manager()

    if crawl_manager.is_crawling():
        return {
            "started": False,
            "message": "í¬ë¡¤ë§ì´ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.",
            "status": crawl_manager.state.to_dict()
        }

    if crawl_manager.is_today_data_available():
        return {
            "started": False,
            "message": "ì˜¤ëŠ˜ ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.",
            "status": crawl_manager.state.to_dict()
        }

    started = await crawl_manager.start_crawl()
    return {
        "started": started,
        "message": "í¬ë¡¤ë§ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤." if started else "í¬ë¡¤ë§ ì‹œì‘ ì‹¤íŒ¨",
        "status": crawl_manager.state.to_dict()
    }


@app.post("/api/export/docx")
async def export_docx(request: ExportRequest):
    """
    ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ DOCX ìƒì„± ë° ë‹¤ìš´ë¡œë“œ
    """
    data = load_dashboard_data()
    if not data:
        raise HTTPException(status_code=404, detail="Dashboard data not found")

    # DOCX ë¬¸ì„œ ìƒì„±
    doc = Document()

    # ìŠ¤íƒ€ì¼ ì„¤ì •
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Arial'
    font.size = Pt(11)

    # ===== í‘œì§€ =====
    title = doc.add_heading('AMORE INSIGHT Report', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER

    subtitle = doc.add_paragraph('LANEIGE Amazon US ë¶„ì„ ë¦¬í¬íŠ¸')
    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER

    # ë‚ ì§œ
    metadata = data.get("metadata", {})
    date_para = doc.add_paragraph()
    date_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    date_para.add_run(f"ë¶„ì„ ê¸°ì¤€ì¼: {metadata.get('data_date', datetime.now().strftime('%Y-%m-%d'))}")
    date_para.add_run(f"\nìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M')}")

    doc.add_page_break()

    # ===== 1. Executive Summary =====
    doc.add_heading('1. Executive Summary', level=1)

    brand_kpis = data.get("brand", {}).get("kpis", {})
    home_status = data.get("home", {}).get("status", {})

    summary_text = f"""
LANEIGE ë¸Œëœë“œëŠ” Amazon US ì‹œì¥ì—ì„œ {home_status.get('exposure', 'N/A')} ìƒíƒœì…ë‹ˆë‹¤.

â€¢ Share of Shelf (SoS): {brand_kpis.get('sos', 0)}%
â€¢ Top 10 ì§„ì… ì œí’ˆ: {brand_kpis.get('top10_count', 0)}ê°œ
â€¢ í‰ê·  ìˆœìœ„: {brand_kpis.get('avg_rank', 0)}ìœ„
â€¢ ì‹œì¥ ì§‘ì¤‘ë„ (HHI): {brand_kpis.get('hhi', 0)}

í˜„ì¬ ì‹œì¥ í¬ì§€ì…˜: {home_status.get('position', 'N/A')}
ì£¼ì˜ í•„ìš” ì œí’ˆ: {home_status.get('warning_count', 0)}ê°œ
"""
    doc.add_paragraph(summary_text)

    # ===== 2. ì œí’ˆë³„ í˜„í™© =====
    doc.add_heading('2. LANEIGE ì œí’ˆ í˜„í™©', level=1)

    products = data.get("products", {})
    if products:
        # í…Œì´ë¸” ìƒì„±
        table = doc.add_table(rows=1, cols=5)
        table.style = 'Table Grid'
        table.alignment = WD_TABLE_ALIGNMENT.CENTER

        # í—¤ë”
        header_cells = table.rows[0].cells
        headers = ['ì œí’ˆëª…', 'ìˆœìœ„', 'ë³€ë™', 'í‰ì ', 'ë³€ë™ì„±']
        for i, header in enumerate(headers):
            header_cells[i].text = header
            header_cells[i].paragraphs[0].runs[0].bold = True

        # ë°ì´í„° í–‰
        for asin, product in products.items():
            row = table.add_row().cells
            row[0].text = product.get('name', '')[:40]
            row[1].text = f"#{product.get('rank', 'N/A')}"
            row[2].text = product.get('rank_delta', '-')
            row[3].text = str(product.get('rating', '-'))
            row[4].text = product.get('volatility_status', '-')

    doc.add_paragraph()

    # ===== 3. ê²½ìŸì‚¬ ë¶„ì„ =====
    doc.add_heading('3. ê²½ìŸì‚¬ ë¶„ì„', level=1)

    competitors = data.get("brand", {}).get("competitors", [])
    if competitors:
        table = doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'

        header_cells = table.rows[0].cells
        headers = ['ë¸Œëœë“œ', 'SoS (%)', 'í‰ê·  ìˆœìœ„', 'ì œí’ˆ ìˆ˜']
        for i, header in enumerate(headers):
            header_cells[i].text = header
            header_cells[i].paragraphs[0].runs[0].bold = True

        for comp in competitors[:10]:
            row = table.add_row().cells
            row[0].text = comp.get('brand', '')
            row[1].text = str(comp.get('sos', 0))
            row[2].text = str(comp.get('avg_rank', '-'))
            row[3].text = str(comp.get('product_count', 0))

    doc.add_paragraph()

    # ===== 4. ì•¡ì…˜ ì•„ì´í…œ =====
    doc.add_heading('4. ì•¡ì…˜ ì•„ì´í…œ', level=1)

    action_items = data.get("home", {}).get("action_items", [])
    if action_items:
        for item in action_items:
            priority_marker = "ğŸ”´" if item.get('priority') == 'P1' else "ğŸŸ "
            para = doc.add_paragraph()
            para.add_run(f"{priority_marker} [{item.get('priority')}] ").bold = True
            para.add_run(f"{item.get('product_name', '')}\n")
            para.add_run(f"   ì‹ í˜¸: {item.get('signal', '')}\n")
            para.add_run(f"   ê¶Œì¥ ì•¡ì…˜: {item.get('action_tag', '')}")
    else:
        doc.add_paragraph("í˜„ì¬ íŠ¹ë³„í•œ ì•¡ì…˜ ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤.")

    # ===== 5. ì „ëµì  ê¶Œê³ ì‚¬í•­ =====
    if request.include_strategy:
        doc.add_heading('5. ì „ëµì  ê¶Œê³ ì‚¬í•­', level=1)

        # ChatGPTë¡œ ì „ëµ ìƒì„± (RAG ì»¨í…ìŠ¤íŠ¸ í™œìš©)
        try:
            # RAGì—ì„œ ì „ëµ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            strategy_context, _ = await get_rag_context("ì „ëµ ì•¡ì…˜ ê¶Œê³ ", QueryType.ANALYSIS)

            strategy_prompt = f"""ë‹¤ìŒ ë°ì´í„°ì™€ ê°€ì´ë“œë¼ì¸ì„ ë°”íƒ•ìœ¼ë¡œ LANEIGE ë¸Œëœë“œì˜ ì „ëµì  ê¶Œê³ ì‚¬í•­ 3ê°€ì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë°ì´í„°:
- SoS: {brand_kpis.get('sos', 0)}%
- Top 10 ì œí’ˆ: {brand_kpis.get('top10_count', 0)}ê°œ
- í‰ê·  ìˆœìœ„: {brand_kpis.get('avg_rank', 0)}ìœ„
- ì£¼ìš” ê²½ìŸì‚¬: {', '.join([c['brand'] for c in competitors[:3]])}

ì°¸ê³  ê°€ì´ë“œë¼ì¸:
{strategy_context if strategy_context else 'ê¸°ë³¸ ì „ëµ ê¸°ì¤€ ì ìš©'}

ê° ê¶Œê³ ì‚¬í•­ì€ 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
"""
            response = await acompletion(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë·°í‹° ì´ì»¤ë¨¸ìŠ¤ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": strategy_prompt}
                ],
                temperature=0.3,
                max_tokens=500
            )

            strategy_text = response.choices[0].message.content
            doc.add_paragraph(strategy_text)

        except Exception as e:
            # í´ë°± ì „ëµ
            doc.add_paragraph("""
1. Top 10 ìœ ì§€ ì „ëµ: í˜„ì¬ ìƒìœ„ê¶Œ ì œí’ˆì˜ ë¦¬ë·° ê´€ë¦¬ ë° ì¬ê³  í™•ë³´ë¥¼ í†µí•œ í¬ì§€ì…˜ ìœ ì§€

2. ê²½ìŸì‚¬ ëª¨ë‹ˆí„°ë§: e.l.f., Maybelline ë“± ì£¼ìš” ê²½ìŸì‚¬ì˜ ê°€ê²© ë° í”„ë¡œëª¨ì…˜ ë™í–¥ íŒŒì•…

3. ì‹ ê·œ ì§„ì… ê¸°íšŒ: Lip Care ì¹´í…Œê³ ë¦¬ ì™¸ Face Powder, Toner ë“± í™•ì¥ ê°€ëŠ¥ì„± ê²€í† 
""")

    # ===== í‘¸í„° =====
    doc.add_paragraph()
    footer = doc.add_paragraph()
    footer.alignment = WD_ALIGN_PARAGRAPH.CENTER
    footer.add_run("Â© 2025 AMORE Pacific - Confidential").italic = True

    # BytesIOë¡œ ì €ì¥
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)

    # íŒŒì¼ëª… ìƒì„±
    filename = f"AMORE_Insight_Report_{datetime.now().strftime('%Y%m%d_%H%M')}.docx"

    return StreamingResponse(
        buffer,
        media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )


# ============= Alert Settings API =============

from core.state_manager import StateManager, get_state_manager

# ì‹±ê¸€í†¤ State Manager
_state_manager: Optional[StateManager] = None

def get_app_state_manager() -> StateManager:
    """ì•± ë ˆë²¨ State Manager ë°˜í™˜"""
    global _state_manager
    if _state_manager is None:
        _state_manager = get_state_manager()
    return _state_manager


class AlertSettingsRequest(BaseModel):
    """ì•Œë¦¼ ì„¤ì • ìš”ì²­"""
    email: str
    consent: bool
    alert_types: List[str] = []


class AlertSettingsResponse(BaseModel):
    """ì•Œë¦¼ ì„¤ì • ì‘ë‹µ"""
    email: str
    consent: bool
    alert_types: List[str]
    consent_date: Optional[str] = None


@app.get("/api/v3/alert-settings")
async def get_alert_settings():
    """
    í˜„ì¬ ì•Œë¦¼ ì„¤ì • ì¡°íšŒ

    ì°¸ê³ : í˜„ì¬ëŠ” ë‹¨ì¼ ì‚¬ìš©ì ì„¤ì •ë§Œ ì§€ì› (ì²« ë²ˆì§¸ ë“±ë¡ëœ ì´ë©”ì¼)
    """
    state_manager = get_app_state_manager()
    subscriptions = state_manager.get_all_subscriptions()

    if not subscriptions:
        return {
            "email": "",
            "consent": False,
            "alert_types": [],
            "consent_date": None
        }

    # ì²« ë²ˆì§¸ êµ¬ë… ë°˜í™˜
    email, sub = next(iter(subscriptions.items()))
    return {
        "email": email,
        "consent": sub.consent,
        "alert_types": sub.alert_types,
        "consent_date": sub.consent_date.isoformat() if sub.consent_date else None
    }


@app.post("/api/v3/alert-settings")
async def save_alert_settings(request: AlertSettingsRequest):
    """
    ì•Œë¦¼ ì„¤ì • ì €ì¥

    ì¤‘ìš”: consentê°€ Trueì¼ ë•Œë§Œ ì´ë©”ì¼ ë“±ë¡
    """
    state_manager = get_app_state_manager()

    if not request.email:
        raise HTTPException(status_code=400, detail="ì´ë©”ì¼ ì£¼ì†Œê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    if request.consent:
        # ì´ë©”ì¼ ë“±ë¡ (ëª…ì‹œì  ë™ì˜)
        success = state_manager.register_email(
            email=request.email,
            consent=True,
            alert_types=request.alert_types
        )

        if not success:
            raise HTTPException(status_code=400, detail="ì´ë©”ì¼ ë“±ë¡ ì‹¤íŒ¨")

        return {"status": "ok", "message": "ì•Œë¦¼ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
    else:
        # ë™ì˜ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸ë§Œ (ì•Œë¦¼ ìœ í˜• ë³€ê²½)
        success = state_manager.update_email_subscription(
            email=request.email,
            alert_types=request.alert_types
        )

        return {"status": "ok", "message": "ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."}


@app.post("/api/v3/alert-settings/revoke")
async def revoke_alert_consent():
    """
    ì•Œë¦¼ ë™ì˜ ì² íšŒ

    ì²« ë²ˆì§¸ ë“±ë¡ëœ ì´ë©”ì¼ì˜ ë™ì˜ë¥¼ ì² íšŒí•©ë‹ˆë‹¤.
    """
    state_manager = get_app_state_manager()
    subscriptions = state_manager.get_all_subscriptions()

    if not subscriptions:
        return {"status": "ok", "message": "ì² íšŒí•  ë™ì˜ê°€ ì—†ìŠµë‹ˆë‹¤."}

    # ì²« ë²ˆì§¸ ì´ë©”ì¼ ì² íšŒ
    email = next(iter(subscriptions.keys()))
    state_manager.revoke_email_consent(email)

    return {"status": "ok", "message": "ë™ì˜ê°€ ì² íšŒë˜ì—ˆìŠµë‹ˆë‹¤."}


@app.get("/api/v3/alerts")
async def get_alerts(limit: int = 50, alert_type: Optional[str] = None):
    """
    ì•Œë¦¼ ëª©ë¡ ì¡°íšŒ

    Args:
        limit: ìµœëŒ€ ê°œìˆ˜
        alert_type: í•„í„°í•  ì•Œë¦¼ ìœ í˜•
    """
    from agents.alert_agent import AlertAgent

    state_manager = get_app_state_manager()
    alert_agent = AlertAgent(state_manager)

    return {
        "alerts": alert_agent.get_alerts(limit=limit, alert_type=alert_type),
        "pending_count": alert_agent.get_pending_count(),
        "stats": alert_agent.get_stats()
    }


# ============= ì„œë²„ ì‹¤í–‰ =============

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
