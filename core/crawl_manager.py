"""
Crawl Manager
ì¼ì¼ í¬ë¡¤ë§ ìƒíƒœ ê´€ë¦¬ ë° ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì„œë¹„ìŠ¤

í”Œë¡œìš°:
1. ì²« ì§ˆë¬¸ ì‹œ ì˜¤ëŠ˜ ë°ì´í„° ì²´í¬
2. ì—†ìœ¼ë©´ ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì‹œìž‘
3. í¬ë¡¤ë§ ì¤‘ì—ë„ ê³¼ê±° ë°ì´í„°ë¡œ ì‘ë‹µ ê°€ëŠ¥
4. ì™„ë£Œ ì‹œ ë‹¤ìŒ ì‘ë‹µì— ì•Œë¦¼ í¬í•¨
"""

import asyncio
import json
import logging
from datetime import datetime, date
from pathlib import Path
from typing import Optional, Dict, Any, Callable
from enum import Enum
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)


class CrawlStatus(Enum):
    """í¬ë¡¤ë§ ìƒíƒœ"""
    IDLE = "idle"               # ëŒ€ê¸° ì¤‘
    RUNNING = "running"         # í¬ë¡¤ë§ ì§„í–‰ ì¤‘
    COMPLETED = "completed"     # ì™„ë£Œ
    FAILED = "failed"           # ì‹¤íŒ¨


@dataclass
class CrawlState:
    """í¬ë¡¤ë§ ìƒíƒœ ì •ë³´"""
    status: CrawlStatus = CrawlStatus.IDLE
    date: Optional[str] = None  # í¬ë¡¤ë§ ëŒ€ìƒ ë‚ ì§œ
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    progress: int = 0  # 0-100
    categories_done: int = 0
    categories_total: int = 0
    products_collected: int = 0
    error: Optional[str] = None

    # ì•Œë¦¼ í”Œëž˜ê·¸ (ì„¸ì…˜ë³„ë¡œ ê´€ë¦¬)
    notified_sessions: set = field(default_factory=set)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "status": self.status.value,
            "date": self.date,
            "started_at": self.started_at,
            "completed_at": self.completed_at,
            "progress": self.progress,
            "categories_done": self.categories_done,
            "categories_total": self.categories_total,
            "products_collected": self.products_collected,
            "error": self.error
        }


class CrawlManager:
    """ì¼ì¼ í¬ë¡¤ë§ ê´€ë¦¬ìž"""

    STATE_FILE = "./data/crawl_state.json"
    DATA_FILE = "./data/dashboard_data.json"

    def __init__(self):
        self.state = CrawlState()
        self._crawl_task: Optional[asyncio.Task] = None
        self._on_complete_callback: Optional[Callable] = None
        self._load_state()

    def _load_state(self):
        """ì €ìž¥ëœ ìƒíƒœ ë¡œë“œ"""
        try:
            if Path(self.STATE_FILE).exists():
                with open(self.STATE_FILE, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.state = CrawlState(
                        status=CrawlStatus(data.get("status", "idle")),
                        date=data.get("date"),
                        started_at=data.get("started_at"),
                        completed_at=data.get("completed_at"),
                        progress=data.get("progress", 0),
                        categories_done=data.get("categories_done", 0),
                        categories_total=data.get("categories_total", 0),
                        products_collected=data.get("products_collected", 0),
                        error=data.get("error")
                    )
        except Exception as e:
            logger.warning(f"Failed to load crawl state: {e}")

    def _save_state(self):
        """ìƒíƒœ ì €ìž¥"""
        try:
            Path(self.STATE_FILE).parent.mkdir(parents=True, exist_ok=True)
            with open(self.STATE_FILE, "w", encoding="utf-8") as f:
                json.dump(self.state.to_dict(), f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save crawl state: {e}")

    def get_data_date(self) -> Optional[str]:
        """í˜„ìž¬ ë°ì´í„°ì˜ ë‚ ì§œ ë°˜í™˜"""
        try:
            if Path(self.DATA_FILE).exists():
                with open(self.DATA_FILE, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    return data.get("metadata", {}).get("data_date")
        except Exception as e:
            logger.warning(f"Failed to read data date: {e}")
        return None

    def is_today_data_available(self) -> bool:
        """ì˜¤ëŠ˜ ë°ì´í„°ê°€ ìžˆëŠ”ì§€ í™•ì¸"""
        data_date = self.get_data_date()
        today = date.today().isoformat()
        return data_date == today

    def is_crawling(self) -> bool:
        """í¬ë¡¤ë§ ì§„í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
        return self.state.status == CrawlStatus.RUNNING

    def needs_crawl(self) -> bool:
        """í¬ë¡¤ë§ì´ í•„ìš”í•œì§€ í™•ì¸"""
        # ì´ë¯¸ ì§„í–‰ ì¤‘ì´ë©´ í•„ìš” ì—†ìŒ
        if self.is_crawling():
            return False

        # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ìžˆìœ¼ë©´ í•„ìš” ì—†ìŒ
        if self.is_today_data_available():
            return False

        # ì˜¤ëŠ˜ ì´ë¯¸ ì™„ë£Œí–ˆìœ¼ë©´ í•„ìš” ì—†ìŒ
        if (self.state.status == CrawlStatus.COMPLETED and
            self.state.date == date.today().isoformat()):
            return False

        return True

    def should_notify(self, session_id: str) -> bool:
        """í•´ë‹¹ ì„¸ì…˜ì— í¬ë¡¤ë§ ì™„ë£Œ ì•Œë¦¼ì´ í•„ìš”í•œì§€ í™•ì¸"""
        if self.state.status != CrawlStatus.COMPLETED:
            return False
        if self.state.date != date.today().isoformat():
            return False
        if session_id in self.state.notified_sessions:
            return False
        return True

    def mark_notified(self, session_id: str):
        """ì„¸ì…˜ì— ì•Œë¦¼ ì™„ë£Œ í‘œì‹œ"""
        self.state.notified_sessions.add(session_id)

    async def start_crawl(self, on_complete: Optional[Callable] = None) -> bool:
        """
        ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì‹œìž‘

        Returns:
            True if crawl started, False if already running
        """
        if self.is_crawling():
            logger.info("Crawl already in progress")
            return False

        self._on_complete_callback = on_complete
        self._crawl_task = asyncio.create_task(self._run_crawl())
        return True

    async def _run_crawl(self):
        """ì‹¤ì œ í¬ë¡¤ë§ ì‹¤í–‰"""
        from agents.crawler_agent import CrawlerAgent
        from agents.storage_agent import StorageAgent
        from tools.dashboard_exporter import DashboardExporter

        today = date.today().isoformat()

        # ìƒíƒœ ì´ˆê¸°í™”
        self.state = CrawlState(
            status=CrawlStatus.RUNNING,
            date=today,
            started_at=datetime.now().isoformat(),
            categories_total=5  # configì—ì„œ ê°€ì ¸ì˜¤ë©´ ë” ì¢‹ìŒ
        )
        self._save_state()

        logger.info(f"Starting daily crawl for {today}")

        try:
            # 1. í¬ë¡¤ë§ ì‹¤í–‰
            crawler = CrawlerAgent()
            await crawler.scraper.initialize()

            result = await crawler.execute()

            await crawler.scraper.close()

            if result.get("status") == "failed":
                raise Exception("All categories failed")

            self.state.products_collected = result.get("total_products", 0)
            self.state.categories_done = len(result.get("categories", {}))
            self.state.progress = 30
            self._save_state()

            logger.info(f"Crawl completed: {self.state.products_collected} products")

            # 2. Google Sheetsì— ë°ì´í„° ì €ìž¥
            logger.info("Saving data to Google Sheets...")
            storage = StorageAgent()
            storage_result = await storage.execute(result)

            self.state.progress = 60
            self._save_state()

            if storage_result.get("errors"):
                logger.warning(f"Storage warnings: {storage_result['errors']}")
            else:
                logger.info(f"Saved {storage_result.get('raw_records', 0)} records to Google Sheets")

            # 3. Dashboard ë°ì´í„° ìƒì„± (Google Sheetsì—ì„œ ì½ì–´ì˜´)
            exporter = DashboardExporter()
            await exporter.initialize()
            await exporter.export_dashboard_data(self.DATA_FILE)

            self.state.progress = 100
            self.state.status = CrawlStatus.COMPLETED
            self.state.completed_at = datetime.now().isoformat()
            self.state.notified_sessions = set()  # ì•Œë¦¼ ì´ˆê¸°í™”
            self._save_state()

            logger.info(f"Dashboard data exported for {today}")

            # SimpleChatService ìºì‹œ ë¬´íš¨í™”
            try:
                from core.simple_chat import get_chat_service
                chat_service = get_chat_service()
                chat_service.invalidate_cache()
                logger.info("Chat service cache invalidated")
            except Exception as e:
                logger.warning(f"Failed to invalidate chat cache: {e}")

            # ì™„ë£Œ ì½œë°± ì‹¤í–‰
            if self._on_complete_callback:
                try:
                    await self._on_complete_callback(self.state)
                except Exception as e:
                    logger.error(f"Complete callback error: {e}")

        except Exception as e:
            logger.error(f"Crawl failed: {e}")
            self.state.status = CrawlStatus.FAILED
            self.state.error = str(e)
            self.state.completed_at = datetime.now().isoformat()
            self._save_state()

    def get_status_message(self) -> str:
        """í˜„ìž¬ ìƒíƒœ ë©”ì‹œì§€ ë°˜í™˜"""
        if self.state.status == CrawlStatus.IDLE:
            data_date = self.get_data_date()
            if data_date:
                return f"ë§ˆì§€ë§‰ ë°ì´í„°: {data_date}"
            return "ë°ì´í„° ì—†ìŒ"

        elif self.state.status == CrawlStatus.RUNNING:
            return f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({self.state.progress}%)"

        elif self.state.status == CrawlStatus.COMPLETED:
            return f"ì˜¤ëŠ˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({self.state.products_collected}ê°œ ì œí’ˆ)"

        elif self.state.status == CrawlStatus.FAILED:
            return f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {self.state.error}"

        return "ì•Œ ìˆ˜ ì—†ìŒ"

    def get_notification_message(self) -> str:
        """í¬ë¡¤ë§ ì™„ë£Œ ì•Œë¦¼ ë©”ì‹œì§€"""
        return (
            f"ðŸ“Š **ì˜¤ëŠ˜({self.state.date}) ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**\n\n"
            f"- ìˆ˜ì§‘ ì œí’ˆ: {self.state.products_collected}ê°œ\n"
            f"- ìˆ˜ì§‘ ì¹´í…Œê³ ë¦¬: {self.state.categories_done}ê°œ\n"
            f"- ì™„ë£Œ ì‹œê°„: {self.state.completed_at}\n\n"
            "ì´ì œ ìµœì‹  ë°ì´í„°ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤."
        )


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_crawl_manager: Optional[CrawlManager] = None


def get_crawl_manager() -> CrawlManager:
    """CrawlManager ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _crawl_manager
    if _crawl_manager is None:
        _crawl_manager = CrawlManager()
    return _crawl_manager
