"""
Insight Agent
ì¸ì‚¬ì´íŠ¸ ìƒì„± ì—ì´ì „íŠ¸ (LLM ê¸°ë°˜)

.. deprecated::
    ì´ ëª¨ë“ˆì€ `HybridInsightAgent`ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.
    ìƒˆ ì½”ë“œì—ì„œëŠ” `from src.agents import HybridInsightAgent`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

    HybridInsightAgentëŠ” Ontology ê¸°ë°˜ ì¶”ë¡ ê³¼ RAGë¥¼ ê²°í•©í•˜ì—¬
    ë” ì •í™•í•˜ê³  ë§¥ë½ì— ë§ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
import warnings

warnings.warn(
    "InsightAgent is deprecated. Use HybridInsightAgent instead. "
    "See: from src.agents import HybridInsightAgent",
    DeprecationWarning,
    stacklevel=2
)

import json
import os
from datetime import datetime
from typing import Dict, Any, List, Optional

from litellm import acompletion
from src.rag.retriever import DocumentRetriever
from src.rag.templates import ResponseTemplates
from src.monitoring.logger import AgentLogger
from src.monitoring.tracer import ExecutionTracer
from src.monitoring.metrics import QualityMetrics


class InsightAgent:
    """ì¸ì‚¬ì´íŠ¸ ìƒì„± ì—ì´ì „íŠ¸"""

    def __init__(
        self,
        model: str = "gpt-4.1-mini",
        docs_dir: str = "./docs",
        logger: Optional[AgentLogger] = None,
        tracer: Optional[ExecutionTracer] = None,
        metrics: Optional[QualityMetrics] = None
    ):
        """
        Args:
            model: LLM ëª¨ë¸ëª…
            docs_dir: RAG ë¬¸ì„œ ë””ë ‰í† ë¦¬
            logger: ë¡œê±°
            tracer: ì¶”ì ê¸°
            metrics: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
        """
        self.model = model
        self.retriever = DocumentRetriever(docs_dir)
        self.templates = ResponseTemplates()
        self.logger = logger or AgentLogger("insight")
        self.tracer = tracer
        self.metrics = metrics

        self._results: Dict[str, Any] = {}

    async def execute(
        self,
        metrics_data: Dict[str, Any],
        crawl_summary: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ì¸ì‚¬ì´íŠ¸ ìƒì„±

        Args:
            metrics_data: ì§€í‘œ ì—ì´ì „íŠ¸ ê²°ê³¼
            crawl_summary: í¬ë¡¤ë§ ìš”ì•½ (ì„ íƒ)

        Returns:
            {
                "status": "completed",
                "daily_insight": "...",
                "action_items": [...],
                "highlights": [...]
            }
        """
        self.logger.agent_start("InsightAgent", "ì¸ì‚¬ì´íŠ¸ ìƒì„±")
        start_time = datetime.now()

        if self.metrics:
            self.metrics.record_agent_start("insight")

        if self.tracer:
            self.tracer.start_span("insight_agent")

        try:
            results = {
                "status": "completed",
                "generated_at": datetime.now().isoformat(),
                "daily_insight": "",
                "action_items": [],
                "highlights": [],
                "warnings": []
            }

            # 1. RAG ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            if self.tracer:
                self.tracer.start_span("retrieve_context")

            rag_context = await self._build_rag_context(metrics_data)

            if self.tracer:
                self.tracer.end_span("completed")

            # 2. ì¼ì¼ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            if self.tracer:
                self.tracer.start_span("generate_daily_insight")

            daily_insight = await self._generate_daily_insight(
                metrics_data, crawl_summary, rag_context
            )
            results["daily_insight"] = daily_insight

            if self.tracer:
                self.tracer.end_span("completed")

            # 3. ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ
            if self.tracer:
                self.tracer.start_span("extract_actions")

            action_items = await self._extract_action_items(
                metrics_data, daily_insight
            )
            results["action_items"] = action_items

            if self.tracer:
                self.tracer.end_span("completed")

            # 4. í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
            results["highlights"] = self._extract_highlights(metrics_data)

            # 5. ê²½ê³  ì‚¬í•­ ìˆ˜ì§‘
            alerts = metrics_data.get("alerts", [])
            results["warnings"] = [
                a for a in alerts
                if a.get("severity") in ["warning", "critical"]
            ]

            self._results = results
            duration = (datetime.now() - start_time).total_seconds()

            if self.tracer:
                self.tracer.end_span("completed")

            if self.metrics:
                self.metrics.record_agent_complete("insight", {
                    "action_items": len(results["action_items"]),
                    "highlights": len(results["highlights"])
                })

            self.logger.agent_complete(
                "InsightAgent",
                duration,
                f"{len(results['action_items'])} actions, {len(results['highlights'])} highlights"
            )

            return results

        except Exception as e:
            duration = (datetime.now() - start_time).total_seconds()

            if self.tracer:
                self.tracer.end_span("failed", str(e))

            if self.metrics:
                self.metrics.record_agent_error("insight", str(e))

            self.logger.agent_error("InsightAgent", str(e), duration)
            raise

    async def _build_rag_context(self, metrics_data: Dict) -> str:
        """RAG ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•"""
        contexts = []

        # retriever ì´ˆê¸°í™” í™•ì¸
        if not self.retriever._initialized:
            await self.retriever.initialize()

        # ì§€í‘œ í•´ì„ ê°€ì´ë“œ ê²€ìƒ‰
        summary = metrics_data.get("summary", {})

        # SoS ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸
        sos_data = summary.get("laneige_sos_by_category", {})
        if sos_data:
            sos_context = await self.retriever.get_relevant_context(
                f"SoS ì ìœ ìœ¨ í•´ì„ {list(sos_data.values())}"
            )
            if sos_context:
                contexts.append(sos_context)

        # ì•Œë¦¼ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸
        alerts = metrics_data.get("alerts", [])
        if alerts:
            alert_types = set(a.get("type") for a in alerts)
            for alert_type in alert_types:
                alert_context = await self.retriever.get_relevant_context(
                    f"{alert_type} ì•Œë¦¼ ëŒ€ì‘"
                )
                if alert_context:
                    contexts.append(alert_context)

        return "\n\n---\n\n".join(contexts) if contexts else ""

    async def _generate_daily_insight(
        self,
        metrics_data: Dict,
        crawl_summary: Optional[Dict],
        rag_context: str
    ) -> str:
        """ì¼ì¼ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = self.templates.get_system_prompt()

        # ë°ì´í„° ìš”ì•½
        summary = metrics_data.get("summary", {})
        brand_metrics = metrics_data.get("brand_metrics", [])
        product_metrics = metrics_data.get("product_metrics", [])
        alerts = metrics_data.get("alerts", [])

        # LANEIGE ì§€í‘œ ì¶”ì¶œ
        laneige_brands = [b for b in brand_metrics if b.get("is_laneige")]

        data_summary = f"""
## ì˜¤ëŠ˜ì˜ ë°ì´í„° ìš”ì•½

### LANEIGE ì œí’ˆ í˜„í™©
- ì¶”ì  ì¤‘ì¸ ì œí’ˆ ìˆ˜: {summary.get('laneige_products_tracked', 0)}ê°œ
- ì¹´í…Œê³ ë¦¬ë³„ ì ìœ ìœ¨(SoS):
{self._format_sos(summary.get('laneige_sos_by_category', {}))}

### ë² ìŠ¤íŠ¸ ìˆœìœ„ ì œí’ˆ
{self._format_best_product(summary.get('best_ranking_product'))}

### ì•Œë¦¼ í˜„í™©
- ì „ì²´ ì•Œë¦¼: {summary.get('alert_count', 0)}ê±´
- ì‹¬ê°(Critical): {summary.get('critical_alerts', 0)}ê±´
- ê²½ê³ (Warning): {summary.get('warning_alerts', 0)}ê±´

{self._format_alerts(alerts[:5]) if alerts else "- íŠ¹ì´ì‚¬í•­ ì—†ìŒ"}
"""

        user_prompt = f"""
ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ LANEIGE Amazon ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

{data_summary}

## ì°¸ê³  ê°€ì´ë“œë¼ì¸
{rag_context if rag_context else "- ê¸°ë³¸ í•´ì„ ê¸°ì¤€ ì ìš©"}

ìš”êµ¬ì‚¬í•­:
1. 3-5ë¬¸ì¥ì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìš”ì•½
2. ì£¼ëª©í•´ì•¼ í•  ìˆœìœ„ ë³€ë™ ì‚¬í•­
3. ì¹´í…Œê³ ë¦¬ë³„ LANEIGE í¬ì§€ì…˜ í‰ê°€
4. ê²½ìŸì‚¬ ëŒ€ë¹„ ì‹œì‚¬ì  (ìˆëŠ” ê²½ìš°)

ì£¼ì˜: ë‹¨ì •ì  í‘œí˜„ì„ í”¼í•˜ê³ , ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
"""

        try:
            response = await acompletion(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )

            insight = response.choices[0].message.content

            # í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡
            if self.metrics and hasattr(response, 'usage'):
                self.metrics.record_llm_call(
                    model=self.model,
                    prompt_tokens=response.usage.prompt_tokens,
                    completion_tokens=response.usage.completion_tokens,
                    latency_ms=0,  # TODO: ì‹¤ì œ latency ì¸¡ì •
                    cost=self._estimate_cost(
                        response.usage.prompt_tokens,
                        response.usage.completion_tokens
                    )
                )

            # ê°€ë“œë ˆì¼ ì ìš©
            insight = self.templates.apply_guardrails(insight)

            return insight

        except Exception as e:
            self.logger.error(f"LLM call failed: {e}")
            return self._generate_fallback_insight(metrics_data)

    async def _extract_action_items(
        self,
        metrics_data: Dict,
        daily_insight: str
    ) -> List[Dict]:
        """ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
        alerts = metrics_data.get("alerts", [])
        actions = []

        # ì•Œë¦¼ ê¸°ë°˜ ì•¡ì…˜
        for alert in alerts:
            if alert.get("severity") == "critical":
                actions.append({
                    "priority": "high",
                    "type": alert.get("type"),
                    "action": f"[ê¸´ê¸‰] {alert.get('message')} - ì¦‰ì‹œ í™•ì¸ í•„ìš”",
                    "product": alert.get("title"),
                    "asin": alert.get("asin")
                })
            elif alert.get("severity") == "warning":
                actions.append({
                    "priority": "medium",
                    "type": alert.get("type"),
                    "action": f"[ì£¼ì˜] {alert.get('message')} - ëª¨ë‹ˆí„°ë§ ê°•í™”",
                    "product": alert.get("title"),
                    "asin": alert.get("asin")
                })

        # ì •ë ¬ (ìš°ì„ ìˆœìœ„)
        priority_order = {"high": 0, "medium": 1, "low": 2}
        actions.sort(key=lambda x: priority_order.get(x.get("priority"), 3))

        return actions[:10]  # ìµœëŒ€ 10ê°œ

    def _extract_highlights(self, metrics_data: Dict) -> List[Dict]:
        """í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ"""
        highlights = []
        product_metrics = metrics_data.get("product_metrics", [])
        summary = metrics_data.get("summary", {})

        # Top 10 ì§„ì… ì œí’ˆ
        top10_products = [
            p for p in product_metrics
            if p.get("current_rank", 100) <= 10
        ]
        for p in top10_products:
            highlights.append({
                "type": "top_rank",
                "title": f"Top 10 ì§„ì…: {p.get('product_title', '')[:30]}",
                "detail": f"{p.get('category_id')} ì¹´í…Œê³ ë¦¬ {p.get('current_rank')}ìœ„",
                "asin": p.get("asin")
            })

        # ìˆœìœ„ ìƒìŠ¹ ì œí’ˆ
        improving = [
            p for p in product_metrics
            if p.get("rank_change_1d") and p.get("rank_change_1d") < -3
        ]
        for p in improving[:3]:
            highlights.append({
                "type": "rank_up",
                "title": f"ìˆœìœ„ ìƒìŠ¹: {p.get('product_title', '')[:30]}",
                "detail": f"{abs(p.get('rank_change_1d'))}ë‹¨ê³„ ìƒìŠ¹ â†’ í˜„ì¬ {p.get('current_rank')}ìœ„",
                "asin": p.get("asin")
            })

        # ë†’ì€ SoS ì¹´í…Œê³ ë¦¬
        sos_data = summary.get("laneige_sos_by_category", {})
        for cat, sos in sos_data.items():
            if sos >= 0.05:  # 5% ì´ìƒ
                highlights.append({
                    "type": "high_sos",
                    "title": f"ë†’ì€ ì ìœ ìœ¨: {cat}",
                    "detail": f"SoS {sos*100:.1f}%",
                    "category": cat
                })

        return highlights[:10]

    def _format_sos(self, sos_data: Dict) -> str:
        """SoS í¬ë§·íŒ…"""
        if not sos_data:
            return "  - ë°ì´í„° ì—†ìŒ"

        lines = []
        for cat, sos in sos_data.items():
            lines.append(f"  - {cat}: {sos*100:.1f}%")
        return "\n".join(lines)

    def _format_best_product(self, product: Optional[Dict]) -> str:
        """ë² ìŠ¤íŠ¸ ì œí’ˆ í¬ë§·íŒ…"""
        if not product:
            return "- ë°ì´í„° ì—†ìŒ"

        return f"""- ì œí’ˆ: {product.get('title', '')[:50]}
- ìˆœìœ„: {product.get('rank')}ìœ„
- ì¹´í…Œê³ ë¦¬: {product.get('category')}"""

    def _format_alerts(self, alerts: List[Dict]) -> str:
        """ì•Œë¦¼ í¬ë§·íŒ…"""
        if not alerts:
            return ""

        lines = ["### ì£¼ìš” ì•Œë¦¼"]
        for a in alerts:
            severity = {"critical": "ğŸ”´", "warning": "ğŸŸ¡", "info": "ğŸ”µ"}.get(
                a.get("severity"), "âšª"
            )
            lines.append(f"- {severity} {a.get('message')}")

        return "\n".join(lines)

    def _generate_fallback_insight(self, metrics_data: Dict) -> str:
        """í´ë°± ì¸ì‚¬ì´íŠ¸ ìƒì„± (LLM ì‹¤íŒ¨ ì‹œ)"""
        summary = metrics_data.get("summary", {})

        insight = f"""ì˜¤ëŠ˜ LANEIGE Amazon ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.

- ì¶”ì  ì¤‘ì¸ ì œí’ˆ: {summary.get('laneige_products_tracked', 0)}ê°œ
- ì•Œë¦¼: {summary.get('alert_count', 0)}ê±´ (Critical: {summary.get('critical_alerts', 0)}, Warning: {summary.get('warning_alerts', 0)})

â€» ìƒì„¸ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê¸°ë³¸ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤."""

        return insight

    def _estimate_cost(self, prompt_tokens: int, completion_tokens: int) -> float:
        """ë¹„ìš© ì¶”ì • (GPT-4.1-mini ê¸°ì¤€)"""
        # $0.40/1M input, $1.60/1M output
        input_cost = (prompt_tokens / 1_000_000) * 0.40
        output_cost = (completion_tokens / 1_000_000) * 1.60
        return round(input_cost + output_cost, 6)

    def get_results(self) -> Dict[str, Any]:
        """ë§ˆì§€ë§‰ ì‹¤í–‰ ê²°ê³¼"""
        return self._results
