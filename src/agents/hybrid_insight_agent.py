"""
Hybrid Insight Agent
Ontology-RAG í•˜ì´ë¸Œë¦¬ë“œ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì—ì´ì „íŠ¸

Flow:
1. í˜„ì¬ ë°ì´í„°ë¡œ Knowledge Graph ì—…ë°ì´íŠ¸
2. Ontology Reasonerë¡œ ê·œì¹™ ê¸°ë°˜ ì¶”ë¡ 
3. RAGë¡œ ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
4. ì¶”ë¡  ê²°ê³¼ + RAG ì»¨í…ìŠ¤íŠ¸ë¡œ LLM ì¸ì‚¬ì´íŠ¸ ìƒì„±
"""

from datetime import datetime
from typing import Any

from litellm import acompletion

from src.domain.entities.relations import (
    InferenceResult,
    InsightType,
    Relation,
    RelationType,
)
from src.monitoring.logger import AgentLogger
from src.monitoring.metrics import QualityMetrics
from src.monitoring.tracer import ExecutionTracer
from src.ontology.business_rules import register_all_rules
from src.ontology.knowledge_graph import KnowledgeGraph
from src.ontology.reasoner import OntologyReasoner
from src.rag.context_builder import ContextBuilder
from src.rag.hybrid_retriever import HybridContext, HybridRetriever
from src.rag.retriever import DocumentRetriever
from src.rag.templates import ResponseTemplates
from src.tools.external_signal_collector import ExternalSignalCollector
from src.tools.insight_formatter import format_insight
from src.tools.market_intelligence import DataLayer, MarketIntelligenceEngine
from src.tools.source_manager import InsightSourceBuilder

# New collectors (Phase 1 & 2)
try:
    from src.tools.google_trends_collector import GoogleTrendsCollector

    GOOGLE_TRENDS_AVAILABLE = True
except ImportError as e:
    from src.monitoring.logger import get_logger

    _logger = get_logger("hybrid_insight")
    _logger.warning(
        f"GoogleTrendsCollector not available - Google Trends signals will be skipped: {e}"
    )
    GOOGLE_TRENDS_AVAILABLE = False


class HybridInsightAgent:
    """
    Ontology-RAG í•˜ì´ë¸Œë¦¬ë“œ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì—ì´ì „íŠ¸

    ê¸°ì¡´ InsightAgentì™€ì˜ ì°¨ì´ì :
    - ì˜¨í†¨ë¡œì§€ ì¶”ë¡  ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
    - ê·œì¹™ ê¸°ë°˜ ì¶”ë¡ ìœ¼ë¡œ ì¼ê´€ì„± ë³´ì¥
    - ì¶”ë¡  ê³¼ì • ì„¤ëª… ê°€ëŠ¥ (Explainability)

    ì‚¬ìš© ì˜ˆ:
        agent = HybridInsightAgent(model="gpt-4.1-mini")
        result = await agent.execute(metrics_data)
    """

    def __init__(
        self,
        model: str = "gpt-4.1-mini",
        docs_dir: str = ".",
        knowledge_graph: KnowledgeGraph | None = None,
        reasoner: OntologyReasoner | None = None,
        logger: AgentLogger | None = None,
        tracer: ExecutionTracer | None = None,
        metrics: QualityMetrics | None = None,
    ):
        """
        Args:
            model: LLM ëª¨ë¸ëª…
            docs_dir: RAG ë¬¸ì„œ ë””ë ‰í† ë¦¬
            knowledge_graph: ì§€ì‹ ê·¸ë˜í”„ (ê³µìœ  ê°€ëŠ¥)
            reasoner: ì¶”ë¡ ê¸° (ê³µìœ  ê°€ëŠ¥)
            logger: ë¡œê±°
            tracer: ì¶”ì ê¸°
            metrics: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
        """
        import os

        self.model = model
        # Temperature: ì¸ì‚¬ì´íŠ¸ ì „ìš© í™˜ê²½ë³€ìˆ˜ > ì¼ë°˜ í™˜ê²½ë³€ìˆ˜ > ê¸°ë³¸ê°’(0.6)
        # ì¸ì‚¬ì´íŠ¸ëŠ” ì°½ì˜ì  ë¶„ì„/ì „ëµ ì œì•ˆì„ ìœ„í•´ ì•½ê°„ ë†’ì€ temperature ì‚¬ìš© (E2E Audit - 2026-01-27)
        from src.shared.constants import INSIGHT_TEMPERATURE

        self.temperature = float(
            os.getenv(
                "LLM_INSIGHT_TEMPERATURE",
                os.getenv("LLM_TEMPERATURE", str(INSIGHT_TEMPERATURE)),
            )
        )

        # ì˜¨í†¨ë¡œì§€ ì»´í¬ë„ŒíŠ¸
        self.kg = knowledge_graph or KnowledgeGraph()
        self.reasoner = reasoner or OntologyReasoner(self.kg)

        # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ë“±ë¡
        if not self.reasoner.rules:
            register_all_rules(self.reasoner)

        # RAG ì»´í¬ë„ŒíŠ¸
        self.doc_retriever = DocumentRetriever(docs_dir)

        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°
        self.hybrid_retriever = HybridRetriever(
            knowledge_graph=self.kg,
            reasoner=self.reasoner,
            doc_retriever=self.doc_retriever,
            auto_init_rules=False,  # ì´ë¯¸ ë“±ë¡ë¨
        )

        # ì»¨í…ìŠ¤íŠ¸ ë¹Œë”
        self.context_builder = ContextBuilder(max_tokens=4000)

        # í…œí”Œë¦¿
        self.templates = ResponseTemplates()

        # ëª¨ë‹ˆí„°ë§
        self.logger = logger or AgentLogger("hybrid_insight")
        self.tracer = tracer
        self.metrics = metrics

        # ê²°ê³¼ ìºì‹œ
        self._results: dict[str, Any] = {}
        self._last_hybrid_context: HybridContext | None = None

        # External Signal Collector
        self._signal_collector: ExternalSignalCollector | None = None

        # Market Intelligence Engine
        self._market_intelligence: MarketIntelligenceEngine | None = None
        self._insight_source_builder: InsightSourceBuilder | None = None

        # New collectors (Phase 1)
        self._google_trends: GoogleTrendsCollector | None = None

    async def execute(
        self,
        metrics_data: dict[str, Any],
        crawl_data: dict[str, Any] | None = None,
        crawl_summary: dict | None = None,
    ) -> dict[str, Any]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì¸ì‚¬ì´íŠ¸ ìƒì„±

        Args:
            metrics_data: ì§€í‘œ ì—ì´ì „íŠ¸ ê²°ê³¼
            crawl_data: í¬ë¡¤ë§ ì›ë³¸ ë°ì´í„° (KG ì—…ë°ì´íŠ¸ìš©)
            crawl_summary: í¬ë¡¤ë§ ìš”ì•½

        Returns:
            {
                "status": "completed",
                "daily_insight": "...",
                "action_items": [...],
                "highlights": [...],
                "inferences": [...],
                "explanations": [...]
            }
        """
        self.logger.agent_start("HybridInsightAgent", "í•˜ì´ë¸Œë¦¬ë“œ ì¸ì‚¬ì´íŠ¸ ìƒì„±")
        start_time = datetime.now()

        if self.metrics:
            self.metrics.record_agent_start("hybrid_insight")

        if self.tracer:
            self.tracer.start_span("hybrid_insight_agent")

        try:
            # ë°ì´í„° ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
            data_source = self._extract_data_source_info(metrics_data, crawl_data)

            results = {
                "status": "completed",
                "generated_at": datetime.now().isoformat(),
                "data_source": data_source,  # ë°ì´í„° ì¶œì²˜ ì •ë³´ ì¶”ê°€
                "daily_insight": "",
                "action_items": [],
                "highlights": [],
                "warnings": [],
                "inferences": [],
                "explanations": [],
                "hybrid_stats": {},
            }

            # 1. Knowledge Graph ì—…ë°ì´íŠ¸
            if self.tracer:
                self.tracer.start_span("update_knowledge_graph")

            kg_stats = self._update_knowledge_graph(crawl_data, metrics_data)
            results["hybrid_stats"]["kg_update"] = kg_stats

            if self.tracer:
                self.tracer.end_span("completed")

            # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ì¶”ë¡  + RAG)
            if self.tracer:
                self.tracer.start_span("hybrid_retrieval")

            hybrid_context = await self._run_hybrid_retrieval(metrics_data)
            self._last_hybrid_context = hybrid_context
            results["inferences"] = [inf.to_dict() for inf in hybrid_context.inferences]

            if self.tracer:
                self.tracer.end_span("completed")

            # 3. RAG â†’ KG ì§€ì‹ ì¶”ì¶œ
            rag_kg_stats = self._ingest_rag_knowledge(hybrid_context.rag_chunks)
            results["hybrid_stats"]["rag_to_kg"] = rag_kg_stats

            # 4. ì¶”ë¡  ì„¤ëª… ìƒì„±
            if self.tracer:
                self.tracer.start_span("generate_explanations")

            explanations = self._generate_explanations(hybrid_context.inferences)
            results["explanations"] = explanations

            if self.tracer:
                self.tracer.end_span("completed")

            # 5. External Signal ìˆ˜ì§‘ (LLM í˜¸ì¶œ ì „ì— ìˆ˜í–‰)
            if self.tracer:
                self.tracer.start_span("collect_external_signals")

            external_signals = await self._collect_external_signals()
            results["external_signals"] = external_signals
            signal_kg_stats = self._ingest_external_signals(external_signals)
            results["hybrid_stats"]["signal_to_kg"] = signal_kg_stats

            # ì‹¤íŒ¨í•œ ì‹ í˜¸ ìˆ˜ì§‘ê¸° ì¶”ì 
            results["failed_signals"] = self._get_failed_signal_collectors()

            if self.tracer:
                self.tracer.end_span("completed")

            # 5.5. Market Intelligence ìˆ˜ì§‘ (Layer 2-4)
            if self.tracer:
                self.tracer.start_span("collect_market_intelligence")

            market_intelligence = await self._collect_market_intelligence()
            results["market_intelligence"] = market_intelligence

            if self.tracer:
                self.tracer.end_span("completed")

            # 6. ì¼ì¼ ì¸ì‚¬ì´íŠ¸ ìƒì„± (LLM + External Signal + Market Intelligence í¬í•¨)
            if self.tracer:
                self.tracer.start_span("generate_daily_insight")

            daily_insight = await self._generate_daily_insight(
                hybrid_context,
                metrics_data,
                crawl_summary,
                external_signals,
                market_intelligence,
                results.get("failed_signals", []),
            )
            results["daily_insight"] = daily_insight

            if self.tracer:
                self.tracer.end_span("completed")

            # 7. ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ
            if self.tracer:
                self.tracer.start_span("extract_actions")

            action_items = self._extract_action_items(hybrid_context.inferences, metrics_data)
            results["action_items"] = action_items

            if self.tracer:
                self.tracer.end_span("completed")

            # 8. í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
            results["highlights"] = self._extract_highlights(
                hybrid_context.inferences, metrics_data
            )

            # 9. ê²½ê³  ìˆ˜ì§‘
            alerts = metrics_data.get("alerts", [])
            results["warnings"] = [
                a for a in alerts if a.get("severity") in ["warning", "critical"]
            ]

            if self.tracer:
                self.tracer.end_span("completed")

            # 10. í†µê³„
            results["hybrid_stats"].update(
                {
                    "inferences_count": len(hybrid_context.inferences),
                    "rag_chunks_count": len(hybrid_context.rag_chunks),
                    "ontology_facts_count": len(hybrid_context.ontology_facts),
                    "external_signals_count": len(external_signals.get("signals", [])),
                    "market_intelligence_sources": len(market_intelligence.get("sources", [])),
                }
            )

            self._results = results
            duration = (datetime.now() - start_time).total_seconds()

            if self.tracer:
                self.tracer.end_span("completed")

            if self.metrics:
                self.metrics.record_agent_complete(
                    "hybrid_insight",
                    {
                        "action_items": len(results["action_items"]),
                        "inferences": len(results["inferences"]),
                    },
                )

            self.logger.agent_complete(
                "HybridInsightAgent",
                duration,
                f"{len(results['inferences'])} inferences, {len(results['action_items'])} actions",
            )

            return results

        except Exception as e:
            duration = (datetime.now() - start_time).total_seconds()

            if self.tracer:
                self.tracer.end_span("failed", str(e))

            if self.metrics:
                self.metrics.record_agent_error("hybrid_insight", str(e))

            self.logger.agent_error("HybridInsightAgent", str(e), duration)
            raise

    def _update_knowledge_graph(
        self, crawl_data: dict | None, metrics_data: dict
    ) -> dict[str, int]:
        """Knowledge Graph ì—…ë°ì´íŠ¸"""
        stats = {"crawl_relations": 0, "metrics_relations": 0}

        if crawl_data:
            stats["crawl_relations"] = self.kg.load_from_crawl_data(crawl_data)
            self.logger.debug(f"KG updated from crawl: {stats['crawl_relations']} relations")

        if metrics_data:
            stats["metrics_relations"] = self.kg.load_from_metrics_data(metrics_data)
            self.logger.debug(f"KG updated from metrics: {stats['metrics_relations']} relations")

        return stats

    async def _run_hybrid_retrieval(self, metrics_data: dict) -> HybridContext:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰"""
        # ì¼ì¼ ì¸ì‚¬ì´íŠ¸ìš© ì¿¼ë¦¬
        query = "LANEIGE ì˜¤ëŠ˜ì˜ Amazon ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì„±ê³¼ ë¶„ì„"

        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        context = await self.hybrid_retriever.retrieve(
            query=query, current_metrics=metrics_data, include_explanations=True
        )

        self.logger.info(
            f"Hybrid retrieval: {len(context.inferences)} inferences, "
            f"{len(context.rag_chunks)} RAG chunks"
        )

        return context

    def _generate_explanations(self, inferences: list[InferenceResult]) -> list[dict[str, Any]]:
        """ì¶”ë¡  ì„¤ëª… ìƒì„±"""
        explanations = []

        for inf in inferences:
            explanation = {
                "rule": inf.rule_name,
                "type": inf.insight_type.value,
                "insight": inf.insight,
                "explanation": self.reasoner.explain_inference(inf),
                "confidence": inf.confidence,
            }
            explanations.append(explanation)

        return explanations

    async def _generate_daily_insight(
        self,
        hybrid_context: HybridContext,
        metrics_data: dict,
        crawl_summary: dict | None,
        external_signals: dict | None = None,
        market_intelligence: dict | None = None,
        failed_signals: list[str] | None = None,
    ) -> str:
        """ì¼ì¼ ì¸ì‚¬ì´íŠ¸ ìƒì„± (LLM)"""
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self.context_builder.build(
            hybrid_context=hybrid_context,
            current_metrics=metrics_data,
            query="ì˜¤ëŠ˜ì˜ LANEIGE Amazon ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì¸ì‚¬ì´íŠ¸",
            knowledge_graph=self.kg,
        )

        # External Signal ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        external_context = ""
        if external_signals and external_signals.get("report_section"):
            external_context = f"""

## ì™¸ë¶€ íŠ¸ë Œë“œ ì‹ í˜¸

{external_signals["report_section"]}

_â€» ìœ„ ì™¸ë¶€ ì‹ í˜¸ëŠ” ì „ë¬¸ ë§¤ì²´(Allure, Byrdie ë“±), Reddit, TikTok ë“±ì—ì„œ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤._
"""

        # Market Intelligence ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        market_context = ""
        if market_intelligence and market_intelligence.get("insight_section"):
            market_context = f"""

## ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ (4-Layer ë¶„ì„)

{market_intelligence["insight_section"]}

"""

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = self.context_builder.build_system_prompt(include_guardrails=True)

        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (4-Layer Why ë¶„ì„ í…œí”Œë¦¿)
        reference_section = self._build_reference_section(
            hybrid_context, external_signals, market_intelligence
        )
        user_prompt = f"""
{context}
{external_context}
{market_context}
{reference_section}
---

## ìš”ì²­ì‚¬í•­

ìœ„ ë¶„ì„ ê²°ê³¼ì™€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ LANEIGE Amazon US ì¼ì¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

### ì¶œë ¥ í˜•ì‹ (AMOREPACIFIC ìŠ¤íƒ€ì¼ - ë°˜ë“œì‹œ ì´ êµ¬ì¡°ì™€ ìˆœì„œë¥¼ ë”°ë¥´ì„¸ìš”):

```markdown
# LANEIGE Amazon US ê²½ìŸë ¥ ë¶„ì„ ë³´ê³ ì„œ

ë¶„ì„ ê¸°ê°„: 2026-01-01 ~ 2026-01-28
ìƒì„±ì¼ì‹œ: 2026-01-28 04:30

---

## ëª©ì°¨
1. ì˜¤ëŠ˜ì˜ í•µì‹¬
2. ì›ì¸ ë¶„ì„ (Why?)
   - Layer 4: ê±°ì‹œê²½ì œ/ë¬´ì—­
   - Layer 3: ì‚°ì—…/ê¸°ì—… ë™í–¥
   - Layer 2: ì†Œë¹„ì íŠ¸ë Œë“œ
   - Layer 1: Amazon ì„±ê³¼
3. ì£¼ì˜ ì‚¬í•­
4. ì „ëµ ì œì–¸
5. ì°¸ê³ ìë£Œ

---

â–**1. ì˜¤ëŠ˜ì˜ í•µì‹¬**
â€¢ ë¼ë„¤ì¦ˆ ë¦½ ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ ìˆœìœ„ ìƒìŠ¹ (**+3**ë‹¨ê³„ â†’ í˜„ì¬ **#4**) [1]
â€¢ SoS **+2.1%p** ì¦ê°€ (ì „ì¼ ëŒ€ë¹„)
[ê°€ì¥ ì¤‘ìš”í•œ ë³€í™” 1-2ê°€ì§€ë¥¼ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì‘ì„±]

â–**2. ì›ì¸ ë¶„ì„ (Why?)**

**Layer 4: ê±°ì‹œê²½ì œ/ë¬´ì—­**
â€¢ ê´€ì„¸ì²­ ìˆ˜ì¶œì… ë°ì´í„°: í™”ì¥í’ˆ ìˆ˜ì¶œ ì „ì›”ë¹„ **+12.3%** [1]
â€¢ ì›/ë‹¬ëŸ¬ í™˜ìœ¨ ì•ˆì •ì„¸ ìœ ì§€

**Layer 3: ì‚°ì—…/ê¸°ì—… ë™í–¥**
â€¢ ì•„ëª¨ë ˆí¼ì‹œí”½ 3Q ì˜ì—…ì´ìµ **+41%** YoY [2]
â€¢ Americas ë§¤ì¶œ **+6.9%** ì„±ì¥

**Layer 2: ì†Œë¹„ì íŠ¸ë Œë“œ**
â€¢ Reddit r/AsianBeauty ë¼ë„¤ì¦ˆ ì–¸ê¸‰ **+34%** [3]
â€¢ TikTok #LipSleepingMask ì¡°íšŒìˆ˜ 2.4M

**Layer 1: Amazon ì„±ê³¼**
â€¢ Lip Care ì¹´í…Œê³ ë¦¬ SoS: **8.2%** (ì „ì£¼ 7.1%)
â€¢ Top 10 ì§„ì… ì œí’ˆ: **3ê°œ** (ìœ ì§€)
â€¢ ì½”ìŠ¤ì•Œì—‘ìŠ¤ ëŒ€ë¹„ ê°€ê²© ê²½ìŸë ¥ ìœ ì§€

â–**3. ì£¼ì˜ ì‚¬í•­**
â€¢ ì½”ìŠ¤ì•Œì—‘ìŠ¤ ì‹ ì œí’ˆ ì¶œì‹œ ì˜ˆì • - ì ìœ ìœ¨ ë³€ë™ ëª¨ë‹ˆí„°ë§ í•„ìš”
â€¢ [ë¦¬ìŠ¤í¬ ë˜ëŠ” ëª¨ë‹ˆí„°ë§ í•„ìš” ì‚¬í•­]

â–**4. ì „ëµ ì œì–¸**
1. [ì¦‰ì‹œ ì‹¤í–‰] ì¬ê³  í™•ë³´ - ë¦½ ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ ìˆ˜ìš” ì¦ê°€ ëŒ€ë¹„
2. [ëª¨ë‹ˆí„°ë§] ì½”ìŠ¤ì•Œì—‘ìŠ¤ ì‹ ì œí’ˆ ì¶œì‹œ ë™í–¥ ì£¼ì‹œ
3. [ê²€í†  í•„ìš”] í™€ë¦¬ë°ì´ ì‹œì¦Œ í”„ë¡œëª¨ì…˜ ì „ëµ ìˆ˜ë¦½

â–**5. ì°¸ê³ ìë£Œ**

**5.1 ë°ì´í„° ì¶œì²˜ (Data Sources)**
[D1] Amazon Best Sellers - Beauty & Personal Care, 2026-01-01 ~ 2026-01-28
[D2] Amazon Best Sellers - Skin Care, 2026-01-01 ~ 2026-01-28
[D3] Amazon Best Sellers - Lip Care, 2026-01-01 ~ 2026-01-28
[D4] Amazon Best Sellers - Lip Makeup, 2026-01-01 ~ 2026-01-28
[D5] Amazon Best Sellers - Face Powder, 2026-01-01 ~ 2026-01-28

**5.2 ì°¸ê³  ë¬¸í—Œ (References)**
[ì œê³µëœ ì°¸ê³ ìë£Œ ëª©ë¡ - ë§í¬ URL ì „ì²´ í‘œì‹œ, ì¶•ì•½ ê¸ˆì§€]
```

### ì¤‘ìš”: ì°¸ê³ ìë£Œ ì‘ì„± ê·œì¹™
1. **ì°¸ê³ ìë£ŒëŠ” ë°˜ë“œì‹œ ë¬¸ì„œ ë§¨ ë§ˆì§€ë§‰ì— ìœ„ì¹˜** (ì „ëµ ì œì–¸ ì´í›„)
2. **ë§í¬ URLì€ ì ˆëŒ€ ì¶•ì•½í•˜ì§€ ë§ ê²ƒ** (... ì‚¬ìš© ê¸ˆì§€, ì „ì²´ URL í‘œì‹œ)
3. **ì œëª©ë„ ì¶•ì•½ ê¸ˆì§€** (ì „ì²´ ì œëª© í‘œì‹œ)
4. **ëª©ì°¨ëŠ” ë°˜ë“œì‹œ ì œëª© ë°”ë¡œ ì•„ë˜ì— ìœ„ì¹˜**

### ì‘ì„± ì›ì¹™ (AMOREPACIFIC ìŠ¤íƒ€ì¼):
1. **ì„¹ì…˜ í—¤ë”**: `â–**ì œëª©**` í˜•ì‹ ì‚¬ìš© (ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€)
2. **ë¸Œëœë“œëª… í•œê¸€í™”**: LANEIGE â†’ ë¼ë„¤ì¦ˆ, COSRX â†’ ì½”ìŠ¤ì•Œì—‘ìŠ¤, SULWHASOO â†’ ì„¤í™”ìˆ˜
3. **ìˆ˜ì¹˜ ê°•ì¡°**: ëª¨ë“  ìˆ˜ì¹˜ì— **ë³¼ë“œ** ì ìš© (ì˜ˆ: **+12%**, **#4**, **3ê°œ**)
4. **ë¶ˆë¦¿ í¬ì¸íŠ¸**: ìµœìƒìœ„ëŠ” â€¢ ì‚¬ìš©, í•˜ìœ„ëŠ” - ì‚¬ìš©
5. **ì¸ê³¼ê´€ê³„ ì¤‘ì‹¬**: "Aê°€ ë°œìƒí–ˆë‹¤" â†’ "AëŠ” B ë•Œë¬¸ì— ë°œìƒí•œ ê²ƒìœ¼ë¡œ íŒë‹¨ëœë‹¤"
6. **ì¶œì²˜ í•„ìˆ˜ ì¸ìš©**: ëª¨ë“  ì‚¬ì‹¤ ì£¼ì¥ì— [1], [2] í˜•íƒœë¡œ ì¶œì²˜ ì¸ìš©
7. **ê³„ì¸µì  ë¶„ì„**: Layer 4(ê±°ì‹œ) â†’ Layer 1(Amazon)ìœ¼ë¡œ ì›ì¸-ê²°ê³¼ ì—°ê²°
8. **ì •ëŸ‰ì  í‘œí˜„**: "ì¦ê°€" ëŒ€ì‹  "+12%", "ë§ìŒ" ëŒ€ì‹  "2,400 ì—…ë³´íŠ¸"
"""

        try:
            response = await acompletion(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=self.temperature,
                max_tokens=1200,
            )

            insight = response.choices[0].message.content

            # í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡
            if self.metrics and hasattr(response, "usage"):
                self.metrics.record_llm_call(
                    model=self.model,
                    prompt_tokens=response.usage.prompt_tokens,
                    completion_tokens=response.usage.completion_tokens,
                    latency_ms=0,
                    cost=self._estimate_cost(
                        response.usage.prompt_tokens, response.usage.completion_tokens
                    ),
                )

            # ê°€ë“œë ˆì¼ ì ìš©
            insight = self.templates.apply_guardrails(insight)

            # LLMì´ ìƒì„±í•œ ì°¸ê³ ìë£Œ ì„¹ì…˜ ì œê±° í›„ ìš°ë¦¬ ì°¸ê³ ìë£Œë¡œ êµì²´ (URL í¬í•¨)
            insight = self._replace_reference_section(insight, reference_section)

            # AMOREPACIFIC ìŠ¤íƒ€ì¼ í¬ë§·íŒ… ì ìš©
            insight = format_insight(insight)

            # ì‹¤íŒ¨í•œ ì‹ í˜¸ ìˆ˜ì§‘ê¸° ê²½ê³  ì¶”ê°€
            if failed_signals:
                warning_section = "\n\n---\n"
                warning_section += "â–**ì™¸ë¶€ íŠ¸ë Œë“œ ì •ë³´ ì¼ë¶€ ë¯¸ë°˜ì˜**\n"
                warning_section += f"â€¢ **ìˆ˜ì§‘ ì‹¤íŒ¨**: {', '.join(failed_signals)}\n"
                warning_section += "â€¢ **ì˜í–¥**: ë³¸ ë¦¬í¬íŠ¸ëŠ” í¬ë¡¤ë§/KG ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë¨\n"
                warning_section += "â€¢ **ê¶Œì¥**: 1-2ì‹œê°„ í›„ ì¬ì‹œë„ ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ íŠ¸ë Œë“œ í™•ì¸"
                insight += warning_section

            return insight

        except Exception as e:
            self.logger.error(f"LLM call failed: {e}")
            return self._generate_fallback_insight(hybrid_context, metrics_data)

    def _generate_fallback_insight(self, hybrid_context: HybridContext, metrics_data: dict) -> str:
        """í´ë°± ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        summary = metrics_data.get("summary", {})
        inferences = hybrid_context.inferences

        insight_parts = [
            "## ì˜¤ëŠ˜ì˜ LANEIGE Amazon ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë¶„ì„\n",
            f"- ì¶”ì  ì¤‘ì¸ ì œí’ˆ: {summary.get('laneige_products_tracked', 0)}ê°œ",
            f"- ì•Œë¦¼: {summary.get('alert_count', 0)}ê±´",
        ]

        # ì¶”ë¡  ê²°ê³¼ ì¶”ê°€
        if inferences:
            insight_parts.append("\n### ì£¼ìš” ë¶„ì„ ê²°ê³¼")
            for inf in inferences[:3]:
                insight_parts.append(f"- {inf.insight}")

        insight_parts.append(
            "\n\n_â€» ìƒì„¸ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê¸°ë³¸ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤._"
        )

        reference_section = self._build_reference_section(hybrid_context, {}, None)
        if reference_section:
            insight_parts.append("\n" + reference_section)

        return "\n".join(insight_parts)

    def _extract_action_items(
        self, inferences: list[InferenceResult], metrics_data: dict
    ) -> list[dict]:
        """ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
        actions = []

        # ì¶”ë¡  ê²°ê³¼ì—ì„œ ì•¡ì…˜ ì¶”ì¶œ
        for inf in inferences:
            if inf.recommendation:
                priority = self._get_priority_from_insight(inf)
                actions.append(
                    {
                        "priority": priority,
                        "type": inf.insight_type.value,
                        "action": inf.recommendation,
                        "source": "ontology_inference",
                        "rule": inf.rule_name,
                        "confidence": inf.confidence,
                    }
                )

        # ì•Œë¦¼ ê¸°ë°˜ ì•¡ì…˜ ì¶”ê°€
        for alert in metrics_data.get("alerts", []):
            if alert.get("severity") == "critical":
                actions.append(
                    {
                        "priority": "high",
                        "type": alert.get("type"),
                        "action": f"[ê¸´ê¸‰] {alert.get('message')} - ì¦‰ì‹œ í™•ì¸ í•„ìš”",
                        "source": "alert",
                        "product": alert.get("title"),
                        "asin": alert.get("asin"),
                    }
                )
            elif alert.get("severity") == "warning":
                actions.append(
                    {
                        "priority": "medium",
                        "type": alert.get("type"),
                        "action": f"[ì£¼ì˜] {alert.get('message')} - ëª¨ë‹ˆí„°ë§ ê°•í™”",
                        "source": "alert",
                        "product": alert.get("title"),
                        "asin": alert.get("asin"),
                    }
                )

        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        priority_order = {"high": 0, "medium": 1, "low": 2}
        actions.sort(key=lambda x: priority_order.get(x.get("priority"), 3))

        return actions[:10]

    def _build_reference_section(
        self,
        hybrid_context: HybridContext,
        external_signals: dict[str, Any] | None,
        market_intelligence: dict[str, Any] | None = None,
    ) -> str:
        """
        ì°¸ê³ ìë£Œ ì„¹ì…˜ ìƒì„± (ìˆ«ì ì¸ìš©ìš©) - URL í¬í•¨

        êµ¬ì¡°:
        â–**5. ì°¸ê³ ìë£Œ**
        **5.1 ë°ì´í„° ì¶œì²˜ (Data Sources)**
        [D1] Amazon Best Sellers - Beauty & Personal Care, 2026-01-01 ~ 2026-01-28
        ...
        **5.2 ì°¸ê³  ë¬¸í—Œ (References)**
        [1] ì¶œì²˜ëª…, "ì œëª©", ë‚ ì§œ
            URL (ì „ì²´ í‘œì‹œ, ì¶•ì•½ ê¸ˆì§€)
        ...

        ì¶œì²˜ ìš°ì„ ìˆœìœ„:
        1. Market Intelligence (Layer 4 â†’ Layer 3 â†’ Layer 2)
        2. External Signals (ë‰´ìŠ¤, Reddit, TikTok ë“±)
        3. RAG Documents
        4. Knowledge Graph

        ê° ì¶œì²˜ì— URLì´ ìˆëŠ” ê²½ìš° ì°¸ê³ ìë£Œì— í¬í•¨ë©ë‹ˆë‹¤.
        """
        from datetime import datetime

        # ë‚ ì§œ ë²”ìœ„ ê³„ì‚° (ì˜¤ëŠ˜ ê¸°ì¤€ 28ì¼)
        today = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - __import__("datetime").timedelta(days=27)).strftime(
            "%Y-%m-%d"
        )

        # 5.1 ë°ì´í„° ì¶œì²˜ ì„¹ì…˜
        data_sources = [
            f"[D1] Amazon Best Sellers - Beauty & Personal Care, {start_date} ~ {today}",
            f"[D2] Amazon Best Sellers - Skin Care, {start_date} ~ {today}",
            f"[D3] Amazon Best Sellers - Lip Care, {start_date} ~ {today}",
            f"[D4] Amazon Best Sellers - Lip Makeup, {start_date} ~ {today}",
            f"[D5] Amazon Best Sellers - Face Powder, {start_date} ~ {today}",
        ]
        data_source_section = "**5.1 ë°ì´í„° ì¶œì²˜ (Data Sources)**\n" + "\n".join(data_sources)

        # 5.2 ì°¸ê³  ë¬¸í—Œ ì„¹ì…˜
        entries = []
        idx = 1

        # 1. Market Intelligence ì¶œì²˜ (Layer 4: ê±°ì‹œê²½ì œ/ë¬´ì—­)
        if market_intelligence:
            sources = market_intelligence.get("sources", [])
            for source in sources[:6]:  # ìµœëŒ€ 6ê°œ
                publisher = source.get("publisher", "")
                title = source.get("title", "")
                date = source.get("date", "")
                url = source.get("url", "")
                source_type = source.get("source_type", "")

                # ë‚ ì§œ í¬ë§·íŒ…
                date_str = self._format_date(date)

                # ê¸°ë³¸ ì°¸ê³ ìë£Œ ë¼ì¸
                if source_type == "government":
                    entry = f"[{idx}] {publisher}, {title}, {date_str}"
                elif source_type == "ir":
                    entry = f'[{idx}] {publisher}, "{title}", {date_str}'
                elif source_type == "news":
                    entry = f'[{idx}] {publisher}, "{title}", {date_str}'
                else:
                    entry = f"[{idx}] {publisher}: {title} ({date_str})"

                # URL ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
                if url:
                    entry += f"\n    {url}"

                entries.append(entry)
                idx += 1

        # 2. External Signal ì¶œì²˜ (ë‰´ìŠ¤, Reddit, TikTok ë“±) - URL í¬í•¨
        for signal in (external_signals or {}).get("signals", [])[:5]:  # ìµœëŒ€ 5ê°œë¡œ ì¦ê°€
            source_name = signal.get("source", "").replace("_", " ").title()
            title = signal.get("title", "")
            url = signal.get("url", "")
            collected_at = signal.get("collected_at", "") or signal.get("published_at", "")

            # ë‚ ì§œ í¬ë§·íŒ…
            date_str = self._format_date(collected_at)

            # ì œëª© ì „ì²´ í‘œì‹œ (ì¶•ì•½ ê¸ˆì§€)
            entry = f'[{idx}] {source_name}, "{title}", {date_str}'

            # URL ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if url:
                entry += f"\n    {url}"

            entries.append(entry)
            idx += 1

        # 3. RAG ë¬¸ì„œ ì¶œì²˜
        for chunk in (hybrid_context.rag_chunks or [])[:2]:
            metadata = chunk.get("metadata", {})
            title = metadata.get("title") or metadata.get("doc_id", "ê°€ì´ë“œ ë¬¸ì„œ")
            source_filename = metadata.get("source_filename", "")
            doc_url = metadata.get("url", "")

            if source_filename:
                entry = f"[{idx}] ë‚´ë¶€ ê°€ì´ë“œ: {title} ({source_filename})"
            else:
                entry = f"[{idx}] ë‚´ë¶€ ê°€ì´ë“œ: {title}"

            if doc_url:
                entry += f"\n    {doc_url}"

            entries.append(entry)
            idx += 1

        # 4. KG ê·¼ê±° (ìš”ì•½)
        if hybrid_context.ontology_facts:
            fact_types = sorted(
                {fact.get("type") for fact in hybrid_context.ontology_facts if fact.get("type")}
            )
            if fact_types:
                entries.append(f"[{idx}] KnowledgeGraph: ì˜¨í†¨ë¡œì§€ ì¶”ë¡  ({', '.join(fact_types)})")

        # ì°¸ê³ ìë£Œ ì „ì²´ ì„¹ì…˜ êµ¬ì„±
        # í•­ìƒ ë°ì´í„° ì¶œì²˜ëŠ” í¬í•¨, ì°¸ê³  ë¬¸í—Œì€ ìˆì„ ë•Œë§Œ
        reference_parts = ["â–**5. ì°¸ê³ ìë£Œ**\n", data_source_section]

        if entries:
            reference_parts.append("\n\n**5.2 ì°¸ê³  ë¬¸í—Œ (References)**\n" + "\n".join(entries))

        return "\n".join(reference_parts)

    def _format_date(self, date_str: str) -> str:
        """ë‚ ì§œ ë¬¸ìì—´ í¬ë§·íŒ…"""
        if not date_str:
            return "ë‚ ì§œ ë¯¸ìƒ"

        # ISO í˜•ì‹ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œ
        date_only = date_str[:10] if len(date_str) >= 10 else date_str

        # YYYY-MM-DD â†’ YYYY.MM.DD
        if len(date_only) == 10 and "-" in date_only:
            parts = date_only.split("-")
            return f"{parts[0]}.{parts[1]}.{parts[2]}"
        # YYYY-MM â†’ YYYY.MM
        elif len(date_only) == 7 and "-" in date_only:
            parts = date_only.split("-")
            return f"{parts[0]}.{parts[1]}"

        return date_only

    def _replace_reference_section(self, insight: str, reference_section: str) -> str:
        """
        LLMì´ ìƒì„±í•œ ì°¸ê³ ìë£Œ ì„¹ì…˜ì„ ìš°ë¦¬ê°€ ìƒì„±í•œ ì°¸ê³ ìë£Œ ì„¹ì…˜(URL í¬í•¨)ìœ¼ë¡œ êµì²´

        Args:
            insight: LLMì´ ìƒì„±í•œ ì¸ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸
            reference_section: URLì´ í¬í•¨ëœ ì°¸ê³ ìë£Œ ì„¹ì…˜

        Returns:
            ì°¸ê³ ìë£Œê°€ êµì²´ëœ ì¸ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸
        """
        import re

        if not reference_section:
            return insight

        # LLMì´ ìƒì„±í•œ ì°¸ê³ ìë£Œ ì„¹ì…˜ íŒ¨í„´ë“¤
        # "## ì°¸ê³ ìë£Œ", "## ğŸ“š ì°¸ê³ ìë£Œ", "## References", "5. ì°¸ê³ ìë£Œ", "**5.2 ì°¸ê³  ë¬¸í—Œ**" ë“±
        patterns = [
            r"##\s*ğŸ“š?\s*ì°¸ê³ ìë£Œ.*?(?=\n##|\n---|\Z)",  # ## ì°¸ê³ ìë£Œ or ## ğŸ“š ì°¸ê³ ìë£Œ
            r"##\s*References.*?(?=\n##|\n---|\Z)",  # ## References
            r"\*\*ì°¸ê³ ìë£Œ\*\*.*?(?=\n##|\n---|\Z)",  # **ì°¸ê³ ìë£Œ**
            r"\*\*\d+\.\s*ì°¸ê³ ìë£Œ\*\*.*?(?=\n\*\*\d+\.|\n---|\Z)",  # **5. ì°¸ê³ ìë£Œ**
            r"\*\*\d+\.\d+\s*ì°¸ê³ \s*ë¬¸í—Œ.*?\*\*.*?(?=\n\*\*\d+\.|\n---|\Z)",  # **5.2 ì°¸ê³  ë¬¸í—Œ**
            r"â–\*\*\d+\.\s*ì°¸ê³ ìë£Œ\*\*.*?(?=\nâ–|\n---|\Z)",  # â–**5. ì°¸ê³ ìë£Œ**
            # ë²ˆí˜¸ ë¶™ì€ ì„¹ì…˜: "5. ì°¸ê³ ìë£Œ" ë˜ëŠ” "5. ì°¸ê³ ìë£Œ (References)"
            # ë‹¤ìŒ ë²ˆí˜¸ ì„¹ì…˜, ---, ë˜ëŠ” ë¬¸ì„œ ëê¹Œì§€ ë§¤ì¹­
            r"\n\d+\.\s*ì°¸ê³ ìë£Œ[^\n]*\n.*?(?=\n\d+\.|\n---|\Z)",
        ]

        # ê¸°ì¡´ ì°¸ê³ ìë£Œ ì„¹ì…˜ ì œê±°
        cleaned_insight = insight
        for pattern in patterns:
            cleaned_insight = re.sub(pattern, "", cleaned_insight, flags=re.DOTALL | re.IGNORECASE)

        # í›„í–‰ ê³µë°±/ì¤„ë°”ê¿ˆ ì •ë¦¬
        cleaned_insight = cleaned_insight.rstrip()

        # ìƒˆ ì°¸ê³ ìë£Œ ì„¹ì…˜ ì¶”ê°€
        cleaned_insight += "\n\n" + reference_section

        return cleaned_insight

    def _get_priority_from_insight(self, inference: InferenceResult) -> str:
        """ì¸ì‚¬ì´íŠ¸ ìœ í˜•ì—ì„œ ìš°ì„ ìˆœìœ„ ê²°ì •"""
        high_priority = {
            InsightType.RISK_ALERT,
            InsightType.COMPETITIVE_THREAT,
            InsightType.RANK_SHOCK,
        }
        medium_priority = {
            InsightType.PRICE_QUALITY_GAP,
            InsightType.COMPETITIVE_ADVANTAGE,
            InsightType.GROWTH_OPPORTUNITY,
        }

        if inference.insight_type in high_priority:
            return "high"
        elif inference.insight_type in medium_priority:
            return "medium"
        else:
            return "low"

    def _extract_highlights(
        self, inferences: list[InferenceResult], metrics_data: dict
    ) -> list[dict]:
        """í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ"""
        highlights = []

        # ê¸ì •ì  ì¶”ë¡  ê²°ê³¼
        positive_types = {
            InsightType.MARKET_DOMINANCE,
            InsightType.GROWTH_MOMENTUM,
            InsightType.STABILITY,
            InsightType.COMPETITIVE_ADVANTAGE,
        }

        for inf in inferences:
            if inf.insight_type in positive_types:
                highlights.append(
                    {
                        "type": inf.insight_type.value,
                        "title": inf.insight_type.value.replace("_", " ").title(),
                        "detail": inf.insight,
                        "source": "ontology",
                    }
                )

        # ì œí’ˆ ë©”íŠ¸ë¦­ì—ì„œ í•˜ì´ë¼ì´íŠ¸
        product_metrics = metrics_data.get("product_metrics", [])

        # Top 10 ì§„ì…
        for p in product_metrics:
            if p.get("current_rank", 100) <= 10:
                highlights.append(
                    {
                        "type": "top_rank",
                        "title": f"Top 10: {p.get('product_title', '')[:30]}...",
                        "detail": f"{p.get('category_id')} ì¹´í…Œê³ ë¦¬ {p.get('current_rank')}ìœ„",
                        "asin": p.get("asin"),
                    }
                )

        # ìˆœìœ„ ìƒìŠ¹
        improving = [
            p for p in product_metrics if p.get("rank_change_1d") and p.get("rank_change_1d") < -3
        ]
        for p in improving[:3]:
            highlights.append(
                {
                    "type": "rank_up",
                    "title": f"ìˆœìœ„ ìƒìŠ¹: {p.get('product_title', '')[:30]}...",
                    "detail": f"{abs(p.get('rank_change_1d'))}ë‹¨ê³„ ìƒìŠ¹ â†’ í˜„ì¬ {p.get('current_rank')}ìœ„",
                    "asin": p.get("asin"),
                }
            )

        return highlights[:10]

    def _estimate_cost(self, prompt_tokens: int, completion_tokens: int) -> float:
        """ë¹„ìš© ì¶”ì •"""
        input_cost = (prompt_tokens / 1_000_000) * 0.40
        output_cost = (completion_tokens / 1_000_000) * 1.60
        return round(input_cost + output_cost, 6)

    def get_results(self) -> dict[str, Any]:
        """ë§ˆì§€ë§‰ ì‹¤í–‰ ê²°ê³¼"""
        return self._results

    def get_last_hybrid_context(self) -> HybridContext | None:
        """ë§ˆì§€ë§‰ í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…ìŠ¤íŠ¸"""
        return self._last_hybrid_context

    def get_knowledge_graph(self) -> KnowledgeGraph:
        """ì§€ì‹ ê·¸ë˜í”„ ë°˜í™˜"""
        return self.kg

    def get_reasoner(self) -> OntologyReasoner:
        """ì¶”ë¡ ê¸° ë°˜í™˜"""
        return self.reasoner

    async def _collect_external_signals(self) -> dict[str, Any]:
        """
        External Signal ìˆ˜ì§‘

        Returns:
            {
                "signals": [...],
                "report_section": "â–  ì „ë¬¸ ë§¤ì²´ ê·¼ê±°: ...",
                "stats": {"by_tier": {...}, "by_source": {...}}
            }
        """
        result = {"signals": [], "report_section": "", "stats": {}}

        try:
            if not self._signal_collector:
                self._signal_collector = ExternalSignalCollector()
                await self._signal_collector.initialize()

            # ê¸°ì¡´ ìˆ˜ì§‘ëœ ì‹ í˜¸ í™•ì¸
            if self._signal_collector.signals:
                result["signals"] = [s.to_dict() for s in self._signal_collector.signals[-20:]]
                result["report_section"] = self._signal_collector.generate_report_section(days=7)
                result["stats"] = self._signal_collector.get_stats()

            self.logger.debug(f"External signals: {len(result['signals'])} signals loaded")

        except Exception as e:
            self.logger.warning(f"External signal collection failed: {e}")

        return result

    def _get_failed_signal_collectors(self) -> list[str]:
        """
        ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ì™¸ë¶€ ì‹ í˜¸ ìˆ˜ì§‘ê¸° ëª©ë¡ ë°˜í™˜

        Returns:
            ì‹¤íŒ¨í•œ ìˆ˜ì§‘ê¸° ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        failed = []

        if not GOOGLE_TRENDS_AVAILABLE:
            failed.append("Google Trends")

        # ExternalSignalCollector ì²´í¬
        try:
            import importlib.util

            if importlib.util.find_spec("src.tools.external_signal_collector") is None:
                failed.append("External Signals (Tavily/RSS/Reddit)")
        except ImportError:
            failed.append("External Signals (Tavily/RSS/Reddit)")

        # Market Intelligence ì²´í¬
        try:
            if importlib.util.find_spec("src.tools.market_intelligence") is None:
                failed.append("Market Intelligence")
        except ImportError:
            failed.append("Market Intelligence")

        return failed

    async def _collect_market_intelligence(self) -> dict[str, Any]:
        """
        Market Intelligence ë°ì´í„° ìˆ˜ì§‘ (Layer 2-4)

        Returns:
            {
                "layer_4": {...},  # ê±°ì‹œê²½ì œ/ë¬´ì—­
                "layer_3": {...},  # ì‚°ì—…/ê¸°ì—…
                "layer_2": {...},  # ì†Œë¹„ì íŠ¸ë Œë“œ
                "sources": [...],  # ì¶œì²˜ ëª©ë¡
                "insight_section": "..."  # ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜
            }
        """
        result = {
            "layer_4": {},
            "layer_3": {},
            "layer_2": {},
            "sources": [],
            "insight_section": "",
        }

        try:
            if not self._market_intelligence:
                self._market_intelligence = MarketIntelligenceEngine()
                await self._market_intelligence.initialize()

            # ëª¨ë“  ë ˆì´ì–´ ë³‘ë ¬ ìˆ˜ì§‘
            await self._market_intelligence.collect_all_layers()

            # ë ˆì´ì–´ë³„ ë°ì´í„° ì¶”ì¶œ
            layer_data = self._market_intelligence.layer_data

            if DataLayer.LAYER_4_MACRO in layer_data:
                result["layer_4"] = layer_data[DataLayer.LAYER_4_MACRO].data
                result["sources"].extend(layer_data[DataLayer.LAYER_4_MACRO].sources)

            if DataLayer.LAYER_3_INDUSTRY in layer_data:
                result["layer_3"] = layer_data[DataLayer.LAYER_3_INDUSTRY].data
                result["sources"].extend(layer_data[DataLayer.LAYER_3_INDUSTRY].sources)

            if DataLayer.LAYER_2_CONSUMER in layer_data:
                result["layer_2"] = layer_data[DataLayer.LAYER_2_CONSUMER].data
                result["sources"].extend(layer_data[DataLayer.LAYER_2_CONSUMER].sources)

            # ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜ ìƒì„±
            result["insight_section"] = self._market_intelligence.generate_layered_insight()

            # Google Trends ìˆ˜ì§‘
            google_trends = await self._collect_google_trends()
            if google_trends.get("trends"):
                result["google_trends"] = google_trends["trends"]
                if google_trends.get("insight_section"):
                    result["insight_section"] += "\n\n" + google_trends["insight_section"]

            self.logger.info(f"Market Intelligence collected: {len(result['sources'])} sources")

        except Exception as e:
            self.logger.warning(f"Market Intelligence collection failed: {e}")

        return result

    async def _collect_google_trends(self) -> dict[str, Any]:
        """
        Google Trends ë°ì´í„° ìˆ˜ì§‘

        Returns:
            {
                "trends": [...],
                "insight_section": "### Google Trends ê²€ìƒ‰ ê´€ì‹¬ë„\n...",
                "collected_at": str
            }
        """
        result = {"trends": [], "insight_section": "", "collected_at": ""}

        if not GOOGLE_TRENDS_AVAILABLE:
            self.logger.debug("Google Trends collector not available")
            return result

        try:
            if not self._google_trends:
                self._google_trends = GoogleTrendsCollector(geo="US", timeframe="today 3-m")

            # ë·°í‹° íŠ¸ë Œë“œ ìˆ˜ì§‘
            trends = await self._google_trends.fetch_beauty_trends()

            if trends:
                result["trends"] = [t.to_dict() for t in trends]
                result["insight_section"] = self._google_trends.generate_insight_section(trends)
                result["collected_at"] = trends[0].collected_at if trends else ""

                # ë°ì´í„° ì €ì¥
                await self._google_trends.save_trends(trends)

            self.logger.info(f"Google Trends collected: {len(trends)} keywords")

        except Exception as e:
            self.logger.warning(f"Google Trends collection failed: {e}")

        return result

    def _extract_data_source_info(
        self, metrics_data: dict | None, crawl_data: dict | None
    ) -> dict[str, Any]:
        """
        ë°ì´í„° ì¶œì²˜ ì •ë³´ ì¶”ì¶œ

        Args:
            metrics_data: ì§€í‘œ ë°ì´í„°
            crawl_data: í¬ë¡¤ë§ ë°ì´í„°

        Returns:
            ë°ì´í„° ì¶œì²˜ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        source_info = {
            "platform": "Amazon US Best Sellers",
            "collected_at": None,
            "snapshot_date": None,
            "categories": [],
            "total_products": 0,
            "disclaimer": "Amazonì€ Best Sellers ìˆœìœ„ë¥¼ ë§¤ ì‹œê°„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. í‘œì‹œëœ ë°ì´í„°ëŠ” ìˆ˜ì§‘ ì‹œì ì˜ ìŠ¤ëƒ…ìƒ·ì…ë‹ˆë‹¤.",
        }

        # í¬ë¡¤ë§ ë°ì´í„°ì—ì„œ ìˆ˜ì§‘ ì‹œì  ì¶”ì¶œ
        if crawl_data:
            collected_at = crawl_data.get("collected_at")
            if collected_at:
                source_info["collected_at"] = collected_at

            # í¬ë¡¤ë§ ìš”ì•½ì—ì„œ ì •ë³´ ì¶”ì¶œ
            if "summary" in crawl_data:
                summary = crawl_data["summary"]
                source_info["total_products"] = summary.get("total_products", 0)
                source_info["categories"] = summary.get("categories", [])

        # ì§€í‘œ ë°ì´í„°ì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
        if metrics_data:
            metadata = metrics_data.get("metadata", {})
            if metadata:
                data_date = metadata.get("data_date")
                if data_date:
                    source_info["snapshot_date"] = data_date
                if not source_info["collected_at"]:
                    source_info["collected_at"] = metadata.get("generated_at")

            # ì¹´í…Œê³ ë¦¬ ì •ë³´
            categories = metrics_data.get("categories", {})
            if categories and not source_info["categories"]:
                source_info["categories"] = list(categories.keys())

            # ì œí’ˆ ìˆ˜
            if not source_info["total_products"]:
                total = (
                    sum(len(cat_data.get("rank_records", [])) for cat_data in categories.values())
                    if categories
                    else 0
                )
                source_info["total_products"] = total

        return source_info

    def _ingest_rag_knowledge(self, rag_chunks: list[dict[str, Any]]) -> dict[str, int]:
        """RAG ì²­í¬ì—ì„œ ì§€ì‹ ì¶”ì¶œ í›„ KGì— ì ì¬"""
        stats = {"trend_relations": 0, "action_relations": 0}

        for chunk in rag_chunks or []:
            metadata = chunk.get("metadata", {})
            doc_type = metadata.get("doc_type", "")
            doc_id = metadata.get("doc_id", "")
            chunk_id = metadata.get("chunk_id") or chunk.get("id")
            target_brand = metadata.get("target_brand")
            brands_covered = metadata.get("brands_covered", [])

            subject = self._normalize_brand_name(target_brand) if target_brand else "MARKET"
            if not target_brand and brands_covered:
                subject = self._normalize_brand_name(brands_covered[0])

            # íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì¸í…”ë¦¬ì „ìŠ¤ ë¬¸ì„œ ìš°ì„ )
            if doc_type in {"intelligence", "knowledge_base"}:
                trend_keywords = metadata.get("keywords", [])
                for keyword in trend_keywords:
                    if len(keyword) < 3:
                        continue
                    relation = Relation(
                        subject=subject,
                        predicate=RelationType.HAS_TREND,
                        object=keyword,
                        properties={
                            "source": "rag",
                            "doc_id": doc_id,
                            "chunk_id": chunk_id,
                            "doc_type": doc_type,
                            "source_filename": metadata.get("source_filename", ""),
                        },
                    )
                    if self.kg.add_relation(relation):
                        stats["trend_relations"] += 1

            # ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ (í”Œë ˆì´ë¶/ëŒ€ì‘ ê°€ì´ë“œ)
            if doc_type in {"playbook", "response_guide"}:
                action_lines = self._extract_action_lines(chunk.get("content", ""))
                for action in action_lines:
                    relation = Relation(
                        subject=subject,
                        predicate=RelationType.REQUIRES_ACTION,
                        object=action,
                        properties={
                            "source": "rag",
                            "doc_id": doc_id,
                            "chunk_id": chunk_id,
                            "doc_type": doc_type,
                            "source_filename": metadata.get("source_filename", ""),
                        },
                    )
                    if self.kg.add_relation(relation):
                        stats["action_relations"] += 1

        return stats

    def _ingest_external_signals(self, external_signals: dict[str, Any]) -> dict[str, int]:
        """External Signalì„ KGì— ì ì¬"""
        stats = {"trend_relations": 0}
        signals = external_signals.get("signals", []) if external_signals else []

        for signal in signals:
            keywords = signal.get("keywords", [])
            if not keywords:
                continue

            subject = self._infer_signal_subject(keywords)
            for keyword in keywords:
                relation = Relation(
                    subject=subject,
                    predicate=RelationType.HAS_TREND,
                    object=keyword,
                    properties={
                        "source": "external_signal",
                        "signal_id": signal.get("signal_id"),
                        "source_name": signal.get("source"),
                        "url": signal.get("url"),
                        "published_at": signal.get("published_at"),
                        "collected_at": signal.get("collected_at"),
                    },
                )
                if self.kg.add_relation(relation):
                    stats["trend_relations"] += 1

        return stats

    def _extract_action_lines(self, content: str) -> list[str]:
        """ë¬¸ì„œ ë³¸ë¬¸ì—ì„œ ì•¡ì…˜ í•­ëª© ì¶”ì¶œ"""
        actions = []
        for line in content.splitlines():
            stripped = line.strip()
            if not stripped:
                continue
            if stripped.startswith("- ") or stripped.startswith("* "):
                actions.append(stripped[2:].strip())
            elif stripped[:2].isdigit() and stripped[1:3] == ". ":
                actions.append(stripped[3:].strip())
        return [a for a in actions if 5 <= len(a) <= 140]

    def _infer_signal_subject(self, keywords: list[str]) -> str:
        """External Signal í‚¤ì›Œë“œì—ì„œ ëŒ€ìƒ ì—”í‹°í‹° ì¶”ì •"""
        brand_keywords = {
            "laneige": "LANEIGE",
            "cosrx": "COSRX",
            "tirtir": "TIRTIR",
            "rare beauty": "RARE BEAUTY",
            "innisfree": "INNISFREE",
            "etude": "ETUDE",
            "sulwhasoo": "SULWHASOO",
            "hera": "HERA",
        }
        for keyword in keywords:
            normalized = keyword.lower()
            if normalized in brand_keywords:
                return brand_keywords[normalized]
        return "MARKET"

    def _normalize_brand_name(self, brand: str | None) -> str:
        if not brand:
            return "MARKET"
        return brand.upper() if brand.isalpha() else brand
