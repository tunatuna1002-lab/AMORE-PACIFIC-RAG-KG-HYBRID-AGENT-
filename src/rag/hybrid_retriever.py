"""
Hybrid Retriever
================
Ontology + RAG í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° (ì§€ì‹ ê·¸ë˜í”„ + ë¬¸ì„œ ê²€ìƒ‰ í†µí•©)

## ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨
```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     User Query      â”‚
                        â”‚  "LANEIGE ê²½ìŸë ¥?"  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Entity Extraction  â”‚
                        â”‚ brands: ["LANEIGE"] â”‚
                        â”‚ categories: ["lip"] â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                        â”‚                        â”‚
          â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Knowledge Graph â”‚     â”‚    Reasoner     â”‚     â”‚  RAG Document   â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚   Retriever     â”‚
â”‚ - ë¸Œëœë“œ ì œí’ˆ   â”‚     â”‚ - ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ â”‚     â”‚                 â”‚
â”‚ - ê²½ìŸ ê´€ê³„     â”‚     â”‚ - SoS ë¶„ì„      â”‚     â”‚ - ì§€í‘œ ì •ì˜     â”‚
â”‚ - ì¹´í…Œê³ ë¦¬ ê³„ì¸µ â”‚     â”‚ - ê²½ìŸë ¥ ì¶”ë¡    â”‚     â”‚ - í•´ì„ ê°€ì´ë“œ   â”‚
â”‚ - ê°ì„± ë°ì´í„°   â”‚     â”‚ - ì¸ì‚¬ì´íŠ¸ ìƒì„± â”‚     â”‚ - ì „ëµ í”Œë ˆì´ë¶ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚    Context Merge    â”‚
                      â”‚                     â”‚
                      â”‚ 1. Ontology Facts   â”‚
                      â”‚ 2. Inferences       â”‚
                      â”‚ 3. RAG Chunks       â”‚
                      â”‚ 4. Category Context â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   HybridContext     â”‚
                      â”‚  (LLM í”„ë¡¬í”„íŠ¸ìš©)   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## í•µì‹¬ ì»´í¬ë„ŒíŠ¸
1. **KnowledgeGraph**: êµ¬ì¡°í™”ëœ ê´€ê³„ ë°ì´í„° (ë¸Œëœë“œ-ì œí’ˆ-ì¹´í…Œê³ ë¦¬)
2. **OntologyReasoner**: ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì¶”ë¡ 
3. **DocumentRetriever**: ê°€ì´ë“œë¼ì¸ ë¬¸ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ (docs/guides/)
4. **EntityExtractor**: ì¿¼ë¦¬ì—ì„œ ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬/ì§€í‘œ ì—”í‹°í‹° ì¶”ì¶œ

## ì‚¬ìš© ì˜ˆ
```python
retriever = HybridRetriever(kg, reasoner, doc_retriever)
await retriever.initialize()

context = await retriever.retrieve(
    query="LANEIGE Lip Care ê²½ìŸë ¥ ë¶„ì„",
    current_metrics=dashboard_data
)

# context.ontology_facts: KGì—ì„œ ì¡°íšŒí•œ ì‚¬ì‹¤
# context.inferences: ì¶”ë¡ ëœ ì¸ì‚¬ì´íŠ¸
# context.rag_chunks: RAG ë¬¸ì„œ ì²­í¬
# context.combined_context: LLMìš© í†µí•© ì»¨í…ìŠ¤íŠ¸
```

## ê¸°ëŠ¥
1. ì˜¨í†¨ë¡œì§€ì—ì„œ êµ¬ì¡°í™”ëœ ì§€ì‹ ì¶”ë¡ 
2. RAGì—ì„œ ë¹„êµ¬ì¡°í™”ëœ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
3. ë‘ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
4. ì¹´í…Œê³ ë¦¬ ê³„ì¸µ ì •ë³´ í¬í•¨
5. ê°ì„± ë¶„ì„ ë°ì´í„° í†µí•©

## Flow
Query â†’ Entity Extraction â†’ [Ontology Reasoning + RAG Search] â†’ Context Merge â†’ LLM
"""

from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import logging

from src.ontology.knowledge_graph import KnowledgeGraph
from src.ontology.reasoner import OntologyReasoner
from src.domain.entities.relations import InsightType, InferenceResult, RelationType
from src.ontology.business_rules import register_all_rules

from .retriever import DocumentRetriever


# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)


@dataclass
class HybridContext:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼

    Attributes:
        query: ì›ë³¸ ì¿¼ë¦¬
        entities: ì¶”ì¶œëœ ì—”í‹°í‹°
        ontology_facts: ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ì¡°íšŒí•œ ì‚¬ì‹¤
        inferences: ì˜¨í†¨ë¡œì§€ ì¶”ë¡  ê²°ê³¼
        rag_chunks: RAG ê²€ìƒ‰ ê²°ê³¼ ì²­í¬
        combined_context: í†µí•©ëœ ì»¨í…ìŠ¤íŠ¸ (LLM í”„ë¡¬í”„íŠ¸ìš©)
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    """
    query: str
    entities: Dict[str, List[str]] = field(default_factory=dict)
    ontology_facts: List[Dict[str, Any]] = field(default_factory=list)
    inferences: List[InferenceResult] = field(default_factory=list)
    rag_chunks: List[Dict[str, Any]] = field(default_factory=list)
    combined_context: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
        return {
            "query": self.query,
            "entities": self.entities,
            "ontology_facts": self.ontology_facts,
            "inferences": [inf.to_dict() for inf in self.inferences],
            "rag_chunks": self.rag_chunks,
            "combined_context": self.combined_context,
            "metadata": self.metadata
        }


class EntityExtractor:
    """
    ì¿¼ë¦¬ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ

    ì¶”ì¶œ ëŒ€ìƒ:
    - ë¸Œëœë“œëª… (LANEIGE, COSRX ë“±)
    - ì¹´í…Œê³ ë¦¬ (Lip Care, Skin Care ë“±)
    - ì§€í‘œëª… (SoS, HHI, CPI ë“±)
    - ì‹œê°„ ë²”ìœ„ (ì˜¤ëŠ˜, ìµœê·¼ 7ì¼ ë“±)
    """

    # ì•Œë ¤ì§„ ì—”í‹°í‹° ë§¤í•‘
    KNOWN_BRANDS = [
        "laneige", "ë¼ë„¤ì¦ˆ",
        "cosrx", "ì½”ìŠ¤ì•Œì—‘ìŠ¤",
        "tirtir", "í‹°ë¥´í‹°ë¥´",
        "rare beauty", "ë ˆì–´ë·°í‹°",
        "innisfree", "ì´ë‹ˆìŠ¤í”„ë¦¬",
        "etude", "ì—ë›°ë“œ",
        "sulwhasoo", "ì„¤í™”ìˆ˜",
        "hera", "í—¤ë¼"
    ]

    CATEGORY_MAP = {
        "lip care": "lip_care",
        "ë¦½ì¼€ì–´": "lip_care",
        "lip makeup": "lip_makeup",
        "ë¦½ë©”ì´í¬ì—…": "lip_makeup",
        "skin care": "skin_care",
        "ìŠ¤í‚¨ì¼€ì–´": "skin_care",
        "face powder": "face_powder",
        "íŒŒìš°ë”": "face_powder",
        "beauty": "beauty",
        "ë·°í‹°": "beauty"
    }

    INDICATOR_MAP = {
        "sos": "sos",
        "ì ìœ ìœ¨": "sos",
        "share of shelf": "sos",
        "hhi": "hhi",
        "ì‹œì¥ì§‘ì¤‘ë„": "hhi",
        "í—ˆí•€ë‹¬": "hhi",
        "cpi": "cpi",
        "ê°€ê²©ì§€ìˆ˜": "cpi",
        "churn": "churn_rate",
        "êµì²´ìœ¨": "churn_rate",
        "streak": "streak_days",
        "ì—°ì†": "streak_days",
        "volatility": "rank_volatility",
        "ë³€ë™ì„±": "rank_volatility",
        "shock": "rank_shock",
        "ê¸‰ë³€": "rank_shock"
    }

    TIME_RANGE_MAP = {
        "ì˜¤ëŠ˜": "today",
        "today": "today",
        "ì–´ì œ": "yesterday",
        "yesterday": "yesterday",
        "ì´ë²ˆ ì£¼": "week",
        "ì´ë²ˆ ë‹¬": "month",
        "ìµœê·¼ 7ì¼": "7days",
        "ìµœê·¼ 30ì¼": "30days",
        "3ê°œì›”": "90days",
        "1ê°œì›”": "30days"
    }

    # ê°ì„± ê´€ë ¨ í‚¤ì›Œë“œ (í•œ/ì˜)
    SENTIMENT_MAP = {
        # ì˜ì–´ í‚¤ì›Œë“œ â†’ í´ëŸ¬ìŠ¤í„°
        "moisturizing": "Hydration",
        "hydrating": "Hydration",
        "ë³´ìŠµ": "Hydration",
        "ìˆ˜ë¶„": "Hydration",
        "ì´‰ì´‰": "Hydration",
        "value for money": "Pricing",
        "ê°€ì„±ë¹„": "Pricing",
        "affordable": "Pricing",
        "ì €ë ´": "Pricing",
        "easy to use": "Usability",
        "ì‚¬ìš©ê°": "Usability",
        "í¸ë¦¬": "Usability",
        "íš¨ê³¼": "Effectiveness",
        "effective": "Effectiveness",
        "works well": "Effectiveness",
        "scent": "Sensory",
        "í–¥": "Sensory",
        "texture": "Sensory",
        "í…ìŠ¤ì²˜": "Sensory",
        "ì§ˆê°": "Sensory",
        "packaging": "Packaging",
        "íŒ¨í‚¤ì§•": "Packaging",
        "í¬ì¥": "Packaging",
        "gentle": "Skin_Compatibility",
        "ìˆœí•œ": "Skin_Compatibility",
        "ë¯¼ê°": "Skin_Compatibility",
        "ë¦¬ë·°": "sentiment_general",
        "review": "sentiment_general",
        "ê³ ê° ë°˜ì‘": "sentiment_general",
        "customer": "sentiment_general",
        "ai ìš”ì•½": "ai_summary",
        "ai summary": "ai_summary",
        "customers say": "ai_summary",
    }

    def extract(self, query: str, knowledge_graph=None) -> Dict[str, List[str]]:
        """
        ì¿¼ë¦¬ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            knowledge_graph: ì§€ì‹ ê·¸ë˜í”„ (ì œí’ˆ ê²€ìƒ‰ìš©, optional)

        Returns:
            {
                "brands": [...],
                "categories": [...],
                "indicators": [...],
                "time_range": [...],
                "products": [...]
            }
        """
        import re
        query_lower = query.lower()

        entities = {
            "brands": [],
            "categories": [],
            "indicators": [],
            "time_range": [],
            "products": []
        }

        # ë¸Œëœë“œ ì¶”ì¶œ
        for brand in self.KNOWN_BRANDS:
            if brand in query_lower:
                # ì •ê·œí™” (ì˜ë¬¸ ì†Œë¬¸ì)
                normalized = brand.replace("ë¼ë„¤ì¦ˆ", "laneige").replace("ì½”ìŠ¤ì•Œì—‘ìŠ¤", "cosrx")
                if normalized not in entities["brands"]:
                    entities["brands"].append(normalized)

        # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
        for cat_name, cat_id in self.CATEGORY_MAP.items():
            if cat_name in query_lower:
                if cat_id not in entities["categories"]:
                    entities["categories"].append(cat_id)

        # ì§€í‘œ ì¶”ì¶œ
        for indicator_name, indicator_id in self.INDICATOR_MAP.items():
            if indicator_name in query_lower:
                if indicator_id not in entities["indicators"]:
                    entities["indicators"].append(indicator_id)

        # ì‹œê°„ ë²”ìœ„ ì¶”ì¶œ
        for time_name, time_id in self.TIME_RANGE_MAP.items():
            if time_name in query_lower:
                if time_id not in entities["time_range"]:
                    entities["time_range"].append(time_id)

        # ì œí’ˆ ASIN ì¶”ì¶œ (B0ë¡œ ì‹œì‘í•˜ëŠ” 10ìë¦¬ í˜•ì‹)
        asin_pattern = r'\bB0[A-Z0-9]{8}\b'
        asins = re.findall(asin_pattern, query)
        if asins:
            entities["products"].extend(asins)

        # ìˆœìœ„ ê¸°ë°˜ ì œí’ˆ ì¶”ì¶œ (ì§€ì‹ ê·¸ë˜í”„ í™œìš©)
        if knowledge_graph:
            # "1ìœ„ ì œí’ˆ", "top 1 product" ê°™ì€ íŒ¨í„´ ê°ì§€
            rank_patterns = [
                (r'(\d+)ìœ„\s*ì œí’ˆ', 'ko'),
                (r'top\s*(\d+)\s*product', 'en'),
                (r'(\d+)ìœ„', 'ko'),
                (r'rank\s*(\d+)', 'en')
            ]

            for pattern, lang in rank_patterns:
                matches = re.findall(pattern, query_lower)
                if matches and entities.get("categories"):
                    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ íŠ¹ì • ìˆœìœ„ ì œí’ˆ ì°¾ê¸°
                    for rank_str in matches:
                        rank = int(rank_str)
                        for category in entities["categories"]:
                            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬+ìˆœìœ„ì˜ ì œí’ˆ ì°¾ê¸°
                            products = knowledge_graph.query(
                                predicate=None,
                                object_=category
                            )
                            for rel in products:
                                if rel.properties.get("rank") == rank:
                                    asin = rel.subject
                                    if asin not in entities["products"]:
                                        entities["products"].append(asin)
                                    break

        # ê°ì„± í‚¤ì›Œë“œ ì¶”ì¶œ
        entities["sentiments"] = []
        entities["sentiment_clusters"] = []

        for keyword, cluster in self.SENTIMENT_MAP.items():
            if keyword in query_lower:
                if keyword not in entities["sentiments"]:
                    entities["sentiments"].append(keyword)
                if cluster not in entities["sentiment_clusters"]:
                    entities["sentiment_clusters"].append(cluster)

        return entities


class QueryDecomposer:
    """
    ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ í•˜ìœ„ ì¿¼ë¦¬ë¡œ ë¶„í•´

    ë¶„í•´ ì „ëµ:
    1. ë¹„êµ ì¿¼ë¦¬ â†’ ê° ëŒ€ìƒë³„ ì¿¼ë¦¬
    2. ë³µí•© ì§€í‘œ ì¿¼ë¦¬ â†’ ì§€í‘œë³„ ì¿¼ë¦¬
    3. ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ â†’ ê¸°ê°„ë³„ ì¿¼ë¦¬

    ì˜ˆì‹œ:
    "LANEIGEì™€ COSRXì˜ Lip Care ê²½ìŸë ¥ ë¹„êµ" â†’
    - "LANEIGE Lip Care í˜„ì¬ ì„±ê³¼"
    - "COSRX Lip Care í˜„ì¬ ì„±ê³¼"
    - "Lip Care ê²½ìŸ ì „ëµ"
    """

    # ë¹„êµ íŒ¨í„´
    COMPARISON_PATTERNS = [
        r'(.+)[ì™€ê³¼]\s*(.+)[ì˜ë¥¼]\s*ë¹„êµ',  # "Aì™€ Bì˜ ë¹„êµ"
        r'(.+)\s*vs\.?\s*(.+)',  # "A vs B"
        r'(.+)[ì™€ê³¼]\s*(.+)\s*ë¹„êµ',  # "Aì™€ B ë¹„êµ"
        r'compare\s+(.+)\s+(?:and|with)\s+(.+)',  # "compare A and B"
    ]

    # ë³µí•© ì§€í‘œ íŒ¨í„´
    MULTI_INDICATOR_KEYWORDS = {
        "ê²½ìŸë ¥": ["SoS", "ìˆœìœ„", "ê²½ìŸì‚¬"],
        "ì‹œì¥ ë¶„ì„": ["HHI", "SoS", "ë¸Œëœë“œ ìˆ˜"],
        "ê°€ê²© ì „ëµ": ["CPI", "ê°€ê²©", "í”„ë¦¬ë¯¸ì—„"],
        "ì„±ì¥ ë¶„ì„": ["ìˆœìœ„ ë³€í™”", "streak", "ì„±ì¥ë¥ "],
        "ì¢…í•© ë¶„ì„": ["SoS", "HHI", "CPI", "ìˆœìœ„"]
    }

    # ì‹œê°„ ë²”ìœ„ íŒ¨í„´
    TIME_COMPARISON_PATTERNS = [
        r'(\d+)ì¼\s*(?:ì „|ì´ì „)',  # "7ì¼ ì „"
        r'ì§€ë‚œ\s*(\d+)ì¼',  # "ì§€ë‚œ 7ì¼"
        r'(\d+)ì£¼\s*ê°„',  # "2ì£¼ ê°„"
        r'ì¶”ì´|ë³€í™”|íŠ¸ë Œë“œ',  # ì‹œê³„ì—´ ë¶„ì„ ì•”ì‹œ
    ]

    @classmethod
    def should_decompose(cls, query: str) -> bool:
        """
        ì¿¼ë¦¬ ë¶„í•´ í•„ìš” ì—¬ë¶€ íŒë‹¨

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬

        Returns:
            ë¶„í•´ í•„ìš” ì—¬ë¶€
        """
        import re
        query_lower = query.lower()

        # ë¹„êµ ì¿¼ë¦¬ ê°ì§€
        for pattern in cls.COMPARISON_PATTERNS:
            if re.search(pattern, query, re.IGNORECASE):
                return True

        # ë³µí•© ì§€í‘œ í‚¤ì›Œë“œ ê°ì§€ (2ê°œ ì´ìƒ)
        indicator_count = 0
        for keyword in ["sos", "hhi", "cpi", "ìˆœìœ„", "ì ìœ ìœ¨", "ì§‘ì¤‘ë„", "ê°€ê²©"]:
            if keyword in query_lower:
                indicator_count += 1
        if indicator_count >= 2:
            return True

        # ì‹œê°„ ë¹„êµ ì¿¼ë¦¬ ê°ì§€
        for pattern in cls.TIME_COMPARISON_PATTERNS:
            if re.search(pattern, query, re.IGNORECASE):
                return True

        # ê¸¸ì´ ê¸°ë°˜ (ë³µì¡í•œ ì¿¼ë¦¬ì¼ ê°€ëŠ¥ì„±)
        if len(query) > 50 and ("ë¶„ì„" in query or "ë¹„êµ" in query or "ì „ëµ" in query):
            return True

        return False

    @classmethod
    def decompose(
        cls,
        query: str,
        entities: Dict[str, List[str]]
    ) -> List[Dict[str, Any]]:
        """
        ì¿¼ë¦¬ ë¶„í•´

        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
            entities: ì¶”ì¶œëœ ì—”í‹°í‹°

        Returns:
            í•˜ìœ„ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
            [{
                "query": str,
                "type": "kg" | "rag" | "both",
                "priority": int,
                "focus": str
            }]
        """
        import re
        sub_queries = []

        brands = entities.get("brands", [])
        categories = entities.get("categories", [])
        indicators = entities.get("indicators", [])

        # 1. ë¹„êµ ì¿¼ë¦¬ ë¶„í•´
        for pattern in cls.COMPARISON_PATTERNS:
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                # ë¹„êµ ëŒ€ìƒ ì¶”ì¶œ
                targets = [match.group(1).strip(), match.group(2).strip()]

                # ê° ëŒ€ìƒì— ëŒ€í•œ ì¿¼ë¦¬
                for i, target in enumerate(targets):
                    category_str = categories[0] if categories else ""
                    sub_queries.append({
                        "query": f"{target} {category_str} í˜„ì¬ ì„±ê³¼ ë¶„ì„".strip(),
                        "type": "kg",  # KG ìš°ì„ 
                        "priority": 1,
                        "focus": f"target_{i}"
                    })

                # ê²½ìŸ/ì „ëµ ê°€ì´ë“œ ì¿¼ë¦¬
                sub_queries.append({
                    "query": f"{category_str} ê²½ìŸ ì „ëµ ê°€ì´ë“œë¼ì¸".strip() if category_str else "ê²½ìŸ ì „ëµ ê°€ì´ë“œë¼ì¸",
                    "type": "rag",  # RAG ìš°ì„ 
                    "priority": 2,
                    "focus": "strategy"
                })

                return sub_queries

        # 2. ë³µí•© ì§€í‘œ ë¶„í•´
        if len(indicators) >= 2:
            # ê° ì§€í‘œë³„ ì¿¼ë¦¬
            for indicator in indicators:
                brand_str = brands[0] if brands else "LANEIGE"
                indicator_name = {
                    "sos": "ì ìœ ìœ¨(SoS)",
                    "hhi": "ì‹œì¥ì§‘ì¤‘ë„(HHI)",
                    "cpi": "ê°€ê²©ì§€ìˆ˜(CPI)"
                }.get(indicator, indicator)

                sub_queries.append({
                    "query": f"{brand_str} {indicator_name} ë¶„ì„",
                    "type": "both",
                    "priority": 1,
                    "focus": indicator
                })

            # ì¢…í•© í•´ì„ ì¿¼ë¦¬
            sub_queries.append({
                "query": "ì§€í‘œ ì¡°í•© í•´ì„ ì „ëµ",
                "type": "rag",
                "priority": 2,
                "focus": "interpretation"
            })

            return sub_queries

        # 3. ì‹œê°„ ë²”ìœ„ ë¶„í•´
        for pattern in cls.TIME_COMPARISON_PATTERNS:
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                brand_str = brands[0] if brands else "LANEIGE"

                # í˜„ì¬ ìƒíƒœ ì¿¼ë¦¬
                sub_queries.append({
                    "query": f"{brand_str} í˜„ì¬ ìˆœìœ„ ì„±ê³¼",
                    "type": "kg",
                    "priority": 1,
                    "focus": "current"
                })

                # ë³€í™” ë¶„ì„ ì¿¼ë¦¬
                sub_queries.append({
                    "query": f"{brand_str} ìˆœìœ„ ë³€í™” ì¶”ì´",
                    "type": "kg",
                    "priority": 1,
                    "focus": "trend"
                })

                # í•´ì„ ê°€ì´ë“œ
                sub_queries.append({
                    "query": "ìˆœìœ„ ë³€í™” í•´ì„ ê°€ì´ë“œ",
                    "type": "rag",
                    "priority": 2,
                    "focus": "guide"
                })

                return sub_queries

        # 4. ê¸°ë³¸ ë¶„í•´ (ê¸´ ë³µí•© ì¿¼ë¦¬)
        if len(query) > 50:
            brand_str = brands[0] if brands else ""
            category_str = categories[0] if categories else ""

            # í˜„í™© ì¿¼ë¦¬
            if brand_str:
                sub_queries.append({
                    "query": f"{brand_str} {category_str} í˜„í™©".strip(),
                    "type": "kg",
                    "priority": 1,
                    "focus": "status"
                })

            # ì „ëµ ì¿¼ë¦¬
            sub_queries.append({
                "query": query,  # ì›ë³¸ ì¿¼ë¦¬ë¥¼ RAGì— ì „ë‹¬
                "type": "rag",
                "priority": 2,
                "focus": "strategy"
            })

            return sub_queries

        # ë¶„í•´ ë¶ˆí•„ìš” - ì›ë³¸ ì¿¼ë¦¬ ë°˜í™˜
        return [{
            "query": query,
            "type": "both",
            "priority": 1,
            "focus": "original"
        }]


class HybridRetriever:
    """
    Ontology + RAG í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°

    ë™ì‘ ë°©ì‹:
    1. ì¿¼ë¦¬ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ
    2. ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ê´€ë ¨ ì‚¬ì‹¤ ì¡°íšŒ
    3. ì˜¨í†¨ë¡œì§€ ì¶”ë¡  ì‹¤í–‰
    4. RAG ë¬¸ì„œ ê²€ìƒ‰ (ì¶”ë¡  ê²°ê³¼ë¡œ ì¿¼ë¦¬ í™•ì¥)
    5. ê²°ê³¼ í†µí•©

    ì‚¬ìš© ì˜ˆ:
        retriever = HybridRetriever(kg, reasoner, doc_retriever)
        context = await retriever.retrieve(query, current_metrics)
    """

    def __init__(
        self,
        knowledge_graph: Optional[KnowledgeGraph] = None,
        reasoner: Optional[OntologyReasoner] = None,
        doc_retriever: Optional[DocumentRetriever] = None,
        auto_init_rules: bool = True
    ):
        """
        Args:
            knowledge_graph: ì§€ì‹ ê·¸ë˜í”„
            reasoner: ì˜¨í†¨ë¡œì§€ ì¶”ë¡ ê¸°
            doc_retriever: RAG ë¬¸ì„œ ê²€ìƒ‰ê¸°
            auto_init_rules: ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ìë™ ë“±ë¡
        """
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.kg = knowledge_graph or KnowledgeGraph()
        self.reasoner = reasoner or OntologyReasoner(self.kg)
        self.doc_retriever = doc_retriever or DocumentRetriever()

        # ì—”í‹°í‹° ì¶”ì¶œê¸°
        self.entity_extractor = EntityExtractor()

        # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ìë™ ë“±ë¡
        if auto_init_rules and not self.reasoner.rules:
            register_all_rules(self.reasoner)
            logger.info(f"Registered {len(self.reasoner.rules)} business rules")

        # ì´ˆê¸°í™” ìƒíƒœ
        self._initialized = False

    async def initialize(self) -> None:
        """ë¹„ë™ê¸° ì´ˆê¸°í™”"""
        if not self._initialized:
            await self.doc_retriever.initialize()

            # ì¹´í…Œê³ ë¦¬ ê³„ì¸µ êµ¬ì¡° ë¡œë“œ (ì§€ì‹ê·¸ë˜í”„ ê°•í™”)
            try:
                hierarchy_added = self.kg.load_category_hierarchy()
                if hierarchy_added > 0:
                    logger.info(f"Loaded category hierarchy: {hierarchy_added} relations added")
            except Exception as e:
                logger.warning(f"Failed to load category hierarchy: {e}")

            self._initialized = True

    async def retrieve(
        self,
        query: str,
        current_metrics: Optional[Dict[str, Any]] = None,
        include_explanations: bool = True
    ) -> HybridContext:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            current_metrics: í˜„ì¬ ê³„ì‚°ëœ ì§€í‘œ ë°ì´í„°
            include_explanations: ì¶”ë¡  ì„¤ëª… í¬í•¨ ì—¬ë¶€

        Returns:
            HybridContext
        """
        # ì´ˆê¸°í™” í™•ì¸
        if not self._initialized:
            await self.initialize()

        start_time = datetime.now()

        # ê²°ê³¼ ê°ì²´ ì´ˆê¸°í™”
        context = HybridContext(query=query)

        try:
            # 1. ì—”í‹°í‹° ì¶”ì¶œ (ì§€ì‹ ê·¸ë˜í”„ ì „ë‹¬ë¡œ ì œí’ˆ ASINë„ ì¶”ì¶œ ê°€ëŠ¥)
            entities = self.entity_extractor.extract(query, knowledge_graph=self.kg)
            context.entities = entities
            logger.debug(f"Extracted entities: {entities}")

            # 2. ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ì‚¬ì‹¤ ì¡°íšŒ
            ontology_facts = self._query_knowledge_graph(entities)
            context.ontology_facts = ontology_facts

            # 3. ì¶”ë¡  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            inference_context = self._build_inference_context(
                entities, current_metrics or {}
            )

            # 4. ì˜¨í†¨ë¡œì§€ ì¶”ë¡  ì‹¤í–‰
            inferences = self.reasoner.infer(inference_context)
            context.inferences = inferences
            logger.debug(f"Generated {len(inferences)} inferences")

            # 5. RAG ë¬¸ì„œ ê²€ìƒ‰ (ì¶”ë¡  ê²°ê³¼ë¡œ ì¿¼ë¦¬ í™•ì¥)
            expanded_query = self._expand_query(query, inferences, entities, ontology_facts)
            rag_results = await self.doc_retriever.search(expanded_query, top_k=5)
            context.rag_chunks = rag_results

            # 6. í†µí•© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context.combined_context = self._combine_contexts(
                context, include_explanations
            )

            # ë©”íƒ€ë°ì´í„°
            context.metadata = {
                "retrieval_time_ms": (datetime.now() - start_time).total_seconds() * 1000,
                "ontology_facts_count": len(ontology_facts),
                "inferences_count": len(inferences),
                "rag_chunks_count": len(rag_results),
                "query_expanded": expanded_query != query
            }

        except Exception as e:
            logger.error(f"Hybrid retrieval failed: {e}")
            context.metadata["error"] = str(e)

        return context

    async def retrieve_with_decomposition(
        self,
        query: str,
        current_metrics: Optional[Dict[str, Any]] = None,
        include_explanations: bool = True
    ) -> HybridContext:
        """
        ì¿¼ë¦¬ ë¶„í•´ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

        ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ ë¶„í•´í•˜ì—¬ ê°ê° ì²˜ë¦¬ í›„ ê²°ê³¼ í•©ì„±

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            current_metrics: í˜„ì¬ ì§€í‘œ
            include_explanations: ì„¤ëª… í¬í•¨

        Returns:
            HybridContext
        """
        # ì´ˆê¸°í™” í™•ì¸
        if not self._initialized:
            await self.initialize()

        start_time = datetime.now()

        # ì—”í‹°í‹° ì¶”ì¶œ
        entities = self.entity_extractor.extract(query, knowledge_graph=self.kg)

        # ë¶„í•´ í•„ìš” ì—¬ë¶€ íŒë‹¨
        if not QueryDecomposer.should_decompose(query):
            # ë‹¨ìˆœ ì¿¼ë¦¬ - ê¸°ì¡´ ê²€ìƒ‰ ì‚¬ìš©
            return await self.retrieve(query, current_metrics, include_explanations)

        # ì¿¼ë¦¬ ë¶„í•´
        sub_queries = QueryDecomposer.decompose(query, entities)
        logger.info(f"Query decomposed into {len(sub_queries)} sub-queries")

        # ê²°ê³¼ ìˆ˜ì§‘
        all_ontology_facts = []
        all_inferences = []
        all_rag_chunks = []

        # ê° í•˜ìœ„ ì¿¼ë¦¬ ì²˜ë¦¬
        for sq in sub_queries:
            sub_query = sq["query"]
            query_type = sq["type"]

            if query_type in ["kg", "both"]:
                # KG ì¡°íšŒ
                sub_entities = self.entity_extractor.extract(sub_query, knowledge_graph=self.kg)
                facts = self._query_knowledge_graph(sub_entities)
                all_ontology_facts.extend(facts)

                # ì¶”ë¡ 
                if query_type == "kg" or query_type == "both":
                    inference_ctx = self._build_inference_context(sub_entities, current_metrics or {})
                    inferences = self.reasoner.infer(inference_ctx)
                    all_inferences.extend(inferences)

            if query_type in ["rag", "both"]:
                # RAG ê²€ìƒ‰
                rag_results = await self.doc_retriever.search(sub_query, top_k=3)
                all_rag_chunks.extend(rag_results)

        # ì¤‘ë³µ ì œê±°
        seen_facts = set()
        unique_facts = []
        for fact in all_ontology_facts:
            key = (fact.get("type"), fact.get("entity"))
            if key not in seen_facts:
                seen_facts.add(key)
                unique_facts.append(fact)

        seen_rules = set()
        unique_inferences = []
        for inf in all_inferences:
            if inf.rule_name not in seen_rules:
                seen_rules.add(inf.rule_name)
                unique_inferences.append(inf)

        seen_chunks = set()
        unique_chunks = []
        for chunk in all_rag_chunks:
            if chunk["id"] not in seen_chunks:
                seen_chunks.add(chunk["id"])
                unique_chunks.append(chunk)

        # ê²°ê³¼ ì¡°í•©
        context = HybridContext(
            query=query,
            entities=entities,
            ontology_facts=unique_facts,
            inferences=unique_inferences,
            rag_chunks=sorted(unique_chunks, key=lambda x: x.get("score", 0), reverse=True)[:5]
        )

        # í†µí•© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context.combined_context = self._combine_contexts(context, include_explanations)

        # ë©”íƒ€ë°ì´í„°
        context.metadata = {
            "retrieval_time_ms": (datetime.now() - start_time).total_seconds() * 1000,
            "decomposed": True,
            "sub_query_count": len(sub_queries),
            "sub_queries": [sq["query"] for sq in sub_queries],
            "ontology_facts_count": len(unique_facts),
            "inferences_count": len(unique_inferences),
            "rag_chunks_count": len(unique_chunks)
        }

        return context

    def _query_knowledge_graph(
        self,
        entities: Dict[str, List[str]]
    ) -> List[Dict[str, Any]]:
        """
        ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ê´€ë ¨ ì‚¬ì‹¤ ì¡°íšŒ

        Args:
            entities: ì¶”ì¶œëœ ì—”í‹°í‹°

        Returns:
            ì‚¬ì‹¤ ë¦¬ìŠ¤íŠ¸
        """
        facts = []

        # ë¸Œëœë“œ ê´€ë ¨ ì‚¬ì‹¤
        for brand in entities.get("brands", []):
            # ë¸Œëœë“œ ë©”íƒ€ë°ì´í„°
            brand_meta = self.kg.get_entity_metadata(brand)
            if brand_meta:
                facts.append({
                    "type": "brand_info",
                    "entity": brand,
                    "data": brand_meta
                })

            # ë¸Œëœë“œì˜ ì œí’ˆë“¤
            products = self.kg.get_brand_products(brand)
            if products:
                facts.append({
                    "type": "brand_products",
                    "entity": brand,
                    "data": {
                        "product_count": len(products),
                        "products": products[:10]  # ìƒìœ„ 10ê°œ
                    }
                })

            # ê²½ìŸì‚¬
            competitors = self.kg.get_competitors(brand)
            if competitors:
                facts.append({
                    "type": "competitors",
                    "entity": brand,
                    "data": competitors[:5]  # ìƒìœ„ 5ê°œ
                })

        # ì¹´í…Œê³ ë¦¬ ê´€ë ¨ ì‚¬ì‹¤
        for category in entities.get("categories", []):
            # ì¹´í…Œê³ ë¦¬ ë¸Œëœë“œ ì •ë³´
            category_brands = self.kg.get_category_brands(category)
            if category_brands:
                facts.append({
                    "type": "category_brands",
                    "entity": category,
                    "data": {
                        "brand_count": len(category_brands),
                        "top_brands": category_brands[:5]
                    }
                })

            # ì¹´í…Œê³ ë¦¬ ê³„ì¸µ ì •ë³´ (ë¶€ëª¨/ìì‹ ê´€ê³„)
            try:
                hierarchy = self.kg.get_category_hierarchy(category)
                if hierarchy and not hierarchy.get("error"):
                    facts.append({
                        "type": "category_hierarchy",
                        "entity": category,
                        "data": {
                            "name": hierarchy.get("name", ""),
                            "level": hierarchy.get("level", 0),
                            "path": hierarchy.get("path", []),
                            "ancestors": hierarchy.get("ancestors", []),
                            "descendants": hierarchy.get("descendants", [])
                        }
                    })
            except Exception:
                pass

        # ê°ì„± ê´€ë ¨ ì‚¬ì‹¤ ì¡°íšŒ
        sentiment_clusters = entities.get("sentiment_clusters", [])
        if sentiment_clusters or entities.get("sentiments"):
            # ì œí’ˆì´ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ì œí’ˆì˜ ê°ì„± ì¡°íšŒ
            for asin in entities.get("products", []):
                try:
                    product_sentiments = self.kg.get_product_sentiments(asin)
                    if product_sentiments.get("sentiment_tags") or product_sentiments.get("ai_summary"):
                        facts.append({
                            "type": "product_sentiment",
                            "entity": asin,
                            "data": product_sentiments
                        })
                except Exception:
                    pass

            # ë¸Œëœë“œê°€ ì§€ì •ëœ ê²½ìš° ë¸Œëœë“œ ê°ì„± í”„ë¡œí•„ ì¡°íšŒ
            for brand in entities.get("brands", []):
                try:
                    brand_sentiment = self.kg.get_brand_sentiment_profile(brand)
                    if brand_sentiment.get("all_tags"):
                        facts.append({
                            "type": "brand_sentiment",
                            "entity": brand,
                            "data": brand_sentiment
                        })
                except Exception:
                    pass

            # íŠ¹ì • ê°ì„± í´ëŸ¬ìŠ¤í„°ë¡œ ì œí’ˆ ê²€ìƒ‰
            for cluster in sentiment_clusters:
                if cluster not in ["sentiment_general", "ai_summary"]:
                    try:
                        # í•´ë‹¹ ê°ì„±ì„ ê°€ì§„ ì œí’ˆ ì°¾ê¸°
                        from src.domain.entities.relations import SENTIMENT_CLUSTERS
                        cluster_tags = SENTIMENT_CLUSTERS.get(cluster, [])
                        for tag in cluster_tags[:2]:  # ìƒìœ„ 2ê°œ íƒœê·¸ë§Œ
                            products_with_sentiment = self.kg.find_products_by_sentiment(tag)
                            if products_with_sentiment:
                                facts.append({
                                    "type": "sentiment_products",
                                    "entity": tag,
                                    "data": {
                                        "sentiment_tag": tag,
                                        "cluster": cluster,
                                        "product_count": len(products_with_sentiment),
                                        "products": products_with_sentiment[:5]
                                    }
                                })
                                break
                    except Exception:
                        pass

        return facts

    def _build_inference_context(
        self,
        entities: Dict[str, List[str]],
        current_metrics: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì¶”ë¡ ìš© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±

        Args:
            entities: ì¶”ì¶œëœ ì—”í‹°í‹°
            current_metrics: í˜„ì¬ ì§€í‘œ ë°ì´í„°

        Returns:
            ì¶”ë¡  ì»¨í…ìŠ¤íŠ¸
        """
        context = {}

        # ì—”í‹°í‹° ì •ë³´
        if entities.get("brands"):
            context["brand"] = entities["brands"][0]  # ì²« ë²ˆì§¸ ë¸Œëœë“œ
            context["is_target"] = entities["brands"][0].lower() == "laneige"

        if entities.get("categories"):
            context["category"] = entities["categories"][0]

        # ë©”íŠ¸ë¦­ ì •ë³´ (summaryì—ì„œ)
        summary = current_metrics.get("summary", {})

        # ë¸Œëœë“œë³„ SoS
        sos_by_category = summary.get("laneige_sos_by_category", {})
        if entities.get("categories") and entities["categories"][0] in sos_by_category:
            context["sos"] = sos_by_category[entities["categories"][0]]
        elif sos_by_category:
            # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ì˜ SoS
            context["sos"] = list(sos_by_category.values())[0] if sos_by_category else 0

        # ë¸Œëœë“œ ë©”íŠ¸ë¦­ì—ì„œ ì¶”ê°€ ì •ë³´
        brand_metrics = current_metrics.get("brand_metrics", [])
        for bm in brand_metrics:
            if bm.get("is_laneige") or bm.get("brand_name", "").lower() == context.get("brand", "").lower():
                context["sos"] = bm.get("share_of_shelf", context.get("sos", 0))
                context["avg_rank"] = bm.get("avg_rank")
                context["product_count"] = bm.get("product_count", 0)
                break

        # ë§ˆì¼“ ë©”íŠ¸ë¦­ì—ì„œ HHI ë“±
        market_metrics = current_metrics.get("market_metrics", [])
        for mm in market_metrics:
            if not entities.get("categories") or mm.get("category_id") == entities["categories"][0]:
                context["hhi"] = mm.get("hhi", 0)
                context["cpi"] = mm.get("cpi", 100)
                context["churn_rate"] = mm.get("churn_rate_7d", 0)
                context["rating_gap"] = mm.get("avg_rating_gap", 0)
                break

        # ì œí’ˆ ë©”íŠ¸ë¦­ì—ì„œ
        product_metrics = current_metrics.get("product_metrics", [])
        if product_metrics:
            # ì²« ë²ˆì§¸ ì œí’ˆ ë˜ëŠ” ê°€ì¥ ì¢‹ì€ ìˆœìœ„ ì œí’ˆ
            best_product = min(product_metrics, key=lambda p: p.get("current_rank", 100))
            context["current_rank"] = best_product.get("current_rank")
            context["rank_change_1d"] = best_product.get("rank_change_1d")
            context["rank_change_7d"] = best_product.get("rank_change_7d")
            context["rank_volatility"] = best_product.get("rank_volatility", 0)
            context["streak_days"] = best_product.get("streak_days", 0)
            context["asin"] = best_product.get("asin")

        # ì•Œë¦¼ ì •ë³´
        alerts = current_metrics.get("alerts", [])
        context["has_rank_shock"] = any(a.get("type") == "rank_shock" for a in alerts)
        context["alert_count"] = len(alerts)

        # ê²½ìŸì‚¬ ìˆ˜ (ì§€ì‹ ê·¸ë˜í”„ì—ì„œ)
        if context.get("brand"):
            competitors = self.kg.get_competitors(context["brand"])
            context["competitor_count"] = len(competitors)
            context["competitors"] = competitors

        # ê°ì„± ë°ì´í„° (ì§€ì‹ ê·¸ë˜í”„ì—ì„œ)
        if entities.get("sentiments") or entities.get("sentiment_clusters"):
            # ìì‚¬ ë¸Œëœë“œ ê°ì„± í”„ë¡œí•„
            if context.get("brand"):
                try:
                    brand_sentiment = self.kg.get_brand_sentiment_profile(context["brand"])
                    context["sentiment_tags"] = brand_sentiment.get("all_tags", [])
                    context["sentiment_clusters"] = brand_sentiment.get("clusters", {})
                    context["dominant_sentiment"] = brand_sentiment.get("dominant_sentiment")
                except Exception:
                    pass

            # ì œí’ˆë³„ ê°ì„± ë°ì´í„°
            if context.get("asin"):
                try:
                    product_sentiment = self.kg.get_product_sentiments(context["asin"])
                    context["ai_summary"] = product_sentiment.get("ai_summary")
                    if not context.get("sentiment_tags"):
                        context["sentiment_tags"] = product_sentiment.get("sentiment_tags", [])
                        context["sentiment_clusters"] = product_sentiment.get("sentiment_clusters", {})
                except Exception:
                    pass

            # ê²½ìŸì‚¬ ê°ì„± ë°ì´í„° (ë¹„êµìš©)
            if context.get("competitors"):
                competitor_tags = []
                competitor_clusters = {}
                for comp in context["competitors"][:3]:  # ìƒìœ„ 3ê°œ ê²½ìŸì‚¬
                    comp_brand = comp.get("brand", comp) if isinstance(comp, dict) else comp
                    try:
                        comp_sentiment = self.kg.get_brand_sentiment_profile(comp_brand)
                        competitor_tags.extend(comp_sentiment.get("all_tags", []))
                        for cluster, count in comp_sentiment.get("clusters", {}).items():
                            competitor_clusters[cluster] = competitor_clusters.get(cluster, 0) + count
                    except Exception:
                        pass
                context["competitor_sentiment_tags"] = list(set(competitor_tags))
                context["competitor_sentiment_clusters"] = competitor_clusters

        return context

    def _expand_query(
        self,
        query: str,
        inferences: List[InferenceResult],
        entities: Dict[str, List[str]],
        ontology_facts: Optional[List[Dict[str, Any]]] = None
    ) -> str:
        """
        Graph-Guided Query Expansion

        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
            inferences: ì¶”ë¡  ê²°ê³¼
            entities: ì—”í‹°í‹°
            ontology_facts: KGì—ì„œ ì¡°íšŒí•œ ì‚¬ì‹¤ (NEW)

        Returns:
            í™•ì¥ëœ ì¿¼ë¦¬
        """
        expansion_terms = []

        # 1. KG ê¸°ë°˜ í™•ì¥ (ê²½ìŸì‚¬, ê´€ë ¨ ì œí’ˆëª…)
        if ontology_facts:
            for fact in ontology_facts:
                fact_type = fact.get("type", "")
                data = fact.get("data", {})

                # ê²½ìŸì‚¬ ì´ë¦„ ì¶”ê°€
                if fact_type == "competitors":
                    for comp in data[:3]:  # ìƒìœ„ 3ê°œ
                        brand = comp.get("brand", "") if isinstance(comp, dict) else str(comp)
                        if brand and brand not in expansion_terms:
                            expansion_terms.append(brand)

                # ì¹´í…Œê³ ë¦¬ ì´ë¦„ ì¶”ê°€
                elif fact_type == "category_brands":
                    top_brands = data.get("top_brands", [])
                    for brand_info in top_brands[:2]:
                        brand = brand_info.get("brand", "") if isinstance(brand_info, dict) else str(brand_info)
                        if brand and brand not in expansion_terms:
                            expansion_terms.append(brand)

                # ì¹´í…Œê³ ë¦¬ ê³„ì¸µì—ì„œ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
                elif fact_type == "category_hierarchy":
                    cat_name = data.get("name", "")
                    if cat_name:
                        expansion_terms.append(cat_name)
                    # ìƒìœ„ ì¹´í…Œê³ ë¦¬ë„ ì¶”ê°€
                    for ancestor in data.get("ancestors", [])[:1]:
                        anc_name = ancestor.get("name", "") if isinstance(ancestor, dict) else str(ancestor)
                        if anc_name and anc_name not in expansion_terms:
                            expansion_terms.append(anc_name)

        # 2. ì¶”ë¡ ëœ ì¸ì‚¬ì´íŠ¸ ìœ í˜•ì— ë”°ë¥¸ í‚¤ì›Œë“œ ì¶”ê°€ (ê¸°ì¡´ ë¡œì§)
        insight_types = set(inf.insight_type for inf in inferences)

        if InsightType.MARKET_POSITION in insight_types or InsightType.MARKET_DOMINANCE in insight_types:
            expansion_terms.append("ì‹œì¥ í¬ì§€ì…˜ í•´ì„")

        if InsightType.RISK_ALERT in insight_types:
            expansion_terms.append("ìœ„í—˜ ì‹ í˜¸ ëŒ€ì‘")

        if InsightType.COMPETITIVE_THREAT in insight_types:
            expansion_terms.append("ê²½ìŸ ìœ„í˜‘ ë¶„ì„")

        if InsightType.GROWTH_OPPORTUNITY in insight_types or InsightType.GROWTH_MOMENTUM in insight_types:
            expansion_terms.append("ì„±ì¥ ê¸°íšŒ ì „ëµ")

        if InsightType.PRICE_QUALITY_GAP in insight_types or InsightType.PRICE_POSITION in insight_types:
            expansion_terms.append("ê°€ê²© ì „ëµ í•´ì„")

        # 3. ì§€í‘œ ê´€ë ¨ í™•ì¥ (ê¸°ì¡´ ë¡œì§)
        for indicator in entities.get("indicators", []):
            if indicator == "sos":
                expansion_terms.append("SoS ì ìœ ìœ¨ í•´ì„")
            elif indicator == "hhi":
                expansion_terms.append("HHI ì‹œì¥ì§‘ì¤‘ë„ í•´ì„")
            elif indicator == "cpi":
                expansion_terms.append("CPI ê°€ê²©ì§€ìˆ˜ í•´ì„")

        # í™•ì¥ëœ ì¿¼ë¦¬ ìƒì„±
        if expansion_terms:
            return f"{query} {' '.join(expansion_terms)}"

        return query

    def _combine_contexts(
        self,
        context: HybridContext,
        include_explanations: bool = True
    ) -> str:
        """
        Ontology-Guided Context Ranking

        Priority Order:
        1. High-confidence Inferences (>= 0.8) - ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì¸ì‚¬ì´íŠ¸
        2. Direct KG Facts (brand_info, competitors) - ì§ì ‘ ê´€ê³„
        3. High-score RAG Chunks - ë†’ì€ ìœ ì‚¬ë„ ë¬¸ì„œ
        4. Medium-confidence Inferences (0.5-0.8)
        5. Supporting Context - ë³´ì¡° ì •ë³´

        Args:
            context: HybridContext
            include_explanations: ì¶”ë¡  ì„¤ëª… í¬í•¨

        Returns:
            í†µí•©ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
        """
        parts = []

        # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ë¶„ë¥˜
        high_conf_inferences = [inf for inf in context.inferences if inf.confidence >= 0.8]
        medium_conf_inferences = [inf for inf in context.inferences if 0.5 <= inf.confidence < 0.8]
        low_conf_inferences = [inf for inf in context.inferences if inf.confidence < 0.5]

        # KG ì‚¬ì‹¤ì„ ìœ í˜•ë³„ë¡œ ë¶„ë¥˜
        direct_facts = []  # brand_info, competitors, brand_products
        category_facts = []  # category_brands, category_hierarchy
        sentiment_facts = []  # product_sentiment, brand_sentiment

        for fact in context.ontology_facts:
            fact_type = fact.get("type", "")
            if fact_type in ["brand_info", "competitors", "brand_products"]:
                direct_facts.append(fact)
            elif fact_type in ["category_brands", "category_hierarchy"]:
                category_facts.append(fact)
            elif fact_type in ["product_sentiment", "brand_sentiment", "sentiment_products"]:
                sentiment_facts.append(fact)

        # RAG ì²­í¬ë¥¼ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_rag_chunks = sorted(
            context.rag_chunks,
            key=lambda x: x.get("rrf_score", x.get("score", 0)),
            reverse=True
        )
        high_score_chunks = sorted_rag_chunks[:2]  # ìƒìœ„ 2ê°œ
        remaining_chunks = sorted_rag_chunks[2:4]  # ë‚˜ë¨¸ì§€

        # ============================================================
        # 1. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (High Confidence >= 0.8)
        # ============================================================
        if high_conf_inferences:
            parts.append("## ğŸ¯ í•µì‹¬ ë¶„ì„ ê²°ê³¼\n")
            for i, inf in enumerate(high_conf_inferences, 1):
                parts.append(f"### {inf.insight_type.value.replace('_', ' ').title()}")
                parts.append(f"- **ê²°ë¡ **: {inf.insight}")
                if inf.recommendation:
                    parts.append(f"- **ê¶Œì¥ ì•¡ì…˜**: {inf.recommendation}")
                parts.append(f"- **ì‹ ë¢°ë„**: {inf.confidence:.0%} â­")
                if include_explanations and inf.evidence:
                    conditions = inf.evidence.get("satisfied_conditions", [])
                    if conditions:
                        parts.append(f"- **ê·¼ê±°**: {', '.join(conditions[:3])}")
                parts.append("")

        # ============================================================
        # 2. ì§ì ‘ ê´€ê³„ ì •ë³´ (KG Direct Facts)
        # ============================================================
        if direct_facts:
            parts.append("## ğŸ“Š í•µì‹¬ ì •ë³´ (Knowledge Graph)\n")
            for fact in direct_facts[:4]:
                fact_type = fact.get("type", "")
                entity = fact.get("entity", "")
                data = fact.get("data", {})

                if fact_type == "brand_info":
                    sos = data.get("sos", 0)
                    if sos:
                        parts.append(f"- **{entity}** SoS: {sos*100:.1f}%")
                    if data.get("avg_rank"):
                        parts.append(f"  - í‰ê·  ìˆœìœ„: {data['avg_rank']:.1f}")
                    if data.get("product_count"):
                        parts.append(f"  - ì œí’ˆ ìˆ˜: {data['product_count']}ê°œ")

                elif fact_type == "competitors":
                    comps = [c.get("brand", str(c)) if isinstance(c, dict) else str(c) for c in data[:3]]
                    if comps:
                        parts.append(f"- **{entity}** ì£¼ìš” ê²½ìŸì‚¬: {', '.join(comps)}")

                elif fact_type == "brand_products":
                    parts.append(f"- **{entity}** ì œí’ˆ ìˆ˜: {data.get('product_count', 0)}ê°œ")
            parts.append("")

        # ============================================================
        # 3. í•µì‹¬ ì°¸ê³  ë¬¸ì„œ (High Score RAG)
        # ============================================================
        if high_score_chunks:
            parts.append("## ğŸ“š í•µì‹¬ ê°€ì´ë“œë¼ì¸\n")
            for chunk in high_score_chunks:
                title = chunk.get("metadata", {}).get("title", "")
                content = chunk.get("content", "")
                score = chunk.get("rrf_score", chunk.get("score", 0))

                if title:
                    parts.append(f"### {title}")
                # ë‚´ìš© ì¶•ì•½ (400ì)
                if len(content) > 400:
                    content = content[:400] + "..."
                parts.append(content)
                parts.append("")

        # ============================================================
        # 4. ì¶”ê°€ ë¶„ì„ (Medium Confidence)
        # ============================================================
        if medium_conf_inferences:
            parts.append("## ğŸ“‹ ì¶”ê°€ ë¶„ì„\n")
            for inf in medium_conf_inferences[:3]:
                parts.append(f"- **{inf.insight_type.value.replace('_', ' ').title()}**: {inf.insight}")
                if inf.recommendation:
                    parts.append(f"  - ê¶Œì¥: {inf.recommendation}")
            parts.append("")

        # ============================================================
        # 5. ë³´ì¡° ì •ë³´
        # ============================================================
        supporting_info = []

        # ì¹´í…Œê³ ë¦¬ ì •ë³´
        if category_facts:
            for fact in category_facts[:2]:
                fact_type = fact.get("type", "")
                entity = fact.get("entity", "")
                data = fact.get("data", {})

                if fact_type == "category_brands":
                    top = [b.get("brand", "") for b in data.get("top_brands", [])[:3] if isinstance(b, dict)]
                    if top:
                        supporting_info.append(f"- {entity} Top ë¸Œëœë“œ: {', '.join(top)}")

                elif fact_type == "category_hierarchy":
                    name = data.get("name", entity)
                    level = data.get("level", 0)
                    if name:
                        supporting_info.append(f"- {name} (Level {level})")

        # ê°ì„± ì •ë³´
        if sentiment_facts:
            for fact in sentiment_facts[:2]:
                entity = fact.get("entity", "")
                data = fact.get("data", {})
                tags = data.get("sentiment_tags", data.get("all_tags", []))[:3]
                if tags:
                    supporting_info.append(f"- {entity} ê°ì„±: {', '.join(tags)}")

        # ë‚˜ë¨¸ì§€ RAG ì²­í¬
        if remaining_chunks:
            for chunk in remaining_chunks[:1]:
                title = chunk.get("metadata", {}).get("title", "")
                if title:
                    supporting_info.append(f"- ì°¸ê³ : {title}")

        # Low confidence inferences
        if low_conf_inferences:
            for inf in low_conf_inferences[:2]:
                supporting_info.append(f"- (ì°¸ê³ ) {inf.insight}")

        if supporting_info:
            parts.append("## ğŸ’¡ ë³´ì¡° ì •ë³´\n")
            parts.extend(supporting_info)
            parts.append("")

        return "\n".join(parts)

    async def retrieve_for_entity(
        self,
        entity: str,
        entity_type: str = "brand",
        current_metrics: Optional[Dict[str, Any]] = None
    ) -> HybridContext:
        """
        íŠ¹ì • ì—”í‹°í‹°ì— ëŒ€í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

        Args:
            entity: ì—”í‹°í‹° ID
            entity_type: ì—”í‹°í‹° ìœ í˜• (brand, product, category)
            current_metrics: í˜„ì¬ ì§€í‘œ

        Returns:
            HybridContext
        """
        # ì—”í‹°í‹° ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±
        if entity_type == "brand":
            query = f"{entity} ë¸Œëœë“œ ë¶„ì„"
            entities = {"brands": [entity.lower()]}
        elif entity_type == "product":
            query = f"{entity} ì œí’ˆ ë¶„ì„"
            entities = {"products": [entity]}
        elif entity_type == "category":
            query = f"{entity} ì¹´í…Œê³ ë¦¬ ë¶„ì„"
            entities = {"categories": [entity]}
        else:
            query = f"{entity} ë¶„ì„"
            entities = {}

        # ê²€ìƒ‰ ìˆ˜í–‰
        context = await self.retrieve(query, current_metrics)
        context.entities.update(entities)

        return context

    def update_knowledge_graph(
        self,
        crawl_data: Optional[Dict[str, Any]] = None,
        metrics_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, int]:
        """
        ì§€ì‹ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸

        Args:
            crawl_data: í¬ë¡¤ë§ ë°ì´í„°
            metrics_data: ë©”íŠ¸ë¦­ ë°ì´í„°

        Returns:
            ì—…ë°ì´íŠ¸ í†µê³„
        """
        stats = {"crawl_relations": 0, "metrics_relations": 0}

        if crawl_data:
            stats["crawl_relations"] = self.kg.load_from_crawl_data(crawl_data)

        if metrics_data:
            stats["metrics_relations"] = self.kg.load_from_metrics_data(metrics_data)

        logger.info(f"KG updated: {stats}")
        return stats

    def get_stats(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ê¸° í†µê³„"""
        return {
            "knowledge_graph": self.kg.get_stats(),
            "reasoner": self.reasoner.get_inference_stats(),
            "rules_count": len(self.reasoner.rules),
            "initialized": self._initialized
        }
